# ğŸ“Š Data Flow - Proceso Universal End-to-End

## ğŸ¯ VisiÃ³n General del Proceso

Este documento describe el proceso completo y genÃ©rico que debe seguir una persona para extraer, procesar y obtener informaciÃ³n inteligente de **cualquier tipo de documento**, con o sin capÃ­tulos.

```
ğŸ“„ Documentos â†’ ğŸ” AnÃ¡lisis IA â†’ ğŸ¤– ExtracciÃ³n + Prompts â†’ âœ‹ ValidaciÃ³n â†’ ğŸ’¾ Base de Datos â†’ ğŸ” Consultas IA
```

---

## ğŸš€ **FASE 1: OBTENCIÃ“N DE DOCUMENTOS** (15-45 minutos)

### Paso 1.1: AdquisiciÃ³n de Documentos ğŸ“

**Fuentes posibles**:
- ğŸŒ **Web scraping automÃ¡tico**: Para sitios web con documentos regulares
- ğŸ“§ **Email/descargas manuales**: Para documentos recibidos por email
- ğŸ’¾ **Archivos locales**: Para documentos ya disponibles localmente
- ğŸ—‚ï¸ **Sistemas corporativos**: Para documentos de sistemas internos

```bash
# OpciÃ³n A: Web scraping (si disponible)
cd domains/[dominio]/shared/scrapers/[fuente]
python scraper_automatico.py

# OpciÃ³n B: ColocaciÃ³n manual
mkdir -p domains/[dominio]/data/source_documents
# Copiar documentos manualmente a esta carpeta
```

### Paso 1.2: OrganizaciÃ³n de Documentos (5-10 minutos) ğŸ“‚

**Tarea humana**: Clasificar y organizar documentos por tipo

```bash
# Verificar documentos obtenidos
ls -la domains/[dominio]/data/source_documents/

# Organizar por tipo si es necesario
mkdir -p domains/[dominio]/data/source_documents/reportes_financieros
mkdir -p domains/[dominio]/data/source_documents/documentos_legales
mkdir -p domains/[dominio]/data/source_documents/manuales_tecnicos

# Renombrar para consistencia
mv "Reporte Q3 2025.pdf" "reporte_financiero_2025_Q3.pdf"
```

---

## ğŸ¤– **FASE 2: ANÃLISIS Y PROCESAMIENTO CON IA** (2-8 horas de desarrollo iterativo)

### Paso 2.1: AnÃ¡lisis Inicial AutomÃ¡tico ğŸ”

**âš ï¸ Prompt como Herramienta de Apoyo**: El prompt es una **guÃ­a para desarrollo**, no una soluciÃ³n automÃ¡tica

**Prompt EstratÃ©gico #1 - Herramienta de Apoyo para AnÃ¡lisis**
```markdown
# PROMPT GUÃA - USAR PARA GENERAR CÃ“DIGO INICIAL
# REQUIERE ITERACIÃ“N Y PERSONALIZACIÃ“N ESPECÃFICA

Analiza este documento y genera cÃ³digo Python que determine:

1. **Tipo de documento**: Reporte, manual, contrato, anÃ¡lisis, etc.
2. **Estructura**: Â¿Tiene capÃ­tulos/secciones? Â¿Es documento Ãºnico?
3. **Contenido principal**: Tipos de datos, tablas, informaciÃ³n clave
4. **Entidades**: Personas, empresas, ubicaciones, fechas importantes
5. **OrganizaciÃ³n**: Â¿CÃ³mo estÃ¡ organizada la informaciÃ³n?

**Si tiene capÃ­tulos/secciones**:
- Genera cÃ³digo para detectar divisiones automÃ¡ticamente
- Identifica patrones especÃ­ficos de tÃ­tulos/secciones

**Si es documento unitario**:
- Genera cÃ³digo para anÃ¡lisis de contenido secuencial
- Detecta patrones de datos repetitivos especÃ­ficos

Genera cÃ³digo Python con clases especÃ­ficas, no solo JSON de respuesta.
```

**Desarrollo Real Requerido** (2-4 horas de iteraciÃ³n):
```bash
# 1. Usar prompt para generar cÃ³digo base
# 2. ITERAR 3-5 veces personalizando para documento especÃ­fico

# Archivos a generar/calibrar:
cd domains/{dominio}/chapters/{documento}/processors/

# A) document_analyzer.py (OBLIGATORIO)
python generate_analyzer.py --prompt-file "prompts/analysis/universal_document_analysis.md"
# â†’ Personalizar para detectar estructura especÃ­fica del documento
# â†’ Iterar hasta 85%+ precisiÃ³n en detecciÃ³n

# B) chapter_divider.py (SI APLICA - si tiene capÃ­tulos)
python generate_divider.py --based-on analyzer_results.json
# â†’ Desarrollar divisor especÃ­fico para patrones encontrados
# â†’ Calibrar tÃ­tulos/secciones especÃ­ficas del documento

# C) content_classifier.py (OBLIGATORIO)
python generate_classifier.py --document-type detected_type
# â†’ Clasificador especÃ­fico para tipo de contenido encontrado
# â†’ Personalizar para estructura especÃ­fica
```

**Resultado Esperado tras IteraciÃ³n**:
```
domains/{dominio}/chapters/{documento}/processors/
â”œâ”€â”€ document_analyzer.py          # âœ… Analiza estructura especÃ­fica
â”œâ”€â”€ chapter_divider.py            # âœ… Si aplica: divide capÃ­tulos automÃ¡ticamente
â”œâ”€â”€ content_classifier.py         # âœ… Clasifica contenido especÃ­fico
â””â”€â”€ patterns/
    â”œâ”€â”€ title_patterns.json       # âœ… Patrones de tÃ­tulos calibrados
    â”œâ”€â”€ structure_rules.json      # âœ… Reglas de estructura especÃ­ficas
    â””â”€â”€ content_types.json        # âœ… Tipos de contenido identificados
```

### Paso 2.2: ExtracciÃ³n Adaptativa de Datos ğŸ“Š

**âš ï¸ Prompt como Herramienta de Apoyo**: Requiere 8-20 horas de desarrollo especÃ­fico e iterativo

**Prompt EstratÃ©gico #2 - Herramienta para Generar Extractores**
```markdown
# PROMPT GUÃA - GENERAR CÃ“DIGO DE EXTRACCIÃ“N ESPECÃFICO
# REQUIERE 8-15 ITERACIONES DE PERSONALIZACIÃ“N

Genera cÃ³digo Python de extracciÃ³n especÃ­fica para este documento:

**Contexto**: [Usar resultado de anÃ¡lisis previo]
**Objetivo**: Crear clase extractor especÃ­fica, no extracciÃ³n genÃ©rica

**Generar cÃ³digo Python que**:
1. **Extraiga entidades especÃ­ficas del tipo de documento**
2. **Valide rangos especÃ­ficos** (ej: fechas vÃ¡lidas, montos realistas)
3. **Normalice entidades** (ej: nombres de empresas consistentes)
4. **Maneje casos especÃ­ficos** del tipo de documento

**Para documentos con capÃ­tulos**: Generar mÃ©todo de procesamiento por secciones
**Para documentos unitarios**: Generar mÃ©todo de procesamiento secuencial
**Incluir**: Validaciones especÃ­ficas del dominio y tipo de documento
```

**Desarrollo Real Requerido** (8-20 horas de iteraciÃ³n intensiva):
```bash
cd domains/{dominio}/chapters/{documento}/processors/

# A) Extractor principal (8-20 horas de iteraciÃ³n)
python generate_extractor.py --prompt-file "prompts/extraction/generic_document_extraction.md"
# â†’ Personalizar ESPECÃFICAMENTE para el documento
# â†’ Iterar 8-15 veces hasta lograr 85-95%+ confianza

# B) content_extractor.py (OBLIGATORIO - desarrollo especÃ­fico)
# â†’ Extraer contenido especÃ­fico del tipo de documento
# â†’ Personalizar validaciones de rangos y formatos
# â†’ NO automatizable con prompts

# C) section_processor.py (SI APLICA - para documentos con capÃ­tulos)
# â†’ Procesamiento especÃ­fico por tipo de secciÃ³n encontrada
# â†’ Requiere lÃ³gica especÃ­fica por cada tipo de capÃ­tulo

# D) entity_extractor.py (OBLIGATORIO - altamente especÃ­fico)
# â†’ Extraer entidades especÃ­ficas del dominio
# â†’ Diccionarios de normalizaciÃ³n especÃ­ficos
# â†’ Validaciones de coherencia especÃ­ficas del documento
```

**Proceso Iterativo TÃ­pico**:
```bash
# Ciclo de desarrollo (repetir 8-15 veces):
for iteration in {1..15}; do
    echo "IteraciÃ³n $iteration:"

    # 1. Probar extractor actual
    python {documento}_processor.py --test-sample sample_$iteration.pdf

    # 2. Revisar manualmente resultados
    python review_results.py --interactive

    # 3. Identificar fallos especÃ­ficos
    # 4. Refinar cÃ³digo especÃ­fico (NO prompt)
    # 5. Calibrar validaciones especÃ­ficas

    # 6. Validar confianza
    confidence=$(python measure_confidence.py --results last_extraction.json)
    echo "Confianza actual: $confidence"

    if [ "$confidence" -gt "0.85" ]; then
        echo "âœ… Extractor calibrado exitosamente"
        break
    fi
done
```

**Resultado Esperado tras IteraciÃ³n Intensiva**:
```
domains/{dominio}/chapters/{documento}/processors/
â”œâ”€â”€ {documento}_processor.py      # âœ… Procesador principal calibrado 85-95%+
â”œâ”€â”€ content_extractor.py          # âœ… Extractor de contenido especÃ­fico
â”œâ”€â”€ section_processor.py          # âœ… Si aplica: procesador por secciones
â”œâ”€â”€ entity_extractor.py           # âœ… Extractor de entidades especÃ­ficas
â”œâ”€â”€ validation_rules.py           # âœ… Reglas de validaciÃ³n especÃ­ficas
â””â”€â”€ patterns/
    â”œâ”€â”€ entity_patterns.json      # âœ… Patrones de entidades calibrados
    â”œâ”€â”€ data_validation.json      # âœ… Rangos vÃ¡lidos especÃ­ficos
    â””â”€â”€ extraction_rules.json     # âœ… Reglas de extracciÃ³n especÃ­ficas
```

### Paso 2.3: GeneraciÃ³n AutomÃ¡tica de Metadatos ğŸ·ï¸

**âš ï¸ Prompt como Herramienta de Apoyo**: Requiere 4-8 horas de desarrollo y calibraciÃ³n especÃ­fica

**Prompt EstratÃ©gico #3 - Herramienta para Metadatos EspecÃ­ficos**
```markdown
# PROMPT GUÃA - GENERAR CÃ“DIGO DE METADATOS ESPECÃFICOS
# REQUIERE PERSONALIZACIÃ“N PARA DOMINIO/INDUSTRIA ESPECÃFICA

Genera cÃ³digo Python para metadatos especÃ­ficos de este documento:

**Generar cÃ³digo Python que**:
1. **Tags semÃ¡nticos especÃ­ficos**: Del dominio/industria especÃ­fica
2. **ClasificaciÃ³n automÃ¡tica**: Basada en contenido especÃ­fico detectado
3. **Entidades normalizadas**: Con diccionarios especÃ­ficos del dominio
4. **Cross-referencias**: Reglas especÃ­ficas entre tipos de documentos

**EspecÃ­fico por dominio**:
- **Financiero**: Tags de mÃ©tricas, periodos fiscales, ratios especÃ­ficos
- **Legal**: Tags de tipos de contrato, obligaciones, jurisdicciones
- **TÃ©cnico**: Tags de especificaciones, normas, procedimientos
- **Operacional**: Tags de KPIs, procesos, mÃ©tricas de rendimiento
```

**Desarrollo Real Requerido** (4-8 horas de calibraciÃ³n especÃ­fica):
```bash
cd domains/{dominio}/chapters/{documento}/processors/

# A) metadata_generator.py (OBLIGATORIO - especÃ­fico por dominio)
python generate_metadata_code.py --prompt-file "prompts/metadata/universal_metadata_generation.md"
# â†’ Personalizar tags especÃ­ficos del dominio/industria
# â†’ Calibrar diccionarios de normalizaciÃ³n especÃ­ficos
# â†’ NO automatizable completamente con prompts

# B) tag_classifier.py (DESARROLLO ESPECÃFICO)
# â†’ Clasificador de tags especÃ­ficos para el tipo de documento
# â†’ Requiere conocimiento del dominio especÃ­fico
# â†’ Diccionarios de sinÃ³nimos especÃ­ficos

# C) entity_normalizer.py (ALTAMENTE ESPECÃFICO)
# â†’ Normalizador de nombres de empresas/organizaciones
# â†’ EspecÃ­fico por paÃ­s/regiÃ³n/industria
# â†’ Requiere bases de datos especÃ­ficas del dominio

# D) cross_reference_generator.py (LÃ“GICA ESPECÃFICA)
# â†’ Generador de referencias cruzadas especÃ­ficas
# â†’ Reglas especÃ­ficas entre tipos de documentos del dominio
# â†’ NO generalizable con prompts Ãºnicamente
```

**CalibraciÃ³n EspecÃ­fica Requerida**:
```python
# Ejemplo de desarrollo especÃ­fico NO automatizable
class DomainSpecificMetadataGenerator:
    def __init__(self, domain_type):
        # Diccionarios especÃ­ficos del dominio
        if domain_type == "financial_chile":
            self.company_normalizer = {
                "Banco de Chile": ["BancoChile", "BCH", "Banco Chile S.A."],
                "Banco Santander": ["Santander", "BSA", "Santander Chile"]
            }
            self.tag_patterns = {
                "ratios_financieros": ["ROI", "ROE", "EBITDA", "margen"],
                "periodos": ["trimestre", "Q1", "Q2", "Q3", "Q4", "anual"]
            }
        elif domain_type == "legal_spain":
            self.legal_terms = {
                "contratos": ["arrendamiento", "servicios", "compraventa"],
                "jurisdicciones": ["madrid", "barcelona", "valencia"]
            }
        # ... desarrollo especÃ­fico por dominio
```

**Resultado Esperado tras CalibraciÃ³n**:
```
domains/{dominio}/chapters/{documento}/processors/
â”œâ”€â”€ metadata_generator.py         # âœ… Generador especÃ­fico calibrado
â”œâ”€â”€ tag_classifier.py             # âœ… Clasificador especÃ­fico del dominio
â”œâ”€â”€ entity_normalizer.py          # âœ… Normalizador especÃ­fico regiÃ³n/industria
â”œâ”€â”€ cross_reference_generator.py  # âœ… Generador referencias especÃ­ficas
â””â”€â”€ metadata_config/
    â”œâ”€â”€ domain_tags.json          # âœ… Tags especÃ­ficos del dominio
    â”œâ”€â”€ normalization_dict.json   # âœ… Diccionario normalizaciÃ³n especÃ­fico
    â”œâ”€â”€ entity_aliases.json       # âœ… Aliases especÃ­ficos regiÃ³n/industria
    â””â”€â”€ cross_ref_rules.json      # âœ… Reglas referencias especÃ­ficas
```
3. **ClasificaciÃ³n geogrÃ¡fica**: paÃ­ses, regiones, ciudades mencionadas
4. **ClasificaciÃ³n temporal**: fechas, perÃ­odos, rangos temporales
5. **ClasificaciÃ³n funcional**: tipo de documento, propÃ³sito, audiencia

**Entidades universales a identificar**:
- **Personas**: Nombres de individuos mencionados
- **Organizaciones**: Empresas, instituciones, entidades gubernamentales
- **Ubicaciones**: Direcciones, ciudades, regiones, paÃ­ses
- **Fechas**: Fechas especÃ­ficas, perÃ­odos, plazos
- **Conceptos clave**: TÃ©rminos tÃ©cnicos, mÃ©tricas importantes

**ClasificaciÃ³n automÃ¡tica por industria/dominio**:
- Si es financiero: balance, ingresos, gastos, activos
- Si es legal: contratos, clausulas, obligaciones, derechos
- Si es tÃ©cnico: especificaciones, procedimientos, equipos
- Si es operacional: procesos, resultados, mÃ©tricas

**Cross-referencias potenciales**:
- Mismas entidades en otros documentos
- Mismo perÃ­odo temporal
- Mismas organizaciones involucradas
```

**Ejecutar**:
```bash
python ai_platform/processors/metadata_generator.py \
  --input "extracted_data.json" \
  --prompt-file "prompts/metadata/universal_metadata_generation.md"
```

---

## âœ‹ **FASE 3: VALIDACIÃ“N Y ENRIQUECIMIENTO MANUAL** (30-60 minutos)

### Paso 3.1: RevisiÃ³n Interactiva de Extracciones ğŸ”

**Herramienta de validaciÃ³n humana**:
```bash
python shared_platform/cli/validation_interface.py --chapter "anexo_02" --interactive
```

**Proceso de validaciÃ³n**:
1. **Revisar cada extracciÃ³n**: âœ… Aprobar o âŒ Rechazar
2. **Verificar nombres**: Â¿"Planta Solar Atacama" es correcto?
3. **Validar capacidades**: Â¿100 MW es realista para esta planta?
4. **Confirmar ubicaciones**: Â¿Las coordenadas corresponden?

**Ejemplo de interfaz interactiva**:
```
ğŸ” ExtracciÃ³n #47 - Planta Solar QuilapilÃºn
â”œâ”€â”€ Empresa: Enel Chile S.A.
â”œâ”€â”€ Capacidad: 110 MW
â”œâ”€â”€ TecnologÃ­a: Solar Fotovoltaica
â”œâ”€â”€ UbicaciÃ³n: RegiÃ³n Metropolitana
â”œâ”€â”€ Confianza IA: 0.89

Â¿Aprobar esta extracciÃ³n? [y/n/edit]:
```

### Paso 3.2: Enriquecimiento Manual de Datos ğŸ“

**Agregar informaciÃ³n adicional**:
```bash
# Editor interactivo para agregar datos
python shared_platform/cli/data_enrichment.py --entity "planta_solar_quilapilun"
```

**InformaciÃ³n que puedes agregar manualmente**:
- **Context business**: Importancia estratÃ©gica de la planta
- **Observaciones tÃ©cnicas**: Particularidades operacionales
- **Links externos**: Sitio web de la empresa, noticias relevantes
- **Tags personalizados**: Etiquetas especÃ­ficas de tu anÃ¡lisis
- **Notas de calidad**: Comentarios sobre la confiabilidad de los datos

**Ejemplo de enriquecimiento**:
```json
{
  "manual_annotations": {
    "business_priority": "high",
    "strategic_notes": "Planta clave para suministro RM",
    "data_quality": "validated_2025_09_25",
    "custom_tags": ["nueva_tecnologia", "alto_rendimiento"],
    "external_links": ["https://enel.cl/proyectos/quilapilun"],
    "analyst_notes": "Rendimiento 15% superior al promedio regional"
  }
}
```

### Paso 3.3: ValidaciÃ³n de Cross-Referencias ğŸ”—

**Prompt EstratÃ©gico #4 - Cross-Referencias**
```markdown
# PROMPT PARA CROSS-REFERENCIAS AUTOMÃTICAS
Genera cross-referencias inteligentes para esta planta solar:

**Reglas de referencia**:
1. **Temporal**: Misma planta en reportes de diferentes meses
2. **Empresarial**: Otras plantas de la misma empresa
3. **GeogrÃ¡fica**: Plantas en la misma regiÃ³n
4. **TÃ©cnica**: Plantas con similar capacidad y tecnologÃ­a
5. **Operacional**: Plantas que operan en el mismo horario solar

**Tipos de relaciÃ³n**:
- MISMA_ENTIDAD: Misma planta en otro documento
- MISMA_EMPRESA: Otra planta de la misma empresa
- PROXIMIDAD_GEOGRAFICA: Plantas cercanas geogrÃ¡ficamente
- COMPLEMENTARIEDAD_TECNICA: Plantas que se complementan operacionalmente

**Nivel de confianza**: 0-1 para cada referencia sugerida
```

---

## ğŸ’¾ **FASE 4: CONSOLIDACIÃ“N Y ALMACENAMIENTO** (15-30 minutos)

### Paso 4.1: GeneraciÃ³n de JSON Universal ğŸ“„

**Aplicar esquema universal chileno**:
```bash
python domains/operaciones/shared/utilities/extractor_universal_integrado.py --input "validated_extractions/" --output "universal_format/"
```

**Resultado - Esquema JSON-LD Universal**:
```json
{
  "@context": "https://coordinador.cl/context/v1",
  "@id": "cen:operaciones:anexo_02:2025-09-25",
  "@type": "DocumentoSistemaElectricoChile",

  "metadatos_universales": {
    "titulo": "ANEXO 2 - GeneraciÃ³n Real",
    "dominio": "operaciones",
    "regulador": "Coordinador ElÃ©ctrico Nacional",
    "sistema_electrico": "SEN"
  },

  "entidades": {
    "centrales_electricas": [
      {
        "@id": "cen:central:planta_solar_quilapilun",
        "@type": "CentralSolarChile",
        "nombre": "Planta Solar QuilapilÃºn",
        "empresa": "Enel Chile S.A.",
        "capacidad_mw": 110,
        "confianza": 0.92
      }
    ]
  },

  "referencias_cruzadas": [
    {
      "documento_objetivo": "cen:operaciones:anexo_01:2025-09-25",
      "tipo_relacion": "MISMA_CENTRAL_PROGRAMACION",
      "confianza": 0.95,
      "contexto": "Misma planta en programaciÃ³n operacional"
    }
  ],

  "datos_especificos_dominio": {
    "operaciones": {
      // Datos originales extraÃ­dos preservados
    }
  }
}
```

### Paso 4.2: Ingesta a Base de Datos ğŸ—„ï¸

```bash
# Crear/actualizar base de datos
make setup-db

# Ingestar datos procesados
make ingest-data

# Verificar ingesta exitosa
python shared_platform/database_tools/verify_ingestion.py --stats
```

**Resultado esperado**:
```
âœ… Base de datos actualizada:
â”œâ”€â”€ [N] entidades principales ingresadas
â”œâ”€â”€ [M] cross-referencias generadas automÃ¡ticamente
â”œâ”€â”€ [X] organizaciones identificadas y normalizadas
â””â”€â”€ 100% datos con validaciÃ³n humana
```

---

## ğŸ” **FASE 5: ACCESO Y CONSULTAS IA** (Tiempo real)

### Paso 5.1: Activar Servidores MCP ğŸ¤–

```bash
# Servidor principal
make run-mcp

# Servidores especializados por dominio
cd ai_platform/mcp_servers
python operaciones_server.py      # AnÃ¡lisis operacional
python mercados_server.py         # AnÃ¡lisis de mercados/business
python legal_server.py            # AnÃ¡lisis legal/compliance
python cross_domain_server.py     # AnÃ¡lisis cross-domain
```

### Paso 5.2: Consultas IA Inteligentes ğŸ’¡

**Ejemplos de consultas universales por tipo de documento**:

```markdown
# Consultas sobre documentos financieros
"Â¿CuÃ¡les son las 10 empresas con mayor crecimiento de ingresos y cÃ³mo se comparan con sus presupuestos?"

# Consultas sobre documentos legales/contractuales
"Muestra todos los contratos que vencen en los prÃ³ximos 6 meses y sus obligaciones pendientes"

# Consultas sobre documentos operacionales
"Â¿QuÃ© procesos tienen mayor desviaciÃ³n respecto a KPIs establecidos y cuÃ¡les son las causas identificadas?"

# Consultas cross-domain (mÃºltiples tipos)
"Correlaciona el rendimiento financiero con los indicadores operacionales durante el Ãºltimo trimestre"
```

### Paso 5.3: Dashboard Web Interactivo ğŸ“Š

```bash
make run-web
# â†’ http://localhost:5000
```

**Funcionalidades del dashboard**:
- **Vista de entidades**: VisualizaciÃ³n interactiva de todas las entidades extraÃ­das
- **AnÃ¡lisis temporal**: GrÃ¡ficos de tendencias y evoluciÃ³n de datos en el tiempo
- **Comparativas**: Entre organizaciones, regiones, mÃ©tricas, perÃ­odos
- **BÃºsqueda**: Por nombre, entidad, mÃ©tricas, ubicaciÃ³n, fechas
- **ExportaciÃ³n**: CSV, JSON, reportes PDF personalizables

---

## ğŸ¯ **PROMPTS ESTRATÃ‰GICOS - Herramientas de Desarrollo IA**

### âš ï¸ **IMPORTANTE: Los Prompts son Herramientas de Apoyo**

Los prompts **NO** son soluciones automÃ¡ticas. Son **plantillas de instrucciones** para:
- **Guiar el desarrollo** de cÃ³digo especÃ­fico para cada documento
- **Acelerar la iteraciÃ³n** de procesadores personalizados
- **Estandarizar el enfoque** de extracciÃ³n y validaciÃ³n

**Proceso real de desarrollo**:
1. **Usar prompt como guÃ­a** â†’ Generar cÃ³digo inicial con IA
2. **Iterar y personalizar** â†’ Adaptar cÃ³digo al documento especÃ­fico
3. **Validar y calibrar** â†’ Lograr 85-95%+ confianza en extracciones
4. **Generar componentes** â†’ Crear divisores, validadores, normalizadores

### ğŸ“ Estructura Completa de Componentes por Fase

```
domains/{dominio}/chapters/{documento}/
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ {documento}_processor.py              # Procesador principal
â”‚   â”œâ”€â”€ chapter_divider.py                    # Si aplica: DivisiÃ³n automÃ¡tica de capÃ­tulos
â”‚   â”œâ”€â”€ content_extractor.py                 # Extractor de contenido especÃ­fico
â”‚   â”œâ”€â”€ data_validator.py                    # Validador de datos extraÃ­dos
â”‚   â”œâ”€â”€ entity_normalizer.py                 # Normalizador de entidades
â”‚   â””â”€â”€ quality_checker.py                   # Control de calidad especÃ­fico
â”œâ”€â”€ patterns/
â”‚   â”œâ”€â”€ title_patterns.json                  # Patrones de tÃ­tulos/secciones
â”‚   â”œâ”€â”€ entity_patterns.json                 # Patrones de entidades especÃ­ficas
â”‚   â””â”€â”€ validation_rules.json                # Reglas de validaciÃ³n especÃ­ficas
â””â”€â”€ data/
    â”œâ”€â”€ extractions/                          # Resultados finales validados
    â”œâ”€â”€ samples/                              # Muestras para desarrollo
    â””â”€â”€ validation_logs/                      # Logs de control de calidad
```

### ğŸ”§ **Uso de Prompts por Etapa de Desarrollo**

#### **ETAPA 1: AnÃ¡lisis Inicial (Prompt: analysis/universal_document_analysis.md)**
```bash
# Usar prompt para generar analizador inicial
python ai_platform/analyzers/document_structure_analyzer.py \
  --prompt-file "prompts/analysis/universal_document_analysis.md" \
  --document "sample_document.pdf"

# Resultado: CÃ³digo base para chapter_divider.py (si aplica)
# IteraciÃ³n manual: Personalizar patrones de detecciÃ³n especÃ­ficos
```

#### **ETAPA 2: ExtracciÃ³n EspecÃ­fica (Prompt: extraction/generic_document_extraction.md)**
```bash
# Usar prompt como base para generar extractor
# IMPORTANTE: El cÃ³digo generado requiere 5-10 iteraciones mÃ­nimo

# Desarrollo iterativo tÃ­pico:
for iteration in range(10):
    # 1. Generar cÃ³digo con IA usando prompt
    # 2. Probar en documentos reales
    # 3. Identificar fallos especÃ­ficos
    # 4. Refinar prompt y regenerar cÃ³digo
    # 5. Validar manualmente hasta lograr 85-95%+ confianza

# Resultado final: {documento}_processor.py calibrado especÃ­ficamente
```

#### **ETAPA 3: Componentes de ValidaciÃ³n (IteraciÃ³n manual intensiva)**
```python
# data_validator.py - Desarrollado especÃ­ficamente por documento
class DocumentSpecificValidator:
    def __init__(self):
        # Rangos especÃ­ficos del tipo de documento
        self.valid_ranges = {
            "financial": {"revenue": (0, 1e12), "margin": (0, 1)},
            "legal": {"contract_duration_months": (1, 240)},
            "technical": {"temperature_celsius": (-50, 200)}
        }

    def validate_extraction(self, data):
        # Validaciones especÃ­ficas que requieren conocimiento del dominio
        # NO generables automÃ¡ticamente con prompts
        pass

# quality_checker.py - Control de calidad especÃ­fico
class QualityController:
    def check_completeness(self, extracted_data, source_document):
        # Verificaciones especÃ­ficas del documento
        # Requiere calibraciÃ³n manual iterativa
        pass
```

#### **ETAPA 4: NormalizaciÃ³n de Entidades (EspecÃ­fico por dominio)**
```python
# entity_normalizer.py - Altamente especÃ­fico
class EntityNormalizer:
    def __init__(self):
        # Diccionarios especÃ­ficos del dominio/regiÃ³n
        self.company_aliases = {
            "financial_chile": {"Banco de Chile": ["BancoChile", "BCH", "Banco Chile"]},
            "energy_spain": {"Iberdrola S.A.": ["Iberdrola", "IBE", "Iberdrola EspaÃ±a"]}
        }

    def normalize_companies(self, raw_entities):
        # LÃ³gica especÃ­fica que requiere conocimiento del dominio
        # NO automatizable con prompts genÃ©ricos
        pass
```

### ğŸ“‹ **Prompts Disponibles (Herramientas de Apoyo)**

```
prompts/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ universal_document_analysis.md          # GuÃ­a para analyzers/
â”œâ”€â”€ extraction/
â”‚   â””â”€â”€ generic_document_extraction.md          # Base para processors/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ universal_metadata_generation.md        # Apoyo para metadatos
â”‚   â””â”€â”€ cross_reference_generation.md          # GuÃ­a para referencias
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ quality_check.md                        # Base para quality_checker.py
â”‚   â””â”€â”€ consistency_validation.md               # Base para data_validator.py
â””â”€â”€ README.md                                   # Manual completo de iteraciÃ³n
```

### â±ï¸ **Tiempo Real de Desarrollo por Componente**

| Componente | Prompt Base | Iteraciones | Tiempo Total |
|------------|-------------|-------------|--------------|
| `document_analyzer.py` | `analysis/universal_*` | 3-5 | 2-4 horas |
| `chapter_divider.py` | Manual | 5-8 | 4-8 horas |
| `{doc}_processor.py` | `extraction/generic_*` | 8-15 | 8-20 horas |
| `data_validator.py` | `validation/quality_*` | 5-10 | 6-12 horas |
| `entity_normalizer.py` | Manual | 10-20 | 10-25 horas |
| `quality_checker.py` | `validation/consistency_*` | 8-12 | 8-15 horas |

### âœ… **Proceso de CalibraciÃ³n hasta 85-95%+ Confianza**

```bash
# Flujo iterativo tÃ­pico para un nuevo tipo de documento
cd domains/{dominio}/chapters/{documento}/processors

# 1. AnÃ¡lisis inicial (2-4 horas)
python document_analyzer.py --samples ../data/samples/ --iterations 5

# 2. DivisiÃ³n de capÃ­tulos si aplica (4-8 horas)
python chapter_divider.py --calibrate --manual-validation

# 3. ExtracciÃ³n especÃ­fica (8-20 horas de iteraciÃ³n)
for i in {1..15}; do
    python {documento}_processor.py --test-sample $i
    # Revisar manualmente, identificar problemas
    # Refinar cÃ³digo, repetir hasta 85-95%+ confianza
done

# 4. ValidaciÃ³n robusta (6-12 horas)
python data_validator.py --strict-mode --manual-review

# 5. NormalizaciÃ³n (10-25 horas - mÃ¡s intensivo)
python entity_normalizer.py --build-dictionary --validate-all

# 6. Control de calidad final (8-15 horas)
python quality_checker.py --full-validation --confidence-threshold 0.85
```

---

## âš¡ **Proceso RÃ¡pido - Resumen Ejecutivo Universal**

### **Para CUALQUIER documento nuevo (Primera vez - 2-3 horas)**:
```bash
# 1. Obtener/organizar documentos (15-30 min)
mkdir -p domains/[dominio]/data/source_documents
# Colocar documentos en carpeta

# 2. AnÃ¡lisis automÃ¡tico (15-30 min)
python ai_platform/analyzers/document_structure_analyzer.py \
  --pdf "path/to/document.pdf" \
  --prompt-file "prompts/analysis/universal_document_analysis.md"

# 3. ExtracciÃ³n adaptativa (45-90 min)
python ai_platform/processors/adaptive_document_processor.py \
  --document "path/to/document.pdf" \
  --analysis "analysis_result.json" \
  --prompt-file "prompts/extraction/generic_document_extraction.md"

# 4. GeneraciÃ³n de metadatos (15-30 min)
python ai_platform/processors/metadata_generator.py \
  --input "extracted_data.json" \
  --prompt-file "prompts/metadata/universal_metadata_generation.md"

# 5. ValidaciÃ³n interactiva (30-60 min)
python shared_platform/cli/universal_validation_interface.py --interactive

# 6. ConsolidaciÃ³n final (15 min)
make ingest-data

# 7. Acceso IA inmediato
make run-mcp
```

### **Para documentos del mismo tipo (Proceso establecido - 30-45 minutos)**:
```bash
# Reutilizar procesadores calibrados
python ai_platform/processors/adaptive_document_processor.py \
  --document "path/to/new/document.pdf" \
  --reuse-profile "previous_document_profile.json" \
  --auto-validate
```

### **Ejemplos por Tipo de Documento**

#### **ğŸ“ˆ Documento Financiero (ej: Estado de Resultados)**
```bash
# Tiempo estimado: 60-90 minutos
python ai_platform/processors/adaptive_document_processor.py \
  --document "estado_resultados_q3_2025.pdf" \
  --domain-hint "financiero" \
  --extract-focus "mÃ©tricas_financieras,comparativos_temporales"
```

**Resultado esperado**: Ingresos, gastos, ratios financieros, comparativos aÃ±o anterior

#### **ğŸ“‹ Contrato Legal (ej: Contrato de Servicios)**
```bash
# Tiempo estimado: 45-75 minutos
python ai_platform/processors/adaptive_document_processor.py \
  --document "contrato_servicios_2025.pdf" \
  --domain-hint "legal" \
  --extract-focus "partes_contrato,obligaciones,fechas_criticas"
```

**Resultado esperado**: Partes involucradas, obligaciones, plazos, condiciones

#### **ğŸ”§ Manual TÃ©cnico (ej: Manual de OperaciÃ³n)**
```bash
# Tiempo estimado: 75-120 minutos
python ai_platform/processors/adaptive_document_processor.py \
  --document "manual_operacion_equipo.pdf" \
  --domain-hint "tÃ©cnico" \
  --extract-focus "procedimientos,especificaciones,requisitos_seguridad"
```

**Resultado esperado**: Procedimientos paso a paso, especificaciones tÃ©cnicas, normas

---

## ğŸ† **Beneficios del Proceso Universal**

### âœ… **Adaptabilidad Total**
- **Funciona con CUALQUIER tipo de documento**: Financieros, legales, tÃ©cnicos, operacionales
- **Auto-detecciÃ³n de estructura**: Con capÃ­tulos o documentos unitarios
- **Procesadores adaptativos**: Se ajustan automÃ¡ticamente al contenido

### âœ… **AutomatizaciÃ³n Inteligente**
- **85-90%+ automatizado** con validaciÃ³n humana estratÃ©gica
- **Prompts universales** que se adaptan al contenido detectado
- **ReutilizaciÃ³n automÃ¡tica** de perfiles para documentos similares

### âœ… **Calidad y Consistencia**
- **ValidaciÃ³n interactiva** en puntos crÃ­ticos identificados automÃ¡ticamente
- **Cross-referencias universales** entre cualquier tipo de documento
- **Metadatos estructurados** para bÃºsqueda y anÃ¡lisis avanzado

### âœ… **Escalabilidad Enterprise**
- **Documentos nuevos del mismo tipo**: 30-45 minutos (reutilizaciÃ³n automÃ¡tica)
- **Tipos completamente nuevos**: 2-3 horas (primera vez, luego reutilizable)
- **Consultas IA cross-domain**: Tiempo real sobre todos los tipos de datos

### âœ… **Valor Business Universal**
- **ROI inmediato**: De documento a insights business en 2-3 horas mÃ¡ximo
- **AnÃ¡lisis correlacional**: Entre documentos de diferentes dominios
- **Decisiones data-driven**: Basadas en informaciÃ³n estructurada y cross-referenciada
- **Knowledge building**: ConstrucciÃ³n automÃ¡tica de base de conocimiento empresarial

### âœ… **Casos de Uso Empresariales**

#### **Due Diligence Automatizado**
```markdown
Escenario: AdquisiciÃ³n empresarial
Documentos: Estados financieros + contratos + auditorÃ­as + documentos legales
Resultado: AnÃ¡lisis integral automÃ¡tico con red de cross-referencias
Tiempo: 8-12 horas vs 2-3 semanas manual
```

#### **Compliance AutomÃ¡tico**
```markdown
Escenario: AuditorÃ­a regulatoria
Documentos: PolÃ­ticas + procedimientos + reportes + contratos
Resultado: VerificaciÃ³n automÃ¡tica de cumplimiento normativo
Tiempo: 4-6 horas vs 1-2 semanas manual
```

#### **Research & Analysis**
```markdown
Escenario: InvestigaciÃ³n de mercado
Documentos: Estudios + reportes + anÃ¡lisis + documentos pÃºblicos
Resultado: SÃ­ntesis inteligente con insights cross-document
Tiempo: 6-8 horas vs 3-4 semanas manual
```

---

## ğŸ“š **DocumentaciÃ³n Relacionada**

- [`DATA_FLOW_EXAMPLE.md`](DATA_FLOW_EXAMPLE.md) - Ejemplo prÃ¡ctico paso a paso
- [`prompts/README.md`](../prompts/README.md) - Biblioteca completa de prompts
- [`CLAUDE.md`](../CLAUDE.md) - GuÃ­a tÃ©cnica para desarrolladores
- [`SETUP_REPOSITORY.md`](../SETUP_REPOSITORY.md) - ConfiguraciÃ³n inicial del proyecto

---

**ğŸš€ Â¡Tu inteligencia del sistema elÃ©ctrico chileno estÃ¡ lista en 2-3 horas!**