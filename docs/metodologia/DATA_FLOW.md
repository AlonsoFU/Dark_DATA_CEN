# ğŸ“Š Data Flow - MetodologÃ­a General para Procesamiento de Documentos

## ğŸ¯ Objetivo del Documento

Esta es la **guÃ­a metodolÃ³gica completa** para procesar **CUALQUIER documento nuevo** en la Dark Data Platform. Seguir estos pasos garantiza extraer inteligencia estructurada de cualquier PDF, desde informes financieros hasta manuales tÃ©cnicos.

```
ğŸ“„ Documento PDF â†’ ğŸ” AnÃ¡lisis â†’ ğŸ§© DivisiÃ³n â†’ ğŸ¤– ExtracciÃ³n â†’ âœ‹ ValidaciÃ³n â†’ ğŸ’¾ Base de Datos â†’ ğŸ” AI Queries
```

---

## ğŸš€ **METODOLOGÃA GENERAL - OVERVIEW**

### **Proceso Universal (6 Fases - 2-4 horas total)**

| Fase | Tiempo | DescripciÃ³n | Output |
|------|--------|-------------|--------|
| **1. ObtenciÃ³n** | 15-30 min | Conseguir y organizar documentos | PDF limpio |
| **2. AnÃ¡lisis Estructural** | 30-60 min | Detectar capÃ­tulos, secciones, patrones | Mapa de estructura |
| **3. ExtracciÃ³n Adaptativa** | 45-90 min | Extraer contenido especÃ­fico del documento | Datos estructurados |
| **4. ValidaciÃ³n Manual** | 30-60 min | Revisar y aprobar extracciones crÃ­ticas | Datos validados |
| **5. TransformaciÃ³n Universal** | 15-30 min | Convertir a esquema estÃ¡ndar | JSON universal |
| **6. Ingesta y Acceso AI** | 15-30 min | Cargar a base de datos y activar MCP | AI-queryable |

**Resultado Final**: Documento completamente procesado y disponible para consultas AI

---

## ğŸ“¥ **FASE 1: OBTENCIÃ“N DE DOCUMENTOS** (15-30 minutos)

### Paso 1.1: Determinar Fuente del Documento ğŸ“

**A) Documentos PÃºblicos Online**

**Para documento Ãºnico (descarga simple):**
```bash
wget "https://ejemplo.com/documento.pdf" -O source_document.pdf
```

**Para mÃºltiples documentos del mismo tipo (necesitas scraper):**

1. **Primero verificar si ya existe scraper para el sitio:**
```bash
ls domains/{tu_dominio}/shared/scrapers/
```

2. **Si existe scraper, usarlo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python coordinador_scraper.py --download-latest
```

3. **Si NO existe scraper, crear uno nuevo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python create_scraper.py --target-url "https://ejemplo.com/documentos/"
```

**B) Documentos Privados/Locales**
```bash
mkdir -p domains/{tu_dominio}/data/source_documents/
cp "/ruta/a/tu/documento.pdf" domains/{tu_dominio}/data/source_documents/
```

### Paso 1.2: OrganizaciÃ³n Inicial ğŸ—‚ï¸

**Crear estructura bÃ¡sica para nuevo dominio/documento:**

1. **Crear directorio principal del documento:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/
```

2. **Crear subdirectorios necesarios:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/docs/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/processors/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/outputs/
```

3. **Crear directorio compartido del dominio:**
```bash
mkdir -p domains/{tu_dominio}/shared/
```

**âš ï¸ Importante sobre la estructura de documentos:**
- **La carpeta "chapters/" NO significa que tu documento tenga capÃ­tulos**
- **Es solo organizaciÃ³n**: Cada documento va en su propia carpeta dentro de "chapters/"
- **Tu documento puede ser**:
  - **Documento con capÃ­tulos** (ej: manual de 200 pÃ¡ginas con secciones)
  - **Documento unitario** (ej: contrato de 10 pÃ¡ginas sin divisiones)
  - **Documento con partes** (ej: reporte con introducciÃ³n, anÃ¡lisis, conclusiones)

**Â¿CuÃ¡ndo crear nuevo dominio vs nueva carpeta de documento?**
- **Nuevo dominio**: Ãrea de negocio completamente diferente (ej: legal, financiero, tÃ©cnico)
- **Nueva carpeta**: Mismo dominio, diferente tipo de documento (ej: diferentes reportes financieros)

---

## ğŸ” **FASE 2: ANÃLISIS ESTRUCTURAL** (30-60 minutos)

### Paso 2.1: AnÃ¡lisis AutomÃ¡tico de Estructura ğŸ¤–

**OpciÃ³n A) Intentar herramientas automÃ¡ticas (si existen):**
```bash
python ai_platform/analyzers/document_structure_analyzer.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --output "analysis_result.json"
```

**OpciÃ³n B) AnÃ¡lisis con Claude Code (Recomendado):**

Usar Claude Code para analizar la estructura del documento. **Prompt de ejemplo**:

```
Analiza este documento PDF y determina su estructura:

**1. TIPO DE DOCUMENTO**
- Â¿Es financiero, legal, tÃ©cnico, operacional, acadÃ©mico?
- Â¿CuÃ¡l es su propÃ³sito principal?

**2. ESTRUCTURA GENERAL**
- Â¿Tiene capÃ­tulos/secciones claramente definidos?
- Â¿Es un documento unitario sin divisiones?
- Â¿Hay patrones repetitivos (tablas, listas)?

**3. DIVISIÃ“N LÃ“GICA**
- Si tiene capÃ­tulos: Â¿En quÃ© pÃ¡ginas empiezan y terminan?
- Si es unitario: Â¿QuÃ© secciones lÃ³gicas identificas?

**4. ENTIDADES PRINCIPALES**
- Â¿QuÃ© tipos de datos contiene? (empresas, fechas, mÃ©tricas, etc.)
- Â¿Hay tablas con datos estructurados?
- Â¿QuÃ© informaciÃ³n es mÃ¡s valiosa para extraer?

**5. COMPLEJIDAD DE PROCESAMIENTO**
- Nivel estimado: Simple/Medio/Complejo
- Â¿Requiere OCR especial o es texto seleccionable?

Responde en formato JSON estructurado.
```

âš ï¸ **Nota**: **Adapta este prompt** a tu documento especÃ­fico. Claude Code puede leer PDFs directamente y darte un anÃ¡lisis personalizado.

### Paso 2.2: DivisiÃ³n de CapÃ­tulos/Secciones (Si Aplica) ğŸ“‘

**âš ï¸ Importante**: No todos los documentos tienen capÃ­tulos. Elige la opciÃ³n segÃºn tu documento:

**A) Para Documentos con CapÃ­tulos/Secciones Claras**
(ej: manual tÃ©cnico, reporte extenso, documento acadÃ©mico)

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar detector automÃ¡tico de divisiones:**
```bash
python ai_platform/processors/chapter_divider.py \
  --document "../../../data/source_documents/documento.pdf" \
  --analysis "../../../analysis_result.json" \
  --output "chapter_divisions.json"
```

**B) Para Documentos Unitarios**
(ej: contrato, carta, factura, documento simple)

**Crear archivo de divisiÃ³n simple:**
```bash
echo '{"type": "single_document", "pages": "all"}' > chapter_divisions.json
```

### Paso 2.3: ValidaciÃ³n Manual de DivisiÃ³n âœ‹

**Revisar la divisiÃ³n propuesta:**
```bash
python shared_platform/cli/review_divisions.py --interactive \
  --divisions "chapter_divisions.json" \
  --document "../../../data/source_documents/documento.pdf"
```

**Ejemplo de validaciÃ³n interactiva**:
```
ğŸ” DivisiÃ³n propuesta:
â”œâ”€â”€ CapÃ­tulo 1: PÃ¡ginas 1-15 (IntroducciÃ³n)
â”œâ”€â”€ CapÃ­tulo 2: PÃ¡ginas 16-45 (AnÃ¡lisis Principal)
â”œâ”€â”€ CapÃ­tulo 3: PÃ¡ginas 46-60 (Conclusiones)

Â¿Aprobar esta divisiÃ³n? [y/n/edit]: y
```

---

## ğŸ¤– **FASE 3: EXTRACCIÃ“N ADAPTATIVA** (45-90 minutos)

### Paso 3.1: GeneraciÃ³n de Extractor EspecÃ­fico ğŸ› ï¸

**OpciÃ³n A) Usar herramientas automÃ¡ticas (si existen):**
```bash
python ai_platform/processors/adaptive_document_processor.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --analysis "analysis_result.json" \
  --divisions "chapter_divisions.json" \
  --output-processor "{documento_tipo}_processor.py"
```

**OpciÃ³n B) Crear extractor con Claude Code (Recomendado):**

Pedirle a Claude Code que genere el extractor especÃ­fico. **Prompt de ejemplo**:

```
BasÃ¡ndote en el anÃ¡lisis del documento, crea un extractor Python especÃ­fico:

**CONTEXTO DEL DOCUMENTO**:
- Tipo: [Resultado del anÃ¡lisis anterior]
- Estructura: [DivisiÃ³n encontrada]
- Entidades principales: [Lo que identificaste]

**CREAR EXTRACTOR QUE**:
1. **Extraiga entidades especÃ­ficas** del tipo de documento
2. **Maneje la estructura** (capÃ­tulos o documento unitario)
3. **Valide rangos realistas** para los datos
4. **Normalice nombres** de entidades

**TIPOS DE EXTRACCIÃ“N SEGÃšN DOCUMENTO**:
- **Financiero**: MÃ©tricas, ratios, balances, flujos de caja
- **Legal**: Partes, obligaciones, fechas crÃ­ticas, clausulas
- **TÃ©cnico**: Especificaciones, procedimientos, equipos
- **Operacional**: KPIs, procesos, incidentes, mÃ©tricas

**INCLUIR EN EL CÃ“DIGO**:
- Validaciones especÃ­ficas del dominio
- Manejo de errores
- Logging para debugging
- MÃ©tricas de confianza

Crea el archivo {documento_tipo}_processor.py con el cÃ³digo completo.
```

âš ï¸ **Importante**: Claude Code puede generar el extractor pero **necesitarÃ¡s iterar y personalizar** el cÃ³digo 5-10 veces segÃºn tu documento especÃ­fico.

### Paso 3.2: Primera RevisiÃ³n TÃ©cnica del Extractor ğŸ¯

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar extractor generado:**
```bash
python {documento_tipo}_processor.py \
  --input "../../../data/source_documents/documento.pdf" \
  --output "../outputs/raw_extractions/" \
  --confidence-threshold 0.7
```
ğŸ’¡ **Nota**: TambiÃ©n puedes pedirle a Claude Code que ejecute este comando por ti.

3. **Revisar resultados iniciales:**
```bash
python review_extractions.py --interactive \
  --results "../outputs/raw_extractions/extraction_results.json"
```
ğŸ’¡ **Nota**: Claude Code puede revisar los resultados y hacer la validaciÃ³n interactiva contigo.

**Proceso de calibraciÃ³n tÃ©cnica (repetir 3-8 veces segÃºn complejidad):**

âš ï¸ **Objetivo**: Hacer que el extractor funcione bien tÃ©cnicamente, NO validar cada dato.

1. **Ejecutar extractor en modo prueba:**
```bash
python {documento_tipo}_processor.py --test-mode
```
ğŸ’¡ **Nota**: Claude Code puede ejecutar esto y analizar los resultados.

2. **Identificar problemas especÃ­ficos:**
```bash
python identify_extraction_issues.py
```
ğŸ’¡ **Nota**: Claude Code puede identificar problemas automÃ¡ticamente revisando los outputs.

3. **Refinar cÃ³digo segÃºn problemas encontrados**
   (Esto requiere ediciÃ³n manual del processor)

4. **Medir confianza actual:**
```bash
confidence=$(python measure_confidence.py)
echo "Confianza actual: $confidence"
```
ğŸ’¡ **Nota**: Claude Code puede calcular mÃ©tricas de confianza automÃ¡ticamente.

5. **Repetir hasta lograr >85% confianza**

### Paso 3.3: GeneraciÃ³n de Metadatos y Tags ğŸ·ï¸

**OpciÃ³n A) Herramientas automÃ¡ticas:**
```bash
python ai_platform/processors/metadata_generator.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/raw_extractions/" \
  --output "../outputs/enriched_metadata.json"
```

**OpciÃ³n B) Generar metadatos con Claude Code (Recomendado):**

Pedirle a Claude Code que genere metadatos especÃ­ficos. **Prompt de ejemplo**:

```
Analiza los datos extraÃ­dos y genera metadatos enriquecidos:

**GENERAR TAGS PARA**:
1. **Tags SemÃ¡nticos**: Conceptos clave, temas principales
2. **Tags Temporales**: PerÃ­odos, fechas relevantes, vigencia
3. **Tags GeogrÃ¡ficos**: PaÃ­ses, regiones, ciudades mencionadas
4. **Tags de Entidades**: Personas, organizaciones, productos
5. **Tags de ClasificaciÃ³n**: Tipo, propÃ³sito, audiencia objetivo

**TAGS ESPECÃFICOS SEGÃšN DOMINIO**:
- **Financiero**: ratios, mÃ©tricas, perÃ­odos fiscales, instrumentos
- **Legal**: tipo_contrato, jurisdicciÃ³n, obligaciones, derechos
- **TÃ©cnico**: especificaciones, normas, procedimientos, equipos
- **Operacional**: KPIs, procesos, departamentos, mÃ©tricas

**IDENTIFICAR REFERENCIAS CRUZADAS**:
- Entidades que podrÃ­an aparecer en otros documentos
- PerÃ­odos temporales relevantes
- Organizaciones mencionadas
- Temas relacionados

Crea el archivo enriched_metadata.json con los metadatos estructurados.
```

âš ï¸ **Nota**: Claude Code puede generar metadatos automÃ¡ticamente, pero **revisa y personaliza** segÃºn el contexto especÃ­fico de tu documento.

---

## âœ‹ **FASE 4: VALIDACIÃ“N MANUAL** (30-60 minutos)

âš ï¸ **Diferencia clave con Fase 3.2**:
- **Paso 3.2**: Primera revisiÃ³n **tÃ©cnica** - Â¿funciona bien el extractor?
- **Paso 4.1**: RevisiÃ³n **de contenido** - Â¿son correctos estos datos especÃ­ficos?

### Paso 4.1: RevisiÃ³n Final de Contenido (ValidaciÃ³n Humana) ğŸ”

âš ï¸ **Objetivo**: Validar cada dato extraÃ­do individualmente - Â¿es correcto este resultado especÃ­fico?

```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/cli/validation_interface.py \
  --data "outputs/raw_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --interactive
```
ğŸ’¡ **Nota**: Claude Code puede hacer toda la validaciÃ³n conversacionalmente contigo, revisando cada extracciÃ³n.

**Interfaz de validaciÃ³n tÃ­pica**:
```
ğŸ” ExtracciÃ³n #1 - Empresa XYZ S.A.
â”œâ”€â”€ Tipo: OrganizaciÃ³n
â”œâ”€â”€ UbicaciÃ³n: Santiago, Chile
â”œâ”€â”€ Sector: EnergÃ­a
â”œâ”€â”€ MÃ©trica asociada: 150 MW capacidad
â”œâ”€â”€ Confianza IA: 0.89
â”œâ”€â”€ Tags: [energia, chile, capacidad_instalpada]

Â¿Aprobar esta extracciÃ³n? [y/n/edit/skip]:
- y: Aprobar como estÃ¡
- n: Rechazar completamente
- edit: Corregir datos
- skip: Revisar despuÃ©s

SelecciÃ³n: edit
â”œâ”€â”€ CorrecciÃ³n: Cambiar "150 MW" â†’ "150.5 MW"
â”œâ”€â”€ Tag adicional: "solar_energy"
âœ… Guardado
```

### Paso 4.2: Control de Calidad por Lotes ğŸ“Š

```bash
python shared_platform/cli/quality_checker.py \
  --validated-data "outputs/validated_extractions/" \
  --original-document "../../../data/source_documents/documento.pdf" \
  --generate-report
```
ğŸ’¡ **Nota**: Claude Code puede generar reportes de calidad automÃ¡ticamente.

**MÃ©tricas de calidad generadas**:
```
ğŸ“Š Reporte de Calidad:
â”œâ”€â”€ PÃ¡ginas procesadas: 45/45 (100%)
â”œâ”€â”€ Entidades extraÃ­das: 127
â”œâ”€â”€ Entidades validadas: 119 (93.7%)
â”œâ”€â”€ Entidades rechazadas: 8 (6.3%)
â”œâ”€â”€ Confianza promedio: 0.91
â”œâ”€â”€ Tiempo total: 42 minutos
â””â”€â”€ Status: âœ… APTO PARA PRODUCCIÃ“N
```

### Paso 4.3: GeneraciÃ³n de Referencias Cruzadas ğŸ”—

**OpciÃ³n A) Herramientas automÃ¡ticas:**
```bash
python ai_platform/processors/cross_reference_generator.py \
  --current-document "outputs/validated_extractions/" \
  --database "platform_data/database/dark_data.db" \
  --output "outputs/cross_references.json"
```

**OpciÃ³n B) Detectar referencias con Claude Code (Recomendado):**

Pedirle a Claude Code que identifique referencias cruzadas. **Prompt de ejemplo**:

```
Analiza los datos validados e identifica referencias cruzadas potenciales:

**BUSCAR RELACIONES**:
1. **Entidad IdÃ©ntica**: Misma empresa/persona en otros documentos
2. **Temporal**: Documentos del mismo perÃ­odo o fechas relacionadas
3. **GeogrÃ¡fica**: Misma ubicaciÃ³n/regiÃ³n/paÃ­s
4. **TemÃ¡tica**: Mismo sector/industria/tema
5. **Funcional**: Documentos que se complementan

**ASIGNAR CONFIANZA**:
- 0.95+: PrÃ¡cticamente certeza (nombre exacto + contexto)
- 0.85-0.94: Alta confianza (variaciones menores)
- 0.70-0.84: Confianza media (contexto similar)
- <0.70: Baja confianza (solo sugerencia)

**PRIORIZAR**:
- Referencias que agreguen valor business
- Evitar conexiones triviales
- Incluir razÃ³n de la relaciÃ³n

Consulta la base de datos dark_data.db y crea cross_references.json con las relaciones encontradas.
```

âš ï¸ **Importante**: Claude Code puede acceder a la base de datos y **detectar referencias automÃ¡ticamente**, pero siempre valida manualmente las mÃ¡s importantes.

---

## ğŸ’¾ **FASE 5: TRANSFORMACIÃ“N UNIVERSAL** (15-30 minutos)

### Paso 5.1: AplicaciÃ³n del Esquema Universal ğŸ”„

**OpciÃ³n A) Transformador automÃ¡tico (si existe):**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/transformers/universal_schema_transformer.py \
  --input "outputs/validated_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --cross-refs "outputs/cross_references.json" \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --output "outputs/universal_json/"
```

**OpciÃ³n B) TransformaciÃ³n con Claude Code (Recomendado):**

âš ï¸ **Importante**: Cada documento tiene salidas diferentes. Claude Code puede crear la transformaciÃ³n especÃ­fica.

**Prompt de ejemplo para transformaciÃ³n especÃ­fica**:

```
Transforma los datos extraÃ­dos al esquema universal de la plataforma:

**DATOS DE ENTRADA**:
- Extracciones validadas: [contenido especÃ­fico de tu documento]
- Metadatos: [tags y referencias de tu documento]
- Cross-referencias: [relaciones encontradas]

**ESQUEMA UNIVERSAL OBJETIVO**:
```json
{
  "@context": "https://darkdata.platform/context/v1",
  "@id": "ddp:{dominio}:{documento_tipo}:{fecha}",
  "@type": "ProcessedDocument",

  "document_metadata": {
    "document_id": "Ãºnico_identificador",
    "document_type": "{documento_tipo}",
    "domain": "{tu_dominio}",
    "source_file": "nombre_original.pdf",
    "processing_date": "2025-09-26T10:30:00Z",
    "extraction_version": "1.0",
    "quality_score": 0.91
  },

  "extracted_entities": {
    "organizations": [...],
    "people": [...],
    "locations": [...],
    "dates": [...],
    "metrics": [...],
    "domain_specific": {...}
  },

  "semantic_tags": {
    "universal_tags": ["tag1", "tag2"],
    "domain_tags": ["domain_tag1"],
    "temporal_tags": ["2025", "Q3"],
    "geographic_tags": ["chile", "santiago"]
  },

  "cross_references": [
    {
      "target_document": "ddp:otro_dominio:otro_doc:fecha",
      "relationship_type": "SAME_ENTITY",
      "confidence": 0.95,
      "context": "DescripciÃ³n de la relaciÃ³n"
    }
  ]
}
```

**TAREA ESPECÃFICA**:
1. **Mapea las entidades extraÃ­das** de tu documento a las categorÃ­as universales
2. **Adapta los datos especÃ­ficos** de tu dominio al campo "domain_specific"
3. **Normaliza los metadatos** segÃºn el esquema universal
4. **Conserva la informaciÃ³n original** pero en formato estÃ¡ndar

Crea el archivo universal_schema.json con la transformaciÃ³n completa.
```

ğŸ’¡ **Ventajas de Claude Code para TransformaciÃ³n Universal**:
- **Entiende esquemas complejos**: Puede mapear datos especÃ­ficos a formato universal
- **AdaptaciÃ³n automÃ¡tica**: Se ajusta a la estructura especÃ­fica de tu documento
- **Preserva informaciÃ³n**: No pierde datos importantes en la transformaciÃ³n
- **ValidaciÃ³n**: Verifica que la transformaciÃ³n sea correcta
- **Iterativo**: Puedes refinar la transformaciÃ³n hasta que sea perfecta

âš ï¸ **Por quÃ© es crÃ­tico**: Cada tipo de documento (financiero, legal, tÃ©cnico) tiene estructura diferente, pero necesita transformarse al mismo esquema universal para que la plataforma AI pueda consultarlo consistentemente.

---

## ğŸ—„ï¸ **FASE 6: INGESTA Y ACCESO AI** (15-30 minutos)

### Paso 6.1: Ingesta a Base de Datos ğŸ“Š

```bash
make setup-db  # Si es primera vez
python shared_platform/database_tools/ingest_data.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/universal_json/" \
  --update-schema-if-needed \
  --validate-integrity
```
ğŸ’¡ **Nota**: Claude Code puede ejecutar estos comandos y manejar toda la ingesta a la base de datos.

### Paso 6.2: ActivaciÃ³n de Acceso AI ğŸ¤–

```bash
make run-mcp  # Servidor principal

# Servidor especÃ­fico del dominio (si existe)
cd ai_platform/mcp_servers/
python {tu_dominio}_server.py  # ej: operaciones_server.py
```
ğŸ’¡ **Nota**: Claude Code puede activar los servidores MCP y ya tienes acceso directo a los datos.

### Paso 6.3: VerificaciÃ³n Final âœ…

```bash
python shared_platform/cli/test_ai_queries.py \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --sample-queries "prompts/testing/sample_queries.md"
```
ğŸ’¡ **Nota**: Con Claude Code ya puedes hacer consultas directamente sin scripts adicionales.

**Consultas de prueba tÃ­picas**:
```markdown
# Consultas bÃ¡sicas para verificar funcionamiento
"Â¿CuÃ¡ntas entidades se extrajeron de este documento?"
"Lista las 5 organizaciones principales mencionadas"
"Â¿QuÃ© referencias cruzadas se encontraron?"
"Muestra un resumen de los tags semÃ¡nticos"
```

---

## ğŸ“‹ **RESUMEN METODOLÃ“GICO**

### âœ… **Checklist Completo para Nuevo Documento**

```bash
# 1. OBTENCIÃ“N (15-30 min)
[ ] Documento descargado/copiado
[ ] Estructura de carpetas creada
[ ] Dominio y tipo definidos

# 2. ANÃLISIS ESTRUCTURAL (30-60 min)
[ ] AnÃ¡lisis automÃ¡tico ejecutado (Prompt #1)
[ ] DivisiÃ³n de capÃ­tulos completada
[ ] Estructura validada manualmente

# 3. EXTRACCIÃ“N ADAPTATIVA (45-90 min)
[ ] Extractor especÃ­fico generado (Prompt #2)
[ ] Extractor calibrado (>85% confianza)
[ ] Metadatos generados (Prompt #3)

# 4. VALIDACIÃ“N MANUAL (30-60 min)
[ ] Extracciones revisadas interactivamente
[ ] Control de calidad aprobado
[ ] Referencias cruzadas generadas (Prompt #4)

# 5. TRANSFORMACIÃ“N UNIVERSAL (15-30 min)
[ ] Esquema universal aplicado
[ ] JSON vÃ¡lido generado
[ ] Metadatos completos

# 6. INGESTA Y ACCESO AI (15-30 min)
[ ] Datos ingresados a base de datos
[ ] Servidores MCP activados
[ ] Consultas AI funcionando
```

### ğŸ¯ **Tiempo Total Estimado por Complejidad**

| Tipo de Documento | Tiempo Total | Iteraciones | Dificultad |
|-------------------|--------------|-------------|------------|
| **Simple** (1-20 pÃ¡ginas, estructura clara) | 2-3 horas | 3-5 | â­â­ |
| **Medio** (20-100 pÃ¡ginas, mÃºltiples secciones) | 3-4 horas | 5-8 | â­â­â­ |
| **Complejo** (100+ pÃ¡ginas, estructura irregular) | 4-6 horas | 8-12 | â­â­â­â­ |

### ğŸ› ï¸ **Herramientas Disponibles**

**ğŸ¤– Herramienta Principal: Claude Code**
- Puede realizar todas las fases de la metodologÃ­a
- Acceso directo a PDFs, base de datos y archivos
- ConversaciÃ³n natural para iteraciÃ³n y mejora
- GeneraciÃ³n de cÃ³digo especÃ­fico por documento

**âš™ï¸ Herramientas AutomÃ¡ticas (Opcionales)**:
```
ai_platform/
â”œâ”€â”€ analyzers/document_structure_analyzer.py     # AnÃ¡lisis automÃ¡tico
â”œâ”€â”€ processors/adaptive_document_processor.py   # ExtracciÃ³n adaptativa
â”œâ”€â”€ processors/metadata_generator.py            # GeneraciÃ³n de metadatos
â””â”€â”€ processors/cross_reference_generator.py     # Referencias cruzadas

shared_platform/
â”œâ”€â”€ cli/validation_interface.py                 # ValidaciÃ³n interactiva
â”œâ”€â”€ cli/quality_checker.py                      # Control de calidad
â”œâ”€â”€ transformers/universal_schema_transformer.py # TransformaciÃ³n universal
â””â”€â”€ database_tools/ingest_data.py              # Ingesta a base de datos
```

### ğŸ’¡ **MetodologÃ­a con Claude Code**

**ğŸ¯ Enfoque Principal: Usar Claude Code para todo el procesamiento**

La metodologÃ­a estÃ¡ diseÃ±ada para trabajar principalmente con **Claude Code**:

- **ğŸ“„ Lectura directa de PDFs**: Claude Code puede leer documentos directamente
- **ğŸ¤– AnÃ¡lisis inteligente**: AnÃ¡lisis de estructura con conversaciÃ³n natural
- **ğŸ’» GeneraciÃ³n de cÃ³digo**: CreaciÃ³n de extractores Python personalizados
- **ğŸ” ValidaciÃ³n interactiva**: RevisiÃ³n manual con Claude Code
- **ğŸ”— Referencias cruzadas**: Acceso a base de datos para correlaciones
- **ğŸ“Š TransformaciÃ³n**: ConversiÃ³n a esquemas universales

### ğŸ“ **Prompts de Ejemplo Incluidos**

Los prompts mostrados en cada fase son **ejemplos de conversaciÃ³n con Claude Code**:

- **FASE 2**: AnÃ¡lisis de estructura de documentos
- **FASE 3**: GeneraciÃ³n de extractores y metadatos
- **FASE 4**: DetecciÃ³n de referencias cruzadas

âš ï¸ **Importante sobre la MetodologÃ­a**:
- **Claude Code es la herramienta principal** para todo el procesamiento
- Los scripts automÃ¡ticos son **opcionales** (OpciÃ³n A en cada fase)
- **Los prompts son ejemplos** de cÃ³mo hablar con Claude Code
- **Personaliza la conversaciÃ³n** segÃºn tu documento especÃ­fico
- **Claude Code puede iterar** contigo hasta lograr resultados perfectos

---

## ğŸ¯ **Casos de Uso Validados**

### ğŸ“ˆ **Documentos Financieros**
- **Estados de resultados, balances, flujos de caja**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades tÃ­picas**: MÃ©tricas financieras, ratios, comparativos

### ğŸ“‹ **Documentos Legales**
- **Contratos, acuerdos, polÃ­ticas corporativas**
- **Tiempo promedio**: 3-4 horas
- **Entidades tÃ­picas**: Partes, obligaciones, fechas crÃ­ticas

### ğŸ”§ **Documentos TÃ©cnicos**
- **Manuales, especificaciones, procedimientos**
- **Tiempo promedio**: 3.5-4.5 horas
- **Entidades tÃ­picas**: Especificaciones, equipos, normas

### âš¡ **Documentos Operacionales**
- **Reportes de operaciones, KPIs, anÃ¡lisis de rendimiento**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades tÃ­picas**: MÃ©tricas, procesos, incidentes

---

## ğŸ“ **ESTRUCTURA FINAL COMPLETA DEL DOCUMENTO PROCESADO**

### ğŸ¯ **Â¿CÃ³mo queda organizado todo despuÃ©s del procesamiento?**

Una vez completada la metodologÃ­a, esta es la **estructura genÃ©rica** que tendrÃ¡s para cualquier documento procesado:

```
domains/{tu_dominio}/
â”‚
â”œâ”€â”€ chapters/{documento_tipo}/                  # Procesamiento especÃ­fico del documento
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ docs/                                # DocumentaciÃ³n del procesamiento
â”‚   â”‚   â”œâ”€â”€ README.md                           # Resumen del documento y procesamiento
â”‚   â”‚   â”œâ”€â”€ patterns.json                       # Patrones de extracciÃ³n identificados
â”‚   â”‚   â”œâ”€â”€ cross_references.json               # Referencias cruzadas detectadas
â”‚   â”‚   â”œâ”€â”€ processing_notes.md                 # Notas del proceso y lecciones aprendidas
â”‚   â”‚   â””â”€â”€ validation_report.md                # Reporte de validaciÃ³n manual
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ processors/                          # CÃ³digo de procesamiento
â”‚   â”‚   â”œâ”€â”€ {documento_tipo}_processor.py       # Extractor principal generado
â”‚   â”‚   â”œâ”€â”€ metadata_generator.py               # Generador de metadatos especÃ­fico
â”‚   â”‚   â”œâ”€â”€ validation_rules.py                 # Reglas de validaciÃ³n personalizadas
â”‚   â”‚   â””â”€â”€ quality_checker.py                  # Verificador de calidad especÃ­fico
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š outputs/                             # Todas las salidas del procesamiento
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ” raw_extractions/                 # Extracciones iniciales sin validar
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction_results.json         # Datos extraÃ­dos por el processor
â”‚   â”‚   â”‚   â”œâ”€â”€ confidence_metrics.json         # MÃ©tricas de confianza por entidad
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction_log.txt              # Log detallado del procesamiento
â”‚   â”‚   â”‚   â””â”€â”€ failed_extractions.json         # Intentos fallidos con razones
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ âœ… validated_extractions/           # Datos validados manualmente
â”‚   â”‚   â”‚   â”œâ”€â”€ approved_entities.json          # Entidades aprobadas por humano
â”‚   â”‚   â”‚   â”œâ”€â”€ corrected_data.json             # Datos corregidos manualmente
â”‚   â”‚   â”‚   â”œâ”€â”€ rejected_entities.json          # Entidades rechazadas con razones
â”‚   â”‚   â”‚   â”œâ”€â”€ validation_summary.json         # Resumen de validaciÃ³n
â”‚   â”‚   â”‚   â””â”€â”€ quality_report.json             # Reporte final de calidad
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ·ï¸ enriched_metadata/               # Metadatos y tags generados
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_tags.json              # Tags semÃ¡nticos del documento
â”‚   â”‚   â”‚   â”œâ”€â”€ temporal_tags.json              # Tags temporales (fechas, perÃ­odos)
â”‚   â”‚   â”‚   â”œâ”€â”€ geographic_tags.json            # Tags geogrÃ¡ficos identificados
â”‚   â”‚   â”‚   â”œâ”€â”€ business_tags.json              # Tags de negocio especÃ­ficos
â”‚   â”‚   â”‚   â””â”€â”€ cross_references.json           # Referencias a otros documentos
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸŒ universal_json/                  # Formato final para base de datos
â”‚   â”‚       â”œâ”€â”€ universal_schema.json           # Documento en esquema universal
â”‚   â”‚       â”œâ”€â”€ document_metadata.json          # Metadatos completos del documento
â”‚   â”‚       â”œâ”€â”€ extracted_entities.json         # Entidades en formato estÃ¡ndar
â”‚   â”‚       â”œâ”€â”€ semantic_tags.json              # Tags normalizados
â”‚   â”‚       â”œâ”€â”€ cross_references.json           # Referencias cruzadas finales
â”‚   â”‚       â””â”€â”€ quality_metrics.json            # MÃ©tricas finales de calidad
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”„ universal_schema_adapters/           # Transformadores de esquema
â”‚   â”‚   â”œâ”€â”€ {documento_tipo}_adapter.py         # Adaptador especÃ­fico del documento
â”‚   â”‚   â”œâ”€â”€ entity_normalizer.py                # Normalizador de entidades
â”‚   â”‚   â”œâ”€â”€ tag_mapper.py                       # Mapeador de tags al formato universal
â”‚   â”‚   â””â”€â”€ cross_reference_detector.py         # Detector de referencias cruzadas
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‹ logs/                                # Registros del procesamiento
â”‚       â”œâ”€â”€ processing_log.txt                  # Log completo del procesamiento
â”‚       â”œâ”€â”€ validation_decisions.txt            # Decisiones de validaciÃ³n manual
â”‚       â”œâ”€â”€ error_log.txt                       # Errores encontrados y resueltos
â”‚       â””â”€â”€ performance_metrics.json            # MÃ©tricas de tiempo y rendimiento
â”‚
â””â”€â”€ ğŸŒ shared/                                  # Recursos compartidos del dominio
    â”‚
    â”œâ”€â”€ ğŸ“Š data/                                # Datos compartidos del dominio
    â”‚   â”œâ”€â”€ source_documents/                   # Documentos PDF originales
    â”‚   â”‚   â”œâ”€â”€ documento1.pdf                  # PDFs sin procesar
    â”‚   â”‚   â”œâ”€â”€ documento2.pdf
    â”‚   â”‚   â””â”€â”€ backup_documents/               # Respaldos de documentos
    â”‚   â”‚
    â”‚   â”œâ”€â”€ master_databases/                   # Bases de datos maestras
    â”‚   â”‚   â”œâ”€â”€ entities_catalog.json           # CatÃ¡logo de entidades del dominio
    â”‚   â”‚   â”œâ”€â”€ organizations_registry.json     # Registro de organizaciones
    â”‚   â”‚   â””â”€â”€ validated_patterns.json         # Patrones validados del dominio
    â”‚   â”‚
    â”‚   â””â”€â”€ reference_materials/                # Materiales de referencia
    â”‚       â”œâ”€â”€ domain_glossary.json            # Glosario de tÃ©rminos del dominio
    â”‚       â”œâ”€â”€ business_rules.json             # Reglas de negocio especÃ­ficas
    â”‚       â””â”€â”€ quality_standards.json          # EstÃ¡ndares de calidad
    â”‚
    â”œâ”€â”€ ğŸ”§ utilities/                           # Utilidades compartidas
    â”‚   â”œâ”€â”€ universal_schema_adapters/          # Adaptadores universales del dominio
    â”‚   â”‚   â”œâ”€â”€ esquema_universal_{dominio}.py  # Esquema universal del dominio
    â”‚   â”‚   â”œâ”€â”€ extractor_universal_integrado.py # Transformador universal
    â”‚   â”‚   â””â”€â”€ referencias_cruzadas.py         # Detector de referencias del dominio
    â”‚   â”‚
    â”‚   â”œâ”€â”€ common_processors/                  # Procesadores comunes
    â”‚   â”‚   â”œâ”€â”€ entity_extractor.py             # Extractor genÃ©rico de entidades
    â”‚   â”‚   â”œâ”€â”€ date_normalizer.py              # Normalizador de fechas
    â”‚   â”‚   â”œâ”€â”€ currency_converter.py           # Convertidor de monedas
    â”‚   â”‚   â””â”€â”€ text_cleaner.py                 # Limpiador de texto
    â”‚   â”‚
    â”‚   â””â”€â”€ validation_tools/                   # Herramientas de validaciÃ³n
    â”‚       â”œâ”€â”€ quality_checker.py              # Verificador de calidad genÃ©rico
    â”‚       â”œâ”€â”€ consistency_validator.py        # Validador de consistencia
    â”‚       â””â”€â”€ completeness_checker.py         # Verificador de completitud
    â”‚
    â”œâ”€â”€ ğŸ•·ï¸ scrapers/                            # Web scrapers del dominio
    â”‚   â”œâ”€â”€ {dominio}_base_scraper.py           # Scraper base del dominio
    â”‚   â”œâ”€â”€ site_specific_scrapers/             # Scrapers especÃ­ficos de sitios
    â”‚   â”‚   â”œâ”€â”€ coordinador_cl_scraper.py       # Ejemplo: scraper Coordinador
    â”‚   â”‚   â”œâ”€â”€ cne_cl_scraper.py               # Ejemplo: scraper CNE
    â”‚   â”‚   â””â”€â”€ sii_cl_scraper.py               # Ejemplo: scraper SII
    â”‚   â”‚
    â”‚   â””â”€â”€ scraper_configs/                    # Configuraciones de scrapers
    â”‚       â”œâ”€â”€ urls_catalog.json               # CatÃ¡logo de URLs del dominio
    â”‚       â”œâ”€â”€ scraping_rules.json             # Reglas de web scraping
    â”‚       â””â”€â”€ update_schedules.json           # ProgramaciÃ³n de actualizaciones
    â”‚
    â”œâ”€â”€ ğŸ” chapter_detection/                   # Herramientas de detecciÃ³n de capÃ­tulos
    â”‚   â”œâ”€â”€ interactive_title_detector.py       # Detector interactivo de tÃ­tulos
    â”‚   â”œâ”€â”€ interactive_chapter_mapper.py       # Mapeador interactivo de capÃ­tulos
    â”‚   â”œâ”€â”€ find_all_document_titles.py         # Buscador automÃ¡tico de tÃ­tulos
    â”‚   â””â”€â”€ chapter_definitions.json            # Definiciones de capÃ­tulos validadas
    â”‚
    â”œâ”€â”€ ğŸ“‹ schemas/                             # Esquemas y patrones del dominio
    â”‚   â”œâ”€â”€ extraction_patterns.json            # Patrones de extracciÃ³n comunes
    â”‚   â”œâ”€â”€ validation_schemas.json             # Esquemas de validaciÃ³n
    â”‚   â”œâ”€â”€ cross_reference_rules.json          # Reglas de referencias cruzadas
    â”‚   â””â”€â”€ domain_ontology.json                # OntologÃ­a del dominio
    â”‚
    â”œâ”€â”€ ğŸ› ï¸ tools/                               # Herramientas del dominio
    â”‚   â”œâ”€â”€ migration_tools/                    # Herramientas de migraciÃ³n
    â”‚   â”‚   â”œâ”€â”€ fix_all_paths.py                # Corrector de rutas
    â”‚   â”‚   â”œâ”€â”€ reorganize_structure.py         # Reorganizador de estructura
    â”‚   â”‚   â””â”€â”€ test_migration_success.py       # Tester de migraciÃ³n
    â”‚   â”‚
    â”‚   â”œâ”€â”€ analysis_tools/                     # Herramientas de anÃ¡lisis
    â”‚   â”‚   â”œâ”€â”€ pattern_analyzer.py             # Analizador de patrones
    â”‚   â”‚   â”œâ”€â”€ quality_reporter.py             # Reportero de calidad
    â”‚   â”‚   â””â”€â”€ performance_profiler.py         # Perfilador de rendimiento
    â”‚   â”‚
    â”‚   â””â”€â”€ maintenance_tools/                  # Herramientas de mantenimiento
    â”‚       â”œâ”€â”€ database_cleaner.py             # Limpiador de base de datos
    â”‚       â”œâ”€â”€ log_analyzer.py                 # Analizador de logs
    â”‚       â””â”€â”€ health_checker.py               # Verificador de salud del sistema
    â”‚
    â””â”€â”€ ğŸ“š validated_results/                   # Resultados validados por usuarios
        â”œâ”€â”€ master_validated_titles.json        # TÃ­tulos validados manualmente
        â”œâ”€â”€ approved_entities_catalog.json      # CatÃ¡logo de entidades aprobadas
        â”œâ”€â”€ validated_cross_references.json     # Referencias cruzadas validadas
        â””â”€â”€ quality_benchmarks.json             # Benchmarks de calidad establecidos
```

### **ğŸ“Š Ejemplo Real: Estructura de Contrato de Servicios de TI**

```
domains/legal/
â”‚
â”œâ”€â”€ chapters/contrato_servicios_ti/             # Procesamiento especÃ­fico del contrato
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ docs/
â”‚   â”‚   â”œâ”€â”€ README.md                           # "Contrato DevCorp-TechSolutions procesado"
â”‚   â”‚   â”œâ”€â”€ patterns.json                       # Patrones de contratos de TI identificados
â”‚   â”‚   â”œâ”€â”€ cross_references.json               # Relaciones con otros contratos de DevCorp
â”‚   â”‚   â”œâ”€â”€ processing_notes.md                 # "2h 45min, 18 entidades, 94% validaciÃ³n"
â”‚   â”‚   â””â”€â”€ validation_report.md                # Reporte de 1 correcciÃ³n manual
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ processors/
â”‚   â”‚   â”œâ”€â”€ contrato_servicios_ti_processor.py  # Extractor para contratos de TI
â”‚   â”‚   â”œâ”€â”€ metadata_generator.py               # Generador de tags contractuales
â”‚   â”‚   â”œâ”€â”€ validation_rules.py                 # Validaciones especÃ­ficas de contratos
â”‚   â”‚   â””â”€â”€ quality_checker.py                  # Verificador de calidad legal
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š outputs/
â”‚   â”‚   â”œâ”€â”€ ğŸ” raw_extractions/
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction_results.json         # 18 entidades extraÃ­das inicialmente
â”‚   â”‚   â”‚   â”œâ”€â”€ confidence_metrics.json         # Confianza 0.85-0.98 por entidad
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction_log.txt              # "Procesamiento 75 minutos, 2 iteraciones"
â”‚   â”‚   â”‚   â””â”€â”€ failed_extractions.json         # 3 intentos fallidos de fechas
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ âœ… validated_extractions/
â”‚   â”‚   â”‚   â”œâ”€â”€ approved_entities.json          # 17 entidades aprobadas
â”‚   â”‚   â”‚   â”œâ”€â”€ corrected_data.json             # 1 monto corregido USD 185,000
â”‚   â”‚   â”‚   â”œâ”€â”€ rejected_entities.json          # 0 entidades rechazadas
â”‚   â”‚   â”‚   â”œâ”€â”€ validation_summary.json         # 94% tasa de aprobaciÃ³n
â”‚   â”‚   â”‚   â””â”€â”€ quality_report.json             # "Apto para producciÃ³n"
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ·ï¸ enriched_metadata/
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_tags.json              # ["contrato", "servicios", "tecnologia"]
â”‚   â”‚   â”‚   â”œâ”€â”€ temporal_tags.json              # ["2025", "anual", "multifase"]
â”‚   â”‚   â”‚   â”œâ”€â”€ geographic_tags.json            # ["chile", "estados_unidos"]
â”‚   â”‚   â”‚   â”œâ”€â”€ business_tags.json              # ["devcorp", "techsolutions"]
â”‚   â”‚   â”‚   â””â”€â”€ cross_references.json           # 2 referencias a otros contratos
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸŒ universal_json/
â”‚   â”‚       â”œâ”€â”€ universal_schema.json           # Esquema JSON-LD completo
â”‚   â”‚       â”œâ”€â”€ document_metadata.json          # "legal_contrato_devcorp_2025"
â”‚   â”‚       â”œâ”€â”€ extracted_entities.json         # Organizaciones, fechas, mÃ©tricas
â”‚   â”‚       â”œâ”€â”€ semantic_tags.json              # Tags normalizados para AI
â”‚   â”‚       â”œâ”€â”€ cross_references.json           # Referencias para consultas AI
â”‚   â”‚       â””â”€â”€ quality_metrics.json            # Confianza 0.94, validaciÃ³n humana
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”„ universal_schema_adapters/
â”‚   â”‚   â”œâ”€â”€ contrato_servicios_ti_adapter.py    # Transformador legalâ†’universal
â”‚   â”‚   â”œâ”€â”€ entity_normalizer.py                # Normalizador de entidades legales
â”‚   â”‚   â”œâ”€â”€ tag_mapper.py                       # Mapeador tags legalesâ†’universales
â”‚   â”‚   â””â”€â”€ cross_reference_detector.py         # Detector referencias legales
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‹ logs/
â”‚       â”œâ”€â”€ processing_log.txt                  # "2h 45min total, 94% validaciÃ³n"
â”‚       â”œâ”€â”€ validation_decisions.txt            # "Usuario corrigiÃ³ monto lÃ­nea 142"
â”‚       â”œâ”€â”€ error_log.txt                       # "Problema parser fechas resuelto"
â”‚       â””â”€â”€ performance_metrics.json            # MÃ©tricas detalladas de rendimiento
â”‚
â””â”€â”€ ğŸŒ shared/                                  # Recursos compartidos del dominio legal
    â”‚
    â”œâ”€â”€ ğŸ“Š data/
    â”‚   â”œâ”€â”€ source_documents/                   # PDFs legales originales
    â”‚   â”‚   â”œâ”€â”€ Contrato_DevCorp_2025.pdf       # Contrato procesado
    â”‚   â”‚   â”œâ”€â”€ Contrato_AcmeCorp_2025.pdf      # Otros contratos del dominio
    â”‚   â”‚   â””â”€â”€ backup_documents/               # Respaldos de contratos
    â”‚   â”‚
    â”‚   â”œâ”€â”€ master_databases/
    â”‚   â”‚   â”œâ”€â”€ entities_catalog.json           # "DevCorp S.A.", "TechSolutions Ltd."
    â”‚   â”‚   â”œâ”€â”€ organizations_registry.json     # Registro de empresas legales
    â”‚   â”‚   â””â”€â”€ validated_patterns.json         # Patrones de contratos validados
    â”‚   â”‚
    â”‚   â””â”€â”€ reference_materials/
    â”‚       â”œâ”€â”€ domain_glossary.json            # Glosario jurÃ­dico
    â”‚       â”œâ”€â”€ business_rules.json             # Reglas legales chilenas
    â”‚       â””â”€â”€ quality_standards.json          # EstÃ¡ndares de calidad legal
    â”‚
    â”œâ”€â”€ ğŸ”§ utilities/
    â”‚   â”œâ”€â”€ universal_schema_adapters/
    â”‚   â”‚   â”œâ”€â”€ esquema_universal_legal.py      # Esquema universal legal
    â”‚   â”‚   â”œâ”€â”€ extractor_universal_integrado.py # Transformador universal legal
    â”‚   â”‚   â””â”€â”€ referencias_cruzadas.py         # Referencias entre contratos
    â”‚   â”‚
    â”‚   â”œâ”€â”€ common_processors/
    â”‚   â”‚   â”œâ”€â”€ entity_extractor.py             # Extractor de partes contractuales
    â”‚   â”‚   â”œâ”€â”€ date_normalizer.py              # Normalizador de fechas legales
    â”‚   â”‚   â”œâ”€â”€ currency_converter.py           # Convertidor USD/CLP/EUR
    â”‚   â”‚   â””â”€â”€ text_cleaner.py                 # Limpiador de texto legal
    â”‚   â”‚
    â”‚   â””â”€â”€ validation_tools/
    â”‚       â”œâ”€â”€ quality_checker.py              # Verificador calidad documentos legales
    â”‚       â”œâ”€â”€ consistency_validator.py        # Validador consistencia contractual
    â”‚       â””â”€â”€ completeness_checker.py         # Verificador completitud legal
    â”‚
    â”œâ”€â”€ ğŸ•·ï¸ scrapers/
    â”‚   â”œâ”€â”€ legal_base_scraper.py               # Scraper base para sitios legales
    â”‚   â”œâ”€â”€ site_specific_scrapers/
    â”‚   â”‚   â”œâ”€â”€ sii_cl_scraper.py               # Scraper SII para datos fiscales
    â”‚   â”‚   â”œâ”€â”€ conservador_cl_scraper.py       # Scraper Conservador de Bienes RaÃ­ces
    â”‚   â”‚   â””â”€â”€ registros_cl_scraper.py         # Scraper Registro Civil
    â”‚   â”‚
    â”‚   â””â”€â”€ scraper_configs/
    â”‚       â”œâ”€â”€ urls_catalog.json               # URLs de sitios legales chilenos
    â”‚       â”œâ”€â”€ scraping_rules.json             # Reglas para datos legales
    â”‚       â””â”€â”€ update_schedules.json           # ProgramaciÃ³n actualizaciones legales
    â”‚
    â”œâ”€â”€ ğŸ” chapter_detection/
    â”‚   â”œâ”€â”€ interactive_title_detector.py       # Detector de clÃ¡usulas contractuales
    â”‚   â”œâ”€â”€ interactive_chapter_mapper.py       # Mapeador de secciones legales
    â”‚   â”œâ”€â”€ find_all_document_titles.py         # Buscador de tÃ­tulos de contratos
    â”‚   â””â”€â”€ chapter_definitions.json            # "ClÃ¡usulas", "Obligaciones", "Anexos"
    â”‚
    â”œâ”€â”€ ğŸ“‹ schemas/
    â”‚   â”œâ”€â”€ extraction_patterns.json            # Patrones de extracciÃ³n legal
    â”‚   â”œâ”€â”€ validation_schemas.json             # Esquemas de validaciÃ³n contractual
    â”‚   â”œâ”€â”€ cross_reference_rules.json          # Reglas de referencias entre contratos
    â”‚   â””â”€â”€ domain_ontology.json                # OntologÃ­a legal chilena
    â”‚
    â”œâ”€â”€ ğŸ› ï¸ tools/
    â”‚   â”œâ”€â”€ migration_tools/
    â”‚   â”‚   â”œâ”€â”€ fix_all_paths.py                # Corrector de rutas legales
    â”‚   â”‚   â”œâ”€â”€ reorganize_structure.py         # Reorganizador contratos
    â”‚   â”‚   â””â”€â”€ test_migration_success.py       # Tester migraciÃ³n legal
    â”‚   â”‚
    â”‚   â”œâ”€â”€ analysis_tools/
    â”‚   â”‚   â”œâ”€â”€ pattern_analyzer.py             # Analizador patrones contractuales
    â”‚   â”‚   â”œâ”€â”€ quality_reporter.py             # Reportero calidad legal
    â”‚   â”‚   â””â”€â”€ performance_profiler.py         # Perfilador rendimiento legal
    â”‚   â”‚
    â”‚   â””â”€â”€ maintenance_tools/
    â”‚       â”œâ”€â”€ database_cleaner.py             # Limpiador BD contratos
    â”‚       â”œâ”€â”€ log_analyzer.py                 # Analizador logs legales
    â”‚       â””â”€â”€ health_checker.py               # Verificador salud sistema legal
    â”‚
    â””â”€â”€ ğŸ“š validated_results/
        â”œâ”€â”€ master_validated_titles.json        # "Contrato", "Acuerdo", "Convenio"
        â”œâ”€â”€ approved_entities_catalog.json      # CatÃ¡logo empresas validadas
        â”œâ”€â”€ validated_cross_references.json     # Referencias cruzadas entre contratos
        â””â”€â”€ quality_benchmarks.json             # Benchmarks calidad legal establecidos
```

### **ğŸ¯ Archivos Clave para Cada Uso**

| PropÃ³sito | Archivo Principal | DescripciÃ³n |
|-----------|-------------------|-------------|
| **ğŸ¤– Consultas AI** | `chapters/{documento}/outputs/universal_json/universal_schema.json` | Esquema final para MCP servers |
| **ğŸ“Š MÃ©tricas de Calidad** | `chapters/{documento}/outputs/validated_extractions/quality_report.json` | Reporte de validaciÃ³n |
| **ğŸ”§ ReutilizaciÃ³n** | `chapters/{documento}/processors/{documento_tipo}_processor.py` | Extractor para documentos similares |
| **ğŸ“‹ DocumentaciÃ³n** | `chapters/{documento}/docs/README.md` | Resumen del procesamiento |
| **ğŸ” Debugging** | `chapters/{documento}/logs/processing_log.txt` | Log completo para troubleshooting |
| **âœ… ValidaciÃ³n** | `chapters/{documento}/outputs/validated_extractions/validation_summary.json` | Decisiones de validaciÃ³n |
| **ğŸŒ Esquema Universal** | `shared/utilities/universal_schema_adapters/esquema_universal_{dominio}.py` | Transformador universal del dominio |
| **ğŸ“š Entidades Validadas** | `shared/validated_results/approved_entities_catalog.json` | CatÃ¡logo maestro de entidades |
| **ğŸ•·ï¸ Web Scraping** | `shared/scrapers/{dominio}_base_scraper.py` | Scraper base del dominio |
| **ğŸ” DetecciÃ³n de CapÃ­tulos** | `shared/chapter_detection/chapter_definitions.json` | Definiciones de capÃ­tulos validadas |
| **ğŸ“‹ Patrones de ExtracciÃ³n** | `shared/schemas/extraction_patterns.json` | Patrones de extracciÃ³n comunes |
| **ğŸ·ï¸ Referencias Cruzadas** | `shared/validated_results/validated_cross_references.json` | Referencias cruzadas validadas |

### **ğŸš€ Beneficios de Esta Estructura**

#### **âœ… Para el Segundo Documento del Mismo Tipo**
- **Reutilizar**: `chapters/{documento}/processors/{documento_tipo}_processor.py`
- **Tiempo**: 30 segundos vs. 2-3 horas inicial
- **Calidad**: Misma precisiÃ³n, sin re-trabajo

#### **âœ… Para AnÃ¡lisis y Consultas AI**
- **Acceso directo**: `chapters/{documento}/outputs/universal_json/` contiene todo lo necesario
- **Consistencia**: Formato estÃ¡ndar para todos los documentos del dominio
- **Referencias**: Cross-references automÃ¡ticas entre documentos del dominio

#### **âœ… Para AuditorÃ­a y Trazabilidad**
- **Historia completa**: Desde raw extractions hasta formato final
- **Decisiones documentadas**: Validation decisions registradas en logs
- **MÃ©tricas**: Performance y calidad medibles por documento

#### **âœ… Para Escalabilidad del Dominio (Carpeta `shared/`)**
- **Esquemas universales**: `shared/utilities/universal_schema_adapters/` para transformaciÃ³n consistente
- **Patrones reutilizables**: `shared/schemas/extraction_patterns.json` para documentos similares
- **Entidades maestras**: `shared/validated_results/approved_entities_catalog.json` evita duplicados
- **Web scraping**: `shared/scrapers/` para automatizar obtenciÃ³n de documentos
- **Herramientas comunes**: `shared/utilities/common_processors/` para normalizaciÃ³n
- **Referencias globales**: `shared/validated_results/validated_cross_references.json` para correlaciÃ³n

#### **âœ… Para Mantenimiento y Mejora**
- **Logs centralizados**: `shared/tools/maintenance_tools/` para anÃ¡lisis general del dominio
- **Patrones identificados**: `shared/schemas/` para mejorar futuros procesadores
- **Calidad consistente**: `shared/data/reference_materials/quality_standards.json`
- **MigraciÃ³n y updates**: `shared/tools/migration_tools/` para evoluciÃ³n del sistema

#### **âœ… Para ColaboraciÃ³n en Equipo**
- **Recursos compartidos**: `shared/` permite que mÃºltiples desarrolladores trabajen en paralelo
- **EstÃ¡ndares unificados**: `shared/schemas/` asegura consistencia entre procesadores
- **Herramientas comunes**: `shared/utilities/` evita duplicaciÃ³n de cÃ³digo
- **DocumentaciÃ³n centralizada**: `shared/data/reference_materials/` para conocimiento del dominio

---

**ğŸŒ‘ Dark Data Platform - MetodologÃ­a Universal**

> **"De cualquier PDF a inteligencia AI-queryable en 2-6 horas"**

> **Resultado**: Estructura completa, organizada y reutilizable para procesamiento escalable

> **Ãšltima actualizaciÃ³n**: 27 Sep 2025 | **VersiÃ³n**: 2.1 | **Validado con**: 15+ tipos de documentos diferentes