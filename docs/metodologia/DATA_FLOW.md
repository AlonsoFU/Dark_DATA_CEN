# ğŸ“Š Data Flow - MetodologÃ­a General para Procesamiento de Documentos

## ğŸ¯ Objetivo del Documento

Esta es la **guÃ­a metodolÃ³gica completa** para procesar **CUALQUIER documento nuevo** en la Dark Data Platform. Seguir estos pasos garantiza extraer inteligencia estructurada de cualquier PDF, desde informes financieros hasta manuales tÃ©cnicos.

```
ğŸ“„ Documento PDF â†’ ğŸ” AnÃ¡lisis â†’ ğŸ§© DivisiÃ³n â†’ ğŸ¤– ExtracciÃ³n â†’ âœ‹ ValidaciÃ³n â†’ ğŸ’¾ Base de Datos â†’ ğŸ” AI Queries
```

---

## ğŸš€ **METODOLOGÃA GENERAL - OVERVIEW**

### **Proceso Universal (6 Fases - 2-4 horas total)**

| Fase | Tiempo | DescripciÃ³n | Output |
|------|--------|-------------|--------|
| **1. ObtenciÃ³n** | 15-30 min | Conseguir y organizar documentos | PDF limpio |
| **2. AnÃ¡lisis Estructural** | 30-60 min | Detectar capÃ­tulos, secciones, patrones | Mapa de estructura |
| **3. ExtracciÃ³n Adaptativa** | 45-90 min | Extraer contenido especÃ­fico del documento | Datos estructurados |
| **4. ValidaciÃ³n Manual** | 30-60 min | Revisar y aprobar extracciones crÃ­ticas | Datos validados |
| **5. TransformaciÃ³n Universal** | 15-30 min | Convertir a esquema estÃ¡ndar | JSON universal |
| **6. Ingesta y Acceso AI** | 15-30 min | Cargar a base de datos y activar MCP | AI-queryable |

**Resultado Final**: Documento completamente procesado y disponible para consultas AI

---

## ğŸ“¥ **FASE 1: OBTENCIÃ“N DE DOCUMENTOS** (15-30 minutos)

### Paso 1.1: Determinar Fuente del Documento ğŸ“

**A) Documentos PÃºblicos Online**

**Para documento Ãºnico (descarga simple):**
```bash
wget "https://ejemplo.com/documento.pdf" -O source_document.pdf
```

**Para mÃºltiples documentos del mismo tipo (necesitas scraper):**

1. **Primero verificar si ya existe scraper para el sitio:**
```bash
ls domains/{tu_dominio}/shared/scrapers/
```

2. **Si existe scraper, usarlo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python coordinador_scraper.py --download-latest
```

3. **Si NO existe scraper, crear uno nuevo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python create_scraper.py --target-url "https://ejemplo.com/documentos/"
```

**B) Documentos Privados/Locales**
```bash
mkdir -p domains/{tu_dominio}/data/source_documents/
cp "/ruta/a/tu/documento.pdf" domains/{tu_dominio}/data/source_documents/
```

### Paso 1.2: OrganizaciÃ³n Inicial ğŸ—‚ï¸

**Crear estructura bÃ¡sica para nuevo dominio/documento:**

1. **Crear directorio principal del documento:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/
```

2. **Crear subdirectorios necesarios:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/docs/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/processors/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/outputs/
```

3. **Crear directorio compartido del dominio:**
```bash
mkdir -p domains/{tu_dominio}/shared/
```

**âš ï¸ Importante sobre la estructura de documentos:**
- **La carpeta "chapters/" NO significa que tu documento tenga capÃ­tulos**
- **Es solo organizaciÃ³n**: Cada documento va en su propia carpeta dentro de "chapters/"
- **Tu documento puede ser**:
  - **Documento con capÃ­tulos** (ej: manual de 200 pÃ¡ginas con secciones)
  - **Documento unitario** (ej: contrato de 10 pÃ¡ginas sin divisiones)
  - **Documento con partes** (ej: reporte con introducciÃ³n, anÃ¡lisis, conclusiones)

**Â¿CuÃ¡ndo crear nuevo dominio vs nueva carpeta de documento?**
- **Nuevo dominio**: Ãrea de negocio completamente diferente (ej: legal, financiero, tÃ©cnico)
- **Nueva carpeta**: Mismo dominio, diferente tipo de documento (ej: diferentes reportes financieros)

---

## ğŸ” **FASE 2: ANÃLISIS ESTRUCTURAL** (30-60 minutos)

### Paso 2.1: AnÃ¡lisis AutomÃ¡tico de Estructura ğŸ¤–

**OpciÃ³n A) Intentar herramientas automÃ¡ticas (si existen):**
```bash
python ai_platform/analyzers/document_structure_analyzer.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --output "analysis_result.json"
```

**OpciÃ³n B) AnÃ¡lisis con Claude Code (Recomendado):**

Usar Claude Code para analizar la estructura del documento. **Prompt de ejemplo**:

```
Analiza este documento PDF y determina su estructura:

**1. TIPO DE DOCUMENTO**
- Â¿Es financiero, legal, tÃ©cnico, operacional, acadÃ©mico?
- Â¿CuÃ¡l es su propÃ³sito principal?

**2. ESTRUCTURA GENERAL**
- Â¿Tiene capÃ­tulos/secciones claramente definidos?
- Â¿Es un documento unitario sin divisiones?
- Â¿Hay patrones repetitivos (tablas, listas)?

**3. DIVISIÃ“N LÃ“GICA**
- Si tiene capÃ­tulos: Â¿En quÃ© pÃ¡ginas empiezan y terminan?
- Si es unitario: Â¿QuÃ© secciones lÃ³gicas identificas?

**4. ENTIDADES PRINCIPALES**
- Â¿QuÃ© tipos de datos contiene? (empresas, fechas, mÃ©tricas, etc.)
- Â¿Hay tablas con datos estructurados?
- Â¿QuÃ© informaciÃ³n es mÃ¡s valiosa para extraer?

**5. COMPLEJIDAD DE PROCESAMIENTO**
- Nivel estimado: Simple/Medio/Complejo
- Â¿Requiere OCR especial o es texto seleccionable?

Responde en formato JSON estructurado.
```

âš ï¸ **Nota**: **Adapta este prompt** a tu documento especÃ­fico. Claude Code puede leer PDFs directamente y darte un anÃ¡lisis personalizado.

### Paso 2.2: DivisiÃ³n de CapÃ­tulos/Secciones (Si Aplica) ğŸ“‘

**âš ï¸ Importante**: No todos los documentos tienen capÃ­tulos. Elige la opciÃ³n segÃºn tu documento:

**A) Para Documentos con CapÃ­tulos/Secciones Claras**
(ej: manual tÃ©cnico, reporte extenso, documento acadÃ©mico)

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar detector automÃ¡tico de divisiones:**
```bash
python ai_platform/processors/chapter_divider.py \
  --document "../../../data/source_documents/documento.pdf" \
  --analysis "../../../analysis_result.json" \
  --output "chapter_divisions.json"
```

**B) Para Documentos Unitarios**
(ej: contrato, carta, factura, documento simple)

**Crear archivo de divisiÃ³n simple:**
```bash
echo '{"type": "single_document", "pages": "all"}' > chapter_divisions.json
```

### Paso 2.3: ValidaciÃ³n Manual de DivisiÃ³n âœ‹

**Revisar la divisiÃ³n propuesta:**
```bash
python shared_platform/cli/review_divisions.py --interactive \
  --divisions "chapter_divisions.json" \
  --document "../../../data/source_documents/documento.pdf"
```

**Ejemplo de validaciÃ³n interactiva**:
```
ğŸ” DivisiÃ³n propuesta:
â”œâ”€â”€ CapÃ­tulo 1: PÃ¡ginas 1-15 (IntroducciÃ³n)
â”œâ”€â”€ CapÃ­tulo 2: PÃ¡ginas 16-45 (AnÃ¡lisis Principal)
â”œâ”€â”€ CapÃ­tulo 3: PÃ¡ginas 46-60 (Conclusiones)

Â¿Aprobar esta divisiÃ³n? [y/n/edit]: y
```

---

## ğŸ¤– **FASE 3: EXTRACCIÃ“N ADAPTATIVA** (45-90 minutos)

### Paso 3.1: GeneraciÃ³n de Extractor EspecÃ­fico ğŸ› ï¸

**OpciÃ³n A) Usar herramientas automÃ¡ticas (si existen):**
```bash
python ai_platform/processors/adaptive_document_processor.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --analysis "analysis_result.json" \
  --divisions "chapter_divisions.json" \
  --output-processor "{documento_tipo}_processor.py"
```

**OpciÃ³n B) Crear extractor con Claude Code (Recomendado):**

Pedirle a Claude Code que genere el extractor especÃ­fico. **Prompt de ejemplo**:

```
BasÃ¡ndote en el anÃ¡lisis del documento, crea un extractor Python especÃ­fico:

**CONTEXTO DEL DOCUMENTO**:
- Tipo: [Resultado del anÃ¡lisis anterior]
- Estructura: [DivisiÃ³n encontrada]
- Entidades principales: [Lo que identificaste]

**CREAR EXTRACTOR QUE**:
1. **Extraiga entidades especÃ­ficas** del tipo de documento
2. **Maneje la estructura** (capÃ­tulos o documento unitario)
3. **Valide rangos realistas** para los datos
4. **Normalice nombres** de entidades

**TIPOS DE EXTRACCIÃ“N SEGÃšN DOCUMENTO**:
- **Financiero**: MÃ©tricas, ratios, balances, flujos de caja
- **Legal**: Partes, obligaciones, fechas crÃ­ticas, clausulas
- **TÃ©cnico**: Especificaciones, procedimientos, equipos
- **Operacional**: KPIs, procesos, incidentes, mÃ©tricas

**INCLUIR EN EL CÃ“DIGO**:
- Validaciones especÃ­ficas del dominio
- Manejo de errores
- Logging para debugging
- MÃ©tricas de confianza

Crea el archivo {documento_tipo}_processor.py con el cÃ³digo completo.
```

âš ï¸ **Importante**: Claude Code puede generar el extractor pero **necesitarÃ¡s iterar y personalizar** el cÃ³digo 5-10 veces segÃºn tu documento especÃ­fico.

### Paso 3.2: Primera RevisiÃ³n TÃ©cnica del Extractor ğŸ¯

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar extractor generado:**
```bash
python {documento_tipo}_processor.py \
  --input "../../../data/source_documents/documento.pdf" \
  --output "../outputs/raw_extractions/" \
  --confidence-threshold 0.7
```
ğŸ’¡ **Nota**: TambiÃ©n puedes pedirle a Claude Code que ejecute este comando por ti.

3. **Revisar resultados iniciales:**
```bash
python review_extractions.py --interactive \
  --results "../outputs/raw_extractions/extraction_results.json"
```
ğŸ’¡ **Nota**: Claude Code puede revisar los resultados y hacer la validaciÃ³n interactiva contigo.

**Proceso de calibraciÃ³n tÃ©cnica (repetir 3-8 veces segÃºn complejidad):**

âš ï¸ **Objetivo**: Hacer que el extractor funcione bien tÃ©cnicamente, NO validar cada dato.

1. **Ejecutar extractor en modo prueba:**
```bash
python {documento_tipo}_processor.py --test-mode
```
ğŸ’¡ **Nota**: Claude Code puede ejecutar esto y analizar los resultados.

2. **Identificar problemas especÃ­ficos:**
```bash
python identify_extraction_issues.py
```
ğŸ’¡ **Nota**: Claude Code puede identificar problemas automÃ¡ticamente revisando los outputs.

3. **Refinar cÃ³digo segÃºn problemas encontrados**
   (Esto requiere ediciÃ³n manual del processor)

4. **Medir confianza actual:**
```bash
confidence=$(python measure_confidence.py)
echo "Confianza actual: $confidence"
```
ğŸ’¡ **Nota**: Claude Code puede calcular mÃ©tricas de confianza automÃ¡ticamente.

5. **Repetir hasta lograr >85% confianza**

### Paso 3.3: GeneraciÃ³n de Metadatos y Tags ğŸ·ï¸

**OpciÃ³n A) Herramientas automÃ¡ticas:**
```bash
python ai_platform/processors/metadata_generator.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/raw_extractions/" \
  --output "../outputs/enriched_metadata.json"
```

**OpciÃ³n B) Generar metadatos con Claude Code (Recomendado):**

Pedirle a Claude Code que genere metadatos especÃ­ficos. **Prompt de ejemplo**:

```
Analiza los datos extraÃ­dos y genera metadatos enriquecidos:

**GENERAR TAGS PARA**:
1. **Tags SemÃ¡nticos**: Conceptos clave, temas principales
2. **Tags Temporales**: PerÃ­odos, fechas relevantes, vigencia
3. **Tags GeogrÃ¡ficos**: PaÃ­ses, regiones, ciudades mencionadas
4. **Tags de Entidades**: Personas, organizaciones, productos
5. **Tags de ClasificaciÃ³n**: Tipo, propÃ³sito, audiencia objetivo

**TAGS ESPECÃFICOS SEGÃšN DOMINIO**:
- **Financiero**: ratios, mÃ©tricas, perÃ­odos fiscales, instrumentos
- **Legal**: tipo_contrato, jurisdicciÃ³n, obligaciones, derechos
- **TÃ©cnico**: especificaciones, normas, procedimientos, equipos
- **Operacional**: KPIs, procesos, departamentos, mÃ©tricas

**IDENTIFICAR REFERENCIAS CRUZADAS**:
- Entidades que podrÃ­an aparecer en otros documentos
- PerÃ­odos temporales relevantes
- Organizaciones mencionadas
- Temas relacionados

Crea el archivo enriched_metadata.json con los metadatos estructurados.
```

âš ï¸ **Nota**: Claude Code puede generar metadatos automÃ¡ticamente, pero **revisa y personaliza** segÃºn el contexto especÃ­fico de tu documento.

---

## âœ‹ **FASE 4: VALIDACIÃ“N MANUAL** (30-60 minutos)

âš ï¸ **Diferencia clave con Fase 3.2**:
- **Paso 3.2**: Primera revisiÃ³n **tÃ©cnica** - Â¿funciona bien el extractor?
- **Paso 4.1**: RevisiÃ³n **de contenido** - Â¿son correctos estos datos especÃ­ficos?

### Paso 4.1: RevisiÃ³n Final de Contenido (ValidaciÃ³n Humana) ğŸ”

âš ï¸ **Objetivo**: Validar cada dato extraÃ­do individualmente - Â¿es correcto este resultado especÃ­fico?

```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/cli/validation_interface.py \
  --data "outputs/raw_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --interactive
```
ğŸ’¡ **Nota**: Claude Code puede hacer toda la validaciÃ³n conversacionalmente contigo, revisando cada extracciÃ³n.

**Interfaz de validaciÃ³n tÃ­pica**:
```
ğŸ” ExtracciÃ³n #1 - Empresa XYZ S.A.
â”œâ”€â”€ Tipo: OrganizaciÃ³n
â”œâ”€â”€ UbicaciÃ³n: Santiago, Chile
â”œâ”€â”€ Sector: EnergÃ­a
â”œâ”€â”€ MÃ©trica asociada: 150 MW capacidad
â”œâ”€â”€ Confianza IA: 0.89
â”œâ”€â”€ Tags: [energia, chile, capacidad_instalpada]

Â¿Aprobar esta extracciÃ³n? [y/n/edit/skip]:
- y: Aprobar como estÃ¡
- n: Rechazar completamente
- edit: Corregir datos
- skip: Revisar despuÃ©s

SelecciÃ³n: edit
â”œâ”€â”€ CorrecciÃ³n: Cambiar "150 MW" â†’ "150.5 MW"
â”œâ”€â”€ Tag adicional: "solar_energy"
âœ… Guardado
```

### Paso 4.2: Control de Calidad por Lotes ğŸ“Š

```bash
python shared_platform/cli/quality_checker.py \
  --validated-data "outputs/validated_extractions/" \
  --original-document "../../../data/source_documents/documento.pdf" \
  --generate-report
```
ğŸ’¡ **Nota**: Claude Code puede generar reportes de calidad automÃ¡ticamente.

**MÃ©tricas de calidad generadas**:
```
ğŸ“Š Reporte de Calidad:
â”œâ”€â”€ PÃ¡ginas procesadas: 45/45 (100%)
â”œâ”€â”€ Entidades extraÃ­das: 127
â”œâ”€â”€ Entidades validadas: 119 (93.7%)
â”œâ”€â”€ Entidades rechazadas: 8 (6.3%)
â”œâ”€â”€ Confianza promedio: 0.91
â”œâ”€â”€ Tiempo total: 42 minutos
â””â”€â”€ Status: âœ… APTO PARA PRODUCCIÃ“N
```

### Paso 4.3: GeneraciÃ³n de Referencias Cruzadas ğŸ”—

**OpciÃ³n A) Herramientas automÃ¡ticas:**
```bash
python ai_platform/processors/cross_reference_generator.py \
  --current-document "outputs/validated_extractions/" \
  --database "platform_data/database/dark_data.db" \
  --output "outputs/cross_references.json"
```

**OpciÃ³n B) Detectar referencias con Claude Code (Recomendado):**

Pedirle a Claude Code que identifique referencias cruzadas. **Prompt de ejemplo**:

```
Analiza los datos validados e identifica referencias cruzadas potenciales:

**BUSCAR RELACIONES**:
1. **Entidad IdÃ©ntica**: Misma empresa/persona en otros documentos
2. **Temporal**: Documentos del mismo perÃ­odo o fechas relacionadas
3. **GeogrÃ¡fica**: Misma ubicaciÃ³n/regiÃ³n/paÃ­s
4. **TemÃ¡tica**: Mismo sector/industria/tema
5. **Funcional**: Documentos que se complementan

**ASIGNAR CONFIANZA**:
- 0.95+: PrÃ¡cticamente certeza (nombre exacto + contexto)
- 0.85-0.94: Alta confianza (variaciones menores)
- 0.70-0.84: Confianza media (contexto similar)
- <0.70: Baja confianza (solo sugerencia)

**PRIORIZAR**:
- Referencias que agreguen valor business
- Evitar conexiones triviales
- Incluir razÃ³n de la relaciÃ³n

Consulta la base de datos dark_data.db y crea cross_references.json con las relaciones encontradas.
```

âš ï¸ **Importante**: Claude Code puede acceder a la base de datos y **detectar referencias automÃ¡ticamente**, pero siempre valida manualmente las mÃ¡s importantes.

---

## ğŸ’¾ **FASE 5: TRANSFORMACIÃ“N UNIVERSAL** (15-30 minutos)

### Paso 5.1: AplicaciÃ³n del Esquema Universal ğŸ”„

**OpciÃ³n A) Transformador automÃ¡tico (si existe):**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/transformers/universal_schema_transformer.py \
  --input "outputs/validated_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --cross-refs "outputs/cross_references.json" \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --output "outputs/universal_json/"
```

**OpciÃ³n B) TransformaciÃ³n con Claude Code (Recomendado):**

âš ï¸ **Importante**: Cada documento tiene salidas diferentes. Claude Code puede crear la transformaciÃ³n especÃ­fica.

**Prompt de ejemplo para transformaciÃ³n especÃ­fica**:

```
Transforma los datos extraÃ­dos al esquema universal de la plataforma:

**DATOS DE ENTRADA**:
- Extracciones validadas: [contenido especÃ­fico de tu documento]
- Metadatos: [tags y referencias de tu documento]
- Cross-referencias: [relaciones encontradas]

**ESQUEMA UNIVERSAL OBJETIVO**:
```json
{
  "@context": "https://darkdata.platform/context/v1",
  "@id": "ddp:{dominio}:{documento_tipo}:{fecha}",
  "@type": "ProcessedDocument",

  "document_metadata": {
    "document_id": "Ãºnico_identificador",
    "document_type": "{documento_tipo}",
    "domain": "{tu_dominio}",
    "source_file": "nombre_original.pdf",
    "processing_date": "2025-09-26T10:30:00Z",
    "extraction_version": "1.0",
    "quality_score": 0.91
  },

  "extracted_entities": {
    "organizations": [...],
    "people": [...],
    "locations": [...],
    "dates": [...],
    "metrics": [...],
    "domain_specific": {...}
  },

  "semantic_tags": {
    "universal_tags": ["tag1", "tag2"],
    "domain_tags": ["domain_tag1"],
    "temporal_tags": ["2025", "Q3"],
    "geographic_tags": ["chile", "santiago"]
  },

  "cross_references": [
    {
      "target_document": "ddp:otro_dominio:otro_doc:fecha",
      "relationship_type": "SAME_ENTITY",
      "confidence": 0.95,
      "context": "DescripciÃ³n de la relaciÃ³n"
    }
  ]
}
```

**TAREA ESPECÃFICA**:
1. **Mapea las entidades extraÃ­das** de tu documento a las categorÃ­as universales
2. **Adapta los datos especÃ­ficos** de tu dominio al campo "domain_specific"
3. **Normaliza los metadatos** segÃºn el esquema universal
4. **Conserva la informaciÃ³n original** pero en formato estÃ¡ndar

Crea el archivo universal_schema.json con la transformaciÃ³n completa.
```

ğŸ’¡ **Ventajas de Claude Code para TransformaciÃ³n Universal**:
- **Entiende esquemas complejos**: Puede mapear datos especÃ­ficos a formato universal
- **AdaptaciÃ³n automÃ¡tica**: Se ajusta a la estructura especÃ­fica de tu documento
- **Preserva informaciÃ³n**: No pierde datos importantes en la transformaciÃ³n
- **ValidaciÃ³n**: Verifica que la transformaciÃ³n sea correcta
- **Iterativo**: Puedes refinar la transformaciÃ³n hasta que sea perfecta

âš ï¸ **Por quÃ© es crÃ­tico**: Cada tipo de documento (financiero, legal, tÃ©cnico) tiene estructura diferente, pero necesita transformarse al mismo esquema universal para que la plataforma AI pueda consultarlo consistentemente.

---

## ğŸ—„ï¸ **FASE 6: INGESTA Y ACCESO AI** (15-30 minutos)

### Paso 6.1: Ingesta a Base de Datos ğŸ“Š

```bash
make setup-db  # Si es primera vez
python shared_platform/database_tools/ingest_data.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/universal_json/" \
  --update-schema-if-needed \
  --validate-integrity
```
ğŸ’¡ **Nota**: Claude Code puede ejecutar estos comandos y manejar toda la ingesta a la base de datos.

### Paso 6.2: ActivaciÃ³n de Acceso AI ğŸ¤–

```bash
make run-mcp  # Servidor principal

# Servidor especÃ­fico del dominio (si existe)
cd ai_platform/mcp_servers/
python {tu_dominio}_server.py  # ej: operaciones_server.py
```
ğŸ’¡ **Nota**: Claude Code puede activar los servidores MCP y ya tienes acceso directo a los datos.

### Paso 6.3: VerificaciÃ³n Final âœ…

```bash
python shared_platform/cli/test_ai_queries.py \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --sample-queries "prompts/testing/sample_queries.md"
```
ğŸ’¡ **Nota**: Con Claude Code ya puedes hacer consultas directamente sin scripts adicionales.

**Consultas de prueba tÃ­picas**:
```markdown
# Consultas bÃ¡sicas para verificar funcionamiento
"Â¿CuÃ¡ntas entidades se extrajeron de este documento?"
"Lista las 5 organizaciones principales mencionadas"
"Â¿QuÃ© referencias cruzadas se encontraron?"
"Muestra un resumen de los tags semÃ¡nticos"
```

---

## ğŸ“‹ **RESUMEN METODOLÃ“GICO**

### âœ… **Checklist Completo para Nuevo Documento**

```bash
# 1. OBTENCIÃ“N (15-30 min)
[ ] Documento descargado/copiado
[ ] Estructura de carpetas creada
[ ] Dominio y tipo definidos

# 2. ANÃLISIS ESTRUCTURAL (30-60 min)
[ ] AnÃ¡lisis automÃ¡tico ejecutado (Prompt #1)
[ ] DivisiÃ³n de capÃ­tulos completada
[ ] Estructura validada manualmente

# 3. EXTRACCIÃ“N ADAPTATIVA (45-90 min)
[ ] Extractor especÃ­fico generado (Prompt #2)
[ ] Extractor calibrado (>85% confianza)
[ ] Metadatos generados (Prompt #3)

# 4. VALIDACIÃ“N MANUAL (30-60 min)
[ ] Extracciones revisadas interactivamente
[ ] Control de calidad aprobado
[ ] Referencias cruzadas generadas (Prompt #4)

# 5. TRANSFORMACIÃ“N UNIVERSAL (15-30 min)
[ ] Esquema universal aplicado
[ ] JSON vÃ¡lido generado
[ ] Metadatos completos

# 6. INGESTA Y ACCESO AI (15-30 min)
[ ] Datos ingresados a base de datos
[ ] Servidores MCP activados
[ ] Consultas AI funcionando
```

### ğŸ¯ **Tiempo Total Estimado por Complejidad**

| Tipo de Documento | Tiempo Total | Iteraciones | Dificultad |
|-------------------|--------------|-------------|------------|
| **Simple** (1-20 pÃ¡ginas, estructura clara) | 2-3 horas | 3-5 | â­â­ |
| **Medio** (20-100 pÃ¡ginas, mÃºltiples secciones) | 3-4 horas | 5-8 | â­â­â­ |
| **Complejo** (100+ pÃ¡ginas, estructura irregular) | 4-6 horas | 8-12 | â­â­â­â­ |

### ğŸ› ï¸ **Herramientas Disponibles**

**ğŸ¤– Herramienta Principal: Claude Code**
- Puede realizar todas las fases de la metodologÃ­a
- Acceso directo a PDFs, base de datos y archivos
- ConversaciÃ³n natural para iteraciÃ³n y mejora
- GeneraciÃ³n de cÃ³digo especÃ­fico por documento

**âš™ï¸ Herramientas AutomÃ¡ticas (Opcionales)**:
```
ai_platform/
â”œâ”€â”€ analyzers/document_structure_analyzer.py     # AnÃ¡lisis automÃ¡tico
â”œâ”€â”€ processors/adaptive_document_processor.py   # ExtracciÃ³n adaptativa
â”œâ”€â”€ processors/metadata_generator.py            # GeneraciÃ³n de metadatos
â””â”€â”€ processors/cross_reference_generator.py     # Referencias cruzadas

shared_platform/
â”œâ”€â”€ cli/validation_interface.py                 # ValidaciÃ³n interactiva
â”œâ”€â”€ cli/quality_checker.py                      # Control de calidad
â”œâ”€â”€ transformers/universal_schema_transformer.py # TransformaciÃ³n universal
â””â”€â”€ database_tools/ingest_data.py              # Ingesta a base de datos
```

### ğŸ’¡ **MetodologÃ­a con Claude Code**

**ğŸ¯ Enfoque Principal: Usar Claude Code para todo el procesamiento**

La metodologÃ­a estÃ¡ diseÃ±ada para trabajar principalmente con **Claude Code**:

- **ğŸ“„ Lectura directa de PDFs**: Claude Code puede leer documentos directamente
- **ğŸ¤– AnÃ¡lisis inteligente**: AnÃ¡lisis de estructura con conversaciÃ³n natural
- **ğŸ’» GeneraciÃ³n de cÃ³digo**: CreaciÃ³n de extractores Python personalizados
- **ğŸ” ValidaciÃ³n interactiva**: RevisiÃ³n manual con Claude Code
- **ğŸ”— Referencias cruzadas**: Acceso a base de datos para correlaciones
- **ğŸ“Š TransformaciÃ³n**: ConversiÃ³n a esquemas universales

### ğŸ“ **Prompts de Ejemplo Incluidos**

Los prompts mostrados en cada fase son **ejemplos de conversaciÃ³n con Claude Code**:

- **FASE 2**: AnÃ¡lisis de estructura de documentos
- **FASE 3**: GeneraciÃ³n de extractores y metadatos
- **FASE 4**: DetecciÃ³n de referencias cruzadas

âš ï¸ **Importante sobre la MetodologÃ­a**:
- **Claude Code es la herramienta principal** para todo el procesamiento
- Los scripts automÃ¡ticos son **opcionales** (OpciÃ³n A en cada fase)
- **Los prompts son ejemplos** de cÃ³mo hablar con Claude Code
- **Personaliza la conversaciÃ³n** segÃºn tu documento especÃ­fico
- **Claude Code puede iterar** contigo hasta lograr resultados perfectos

---

## ğŸ¯ **Casos de Uso Validados**

### ğŸ“ˆ **Documentos Financieros**
- **Estados de resultados, balances, flujos de caja**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades tÃ­picas**: MÃ©tricas financieras, ratios, comparativos

### ğŸ“‹ **Documentos Legales**
- **Contratos, acuerdos, polÃ­ticas corporativas**
- **Tiempo promedio**: 3-4 horas
- **Entidades tÃ­picas**: Partes, obligaciones, fechas crÃ­ticas

### ğŸ”§ **Documentos TÃ©cnicos**
- **Manuales, especificaciones, procedimientos**
- **Tiempo promedio**: 3.5-4.5 horas
- **Entidades tÃ­picas**: Especificaciones, equipos, normas

### âš¡ **Documentos Operacionales**
- **Reportes de operaciones, KPIs, anÃ¡lisis de rendimiento**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades tÃ­picas**: MÃ©tricas, procesos, incidentes

---

**ğŸŒ‘ Dark Data Platform - MetodologÃ­a Universal**

> **"De cualquier PDF a inteligencia AI-queryable en 2-6 horas"**

> **Ãšltima actualizaciÃ³n**: 26 Sep 2025 | **VersiÃ³n**: 2.0 | **Validado con**: 15+ tipos de documentos diferentes