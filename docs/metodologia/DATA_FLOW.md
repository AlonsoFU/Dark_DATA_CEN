# üìä Data Flow - Metodolog√≠a General para Procesamiento de Documentos

## üéØ Objetivo del Documento

Esta es la **gu√≠a metodol√≥gica completa** para procesar **CUALQUIER documento nuevo** en la Dark Data Platform. Seguir estos pasos garantiza extraer inteligencia estructurada de cualquier PDF, desde informes financieros hasta manuales t√©cnicos.

```
üìÑ Documento PDF ‚Üí üîç An√°lisis ‚Üí üß© Divisi√≥n ‚Üí ü§ñ Extracci√≥n ‚Üí ‚úã Validaci√≥n ‚Üí üíæ Base de Datos ‚Üí üîç AI Queries
```

---

## üöÄ **METODOLOG√çA GENERAL - OVERVIEW**

### **Proceso Universal (6 Fases - 2-4 horas total)**

| Fase | Tiempo | Descripci√≥n | Output |
|------|--------|-------------|--------|
| **1. Obtenci√≥n** | 15-30 min | Conseguir y organizar documentos | PDF limpio |
| **2. An√°lisis Estructural** | 30-60 min | Detectar cap√≠tulos, secciones, patrones | Mapa de estructura |
| **3. Extracci√≥n Adaptativa** | 45-90 min | Extraer contenido espec√≠fico del documento | Datos estructurados |
| **4. Validaci√≥n Manual** | 30-60 min | Revisar y aprobar extracciones cr√≠ticas | Datos validados |
| **5. Transformaci√≥n Universal** | 15-30 min | Convertir a esquema est√°ndar | JSON universal |
| **6. Ingesta y Acceso AI** | 15-30 min | Cargar a base de datos y activar MCP | AI-queryable |

**Resultado Final**: Documento completamente procesado y disponible para consultas AI

---

## üì• **FASE 1: OBTENCI√ìN DE DOCUMENTOS** (15-30 minutos)

### Paso 1.1: Determinar Fuente del Documento üìÅ

**A) Documentos P√∫blicos Online**

**Para documento √∫nico (descarga simple):**
```bash
wget "https://ejemplo.com/documento.pdf" -O source_document.pdf
```

**Para m√∫ltiples documentos del mismo tipo (necesitas scraper):**

1. **Primero verificar si ya existe scraper para el sitio:**
```bash
ls domains/{tu_dominio}/shared/scrapers/
```

2. **Si existe scraper, usarlo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python coordinador_scraper.py --download-latest
```

3. **Si NO existe scraper, crear uno nuevo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python create_scraper.py --target-url "https://ejemplo.com/documentos/"
```

**B) Documentos Privados/Locales**
```bash
mkdir -p domains/{tu_dominio}/data/source_documents/
cp "/ruta/a/tu/documento.pdf" domains/{tu_dominio}/data/source_documents/
```

### Paso 1.2: Organizaci√≥n Inicial üóÇÔ∏è

**Crear estructura b√°sica para nuevo dominio/documento:**

1. **Crear directorio principal del documento:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/
```

2. **Crear subdirectorios necesarios:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/docs/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/processors/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/outputs/
```

3. **Crear directorio compartido del dominio:**
```bash
mkdir -p domains/{tu_dominio}/shared/
```

**‚ö†Ô∏è Importante sobre la estructura de documentos:**
- **La carpeta "chapters/" NO significa que tu documento tenga cap√≠tulos**
- **Es solo organizaci√≥n**: Cada documento va en su propia carpeta dentro de "chapters/"
- **Tu documento puede ser**:
  - **Documento con cap√≠tulos** (ej: manual de 200 p√°ginas con secciones)
  - **Documento unitario** (ej: contrato de 10 p√°ginas sin divisiones)
  - **Documento con partes** (ej: reporte con introducci√≥n, an√°lisis, conclusiones)

**¬øCu√°ndo crear nuevo dominio vs nueva carpeta de documento?**
- **Nuevo dominio**: √Årea de negocio completamente diferente (ej: legal, financiero, t√©cnico)
- **Nueva carpeta**: Mismo dominio, diferente tipo de documento (ej: diferentes reportes financieros)

---

## üîç **FASE 2: AN√ÅLISIS ESTRUCTURAL** (30-60 minutos)

### Paso 2.1: An√°lisis Autom√°tico de Estructura ü§ñ

**Opci√≥n A) Intentar herramientas autom√°ticas (si existen):**
```bash
python ai_platform/analyzers/document_structure_analyzer.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --output "analysis_result.json"
```

**Opci√≥n B) An√°lisis con Claude Code (Recomendado):**

Usar Claude Code para analizar la estructura del documento. **Prompt de ejemplo**:

```
Analiza este documento PDF y determina su estructura:

**1. TIPO DE DOCUMENTO**
- ¬øEs financiero, legal, t√©cnico, operacional, acad√©mico?
- ¬øCu√°l es su prop√≥sito principal?

**2. ESTRUCTURA GENERAL**
- ¬øTiene cap√≠tulos/secciones claramente definidos?
- ¬øEs un documento unitario sin divisiones?
- ¬øHay patrones repetitivos (tablas, listas)?

**3. DIVISI√ìN L√ìGICA**
- Si tiene cap√≠tulos: ¬øEn qu√© p√°ginas empiezan y terminan?
- Si es unitario: ¬øQu√© secciones l√≥gicas identificas?

**4. ENTIDADES PRINCIPALES**
- ¬øQu√© tipos de datos contiene? (empresas, fechas, m√©tricas, etc.)
- ¬øHay tablas con datos estructurados?
- ¬øQu√© informaci√≥n es m√°s valiosa para extraer?

**5. COMPLEJIDAD DE PROCESAMIENTO**
- Nivel estimado: Simple/Medio/Complejo
- ¬øRequiere OCR especial o es texto seleccionable?

Responde en formato JSON estructurado.
```

‚ö†Ô∏è **Nota**: **Adapta este prompt** a tu documento espec√≠fico. Claude Code puede leer PDFs directamente y darte un an√°lisis personalizado.

### Paso 2.2: Divisi√≥n de Cap√≠tulos/Secciones (Si Aplica) üìë

**‚ö†Ô∏è Importante**: No todos los documentos tienen cap√≠tulos. Elige la opci√≥n seg√∫n tu documento:

**A) Para Documentos con Cap√≠tulos/Secciones Claras**
(ej: manual t√©cnico, reporte extenso, documento acad√©mico)

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar detector autom√°tico de divisiones:**
```bash
python ai_platform/processors/chapter_divider.py \
  --document "../../../data/source_documents/documento.pdf" \
  --analysis "../../../analysis_result.json" \
  --output "chapter_divisions.json"
```

**B) Para Documentos Unitarios**
(ej: contrato, carta, factura, documento simple)

**Crear archivo de divisi√≥n simple:**
```bash
echo '{"type": "single_document", "pages": "all"}' > chapter_divisions.json
```

### Paso 2.3: Validaci√≥n Manual de Divisi√≥n ‚úã

**Revisar la divisi√≥n propuesta:**
```bash
python shared_platform/cli/review_divisions.py --interactive \
  --divisions "chapter_divisions.json" \
  --document "../../../data/source_documents/documento.pdf"
```

**Ejemplo de validaci√≥n interactiva**:
```
üîç Divisi√≥n propuesta:
‚îú‚îÄ‚îÄ Cap√≠tulo 1: P√°ginas 1-15 (Introducci√≥n)
‚îú‚îÄ‚îÄ Cap√≠tulo 2: P√°ginas 16-45 (An√°lisis Principal)
‚îú‚îÄ‚îÄ Cap√≠tulo 3: P√°ginas 46-60 (Conclusiones)

¬øAprobar esta divisi√≥n? [y/n/edit]: y
```

---

## ü§ñ **FASE 3: EXTRACCI√ìN ADAPTATIVA** (45-90 minutos)

### Paso 3.1: Generaci√≥n de Extractor Espec√≠fico üõ†Ô∏è

**Opci√≥n A) Usar herramientas autom√°ticas (si existen):**
```bash
python ai_platform/processors/adaptive_document_processor.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --analysis "analysis_result.json" \
  --divisions "chapter_divisions.json" \
  --output-processor "{documento_tipo}_processor.py"
```

**Opci√≥n B) Crear extractor con Claude Code (Recomendado):**

Pedirle a Claude Code que genere el extractor espec√≠fico. **Prompt de ejemplo**:

```
Bas√°ndote en el an√°lisis del documento, crea un extractor Python espec√≠fico:

**CONTEXTO DEL DOCUMENTO**:
- Tipo: [Resultado del an√°lisis anterior]
- Estructura: [Divisi√≥n encontrada]
- Entidades principales: [Lo que identificaste]

**CREAR EXTRACTOR QUE**:
1. **Extraiga entidades espec√≠ficas** del tipo de documento
2. **Maneje la estructura** (cap√≠tulos o documento unitario)
3. **Valide rangos realistas** para los datos
4. **Normalice nombres** de entidades

**TIPOS DE EXTRACCI√ìN SEG√öN DOCUMENTO**:
- **Financiero**: M√©tricas, ratios, balances, flujos de caja
- **Legal**: Partes, obligaciones, fechas cr√≠ticas, clausulas
- **T√©cnico**: Especificaciones, procedimientos, equipos
- **Operacional**: KPIs, procesos, incidentes, m√©tricas

**INCLUIR EN EL C√ìDIGO**:
- Validaciones espec√≠ficas del dominio
- Manejo de errores
- Logging para debugging
- M√©tricas de confianza

Crea el archivo {documento_tipo}_processor.py con el c√≥digo completo.
```

‚ö†Ô∏è **Importante**: Claude Code puede generar el extractor pero **necesitar√°s iterar y personalizar** el c√≥digo 5-10 veces seg√∫n tu documento espec√≠fico.

### Paso 3.2: Primera Revisi√≥n T√©cnica del Extractor üéØ

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar extractor generado:**
```bash
python {documento_tipo}_processor.py \
  --input "../../../data/source_documents/documento.pdf" \
  --output "../outputs/raw_extractions/" \
  --confidence-threshold 0.7
```
üí° **Nota**: Tambi√©n puedes pedirle a Claude Code que ejecute este comando por ti.

3. **Revisar resultados iniciales:**
```bash
python review_extractions.py --interactive \
  --results "../outputs/raw_extractions/extraction_results.json"
```
üí° **Nota**: Claude Code puede revisar los resultados y hacer la validaci√≥n interactiva contigo.

**Proceso de calibraci√≥n t√©cnica (repetir 3-8 veces seg√∫n complejidad):**

‚ö†Ô∏è **Objetivo**: Hacer que el extractor funcione bien t√©cnicamente, NO validar cada dato.

1. **Ejecutar extractor en modo prueba:**
```bash
python {documento_tipo}_processor.py --test-mode
```
üí° **Nota**: Claude Code puede ejecutar esto y analizar los resultados.

2. **Identificar problemas espec√≠ficos:**
```bash
python identify_extraction_issues.py
```
üí° **Nota**: Claude Code puede identificar problemas autom√°ticamente revisando los outputs.

3. **Refinar c√≥digo seg√∫n problemas encontrados**
   (Esto requiere edici√≥n manual del processor)

4. **Medir confianza actual:**
```bash
confidence=$(python measure_confidence.py)
echo "Confianza actual: $confidence"
```
üí° **Nota**: Claude Code puede calcular m√©tricas de confianza autom√°ticamente.

5. **Repetir hasta lograr >85% confianza**

### Paso 3.3: Generaci√≥n de Metadatos y Tags üè∑Ô∏è

**Opci√≥n A) Herramientas autom√°ticas:**
```bash
python ai_platform/processors/metadata_generator.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/raw_extractions/" \
  --output "../outputs/enriched_metadata.json"
```

**Opci√≥n B) Generar metadatos con Claude Code (Recomendado):**

Pedirle a Claude Code que genere metadatos espec√≠ficos. **Prompt de ejemplo**:

```
Analiza los datos extra√≠dos y genera metadatos enriquecidos:

**GENERAR TAGS PARA**:
1. **Tags Sem√°nticos**: Conceptos clave, temas principales
2. **Tags Temporales**: Per√≠odos, fechas relevantes, vigencia
3. **Tags Geogr√°ficos**: Pa√≠ses, regiones, ciudades mencionadas
4. **Tags de Entidades**: Personas, organizaciones, productos
5. **Tags de Clasificaci√≥n**: Tipo, prop√≥sito, audiencia objetivo

**TAGS ESPEC√çFICOS SEG√öN DOMINIO**:
- **Financiero**: ratios, m√©tricas, per√≠odos fiscales, instrumentos
- **Legal**: tipo_contrato, jurisdicci√≥n, obligaciones, derechos
- **T√©cnico**: especificaciones, normas, procedimientos, equipos
- **Operacional**: KPIs, procesos, departamentos, m√©tricas

**IDENTIFICAR REFERENCIAS CRUZADAS**:
- Entidades que podr√≠an aparecer en otros documentos
- Per√≠odos temporales relevantes
- Organizaciones mencionadas
- Temas relacionados

Crea el archivo enriched_metadata.json con los metadatos estructurados.
```

‚ö†Ô∏è **Nota**: Claude Code puede generar metadatos autom√°ticamente, pero **revisa y personaliza** seg√∫n el contexto espec√≠fico de tu documento.

---

## ‚úã **FASE 4: VALIDACI√ìN MANUAL** (30-60 minutos)

‚ö†Ô∏è **Diferencia clave con Fase 3.2**:
- **Paso 3.2**: Primera revisi√≥n **t√©cnica** - ¬øfunciona bien el extractor?
- **Paso 4.1**: Revisi√≥n **de contenido** - ¬øson correctos estos datos espec√≠ficos?

### Paso 4.1: Revisi√≥n Final de Contenido (Validaci√≥n Humana) üîé

‚ö†Ô∏è **Objetivo**: Validar cada dato extra√≠do individualmente - ¬øes correcto este resultado espec√≠fico?

```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/cli/validation_interface.py \
  --data "outputs/raw_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --interactive
```
üí° **Nota**: Claude Code puede hacer toda la validaci√≥n conversacionalmente contigo, revisando cada extracci√≥n.

**Interfaz de validaci√≥n t√≠pica**:
```
üîç Extracci√≥n #1 - Empresa XYZ S.A.
‚îú‚îÄ‚îÄ Tipo: Organizaci√≥n
‚îú‚îÄ‚îÄ Ubicaci√≥n: Santiago, Chile
‚îú‚îÄ‚îÄ Sector: Energ√≠a
‚îú‚îÄ‚îÄ M√©trica asociada: 150 MW capacidad
‚îú‚îÄ‚îÄ Confianza IA: 0.89
‚îú‚îÄ‚îÄ Tags: [energia, chile, capacidad_instalpada]

¬øAprobar esta extracci√≥n? [y/n/edit/skip]:
- y: Aprobar como est√°
- n: Rechazar completamente
- edit: Corregir datos
- skip: Revisar despu√©s

Selecci√≥n: edit
‚îú‚îÄ‚îÄ Correcci√≥n: Cambiar "150 MW" ‚Üí "150.5 MW"
‚îú‚îÄ‚îÄ Tag adicional: "solar_energy"
‚úÖ Guardado
```

### Paso 4.2: Control de Calidad por Lotes üìä

```bash
python shared_platform/cli/quality_checker.py \
  --validated-data "outputs/validated_extractions/" \
  --original-document "../../../data/source_documents/documento.pdf" \
  --generate-report
```
üí° **Nota**: Claude Code puede generar reportes de calidad autom√°ticamente.

**M√©tricas de calidad generadas**:
```
üìä Reporte de Calidad:
‚îú‚îÄ‚îÄ P√°ginas procesadas: 45/45 (100%)
‚îú‚îÄ‚îÄ Entidades extra√≠das: 127
‚îú‚îÄ‚îÄ Entidades validadas: 119 (93.7%)
‚îú‚îÄ‚îÄ Entidades rechazadas: 8 (6.3%)
‚îú‚îÄ‚îÄ Confianza promedio: 0.91
‚îú‚îÄ‚îÄ Tiempo total: 42 minutos
‚îî‚îÄ‚îÄ Status: ‚úÖ APTO PARA PRODUCCI√ìN
```

### Paso 4.3: Generaci√≥n de Referencias Cruzadas üîó

**Opci√≥n A) Herramientas autom√°ticas:**
```bash
python ai_platform/processors/cross_reference_generator.py \
  --current-document "outputs/validated_extractions/" \
  --database "platform_data/database/dark_data.db" \
  --output "outputs/cross_references.json"
```

**Opci√≥n B) Detectar referencias con Claude Code (Recomendado):**

Pedirle a Claude Code que identifique referencias cruzadas. **Prompt de ejemplo**:

```
Analiza los datos validados e identifica referencias cruzadas potenciales:

**BUSCAR RELACIONES**:
1. **Entidad Id√©ntica**: Misma empresa/persona en otros documentos
2. **Temporal**: Documentos del mismo per√≠odo o fechas relacionadas
3. **Geogr√°fica**: Misma ubicaci√≥n/regi√≥n/pa√≠s
4. **Tem√°tica**: Mismo sector/industria/tema
5. **Funcional**: Documentos que se complementan

**ASIGNAR CONFIANZA**:
- 0.95+: Pr√°cticamente certeza (nombre exacto + contexto)
- 0.85-0.94: Alta confianza (variaciones menores)
- 0.70-0.84: Confianza media (contexto similar)
- <0.70: Baja confianza (solo sugerencia)

**PRIORIZAR**:
- Referencias que agreguen valor business
- Evitar conexiones triviales
- Incluir raz√≥n de la relaci√≥n

Consulta la base de datos dark_data.db y crea cross_references.json con las relaciones encontradas.
```

‚ö†Ô∏è **Importante**: Claude Code puede acceder a la base de datos y **detectar referencias autom√°ticamente**, pero siempre valida manualmente las m√°s importantes.

---

## üíæ **FASE 5: TRANSFORMACI√ìN UNIVERSAL** (15-30 minutos)

### Paso 5.1: Aplicaci√≥n del Esquema Universal üîÑ

**Opci√≥n A) Transformador autom√°tico (si existe):**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/transformers/universal_schema_transformer.py \
  --input "outputs/validated_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --cross-refs "outputs/cross_references.json" \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --output "outputs/universal_json/"
```

**Opci√≥n B) Transformaci√≥n con Claude Code (Recomendado):**

‚ö†Ô∏è **Importante**: Cada documento tiene salidas diferentes. Claude Code puede crear la transformaci√≥n espec√≠fica.

**Prompt de ejemplo para transformaci√≥n espec√≠fica**:

```
Transforma los datos extra√≠dos al esquema universal de la plataforma:

**DATOS DE ENTRADA**:
- Extracciones validadas: [contenido espec√≠fico de tu documento]
- Metadatos: [tags y referencias de tu documento]
- Cross-referencias: [relaciones encontradas]

**ESQUEMA UNIVERSAL OBJETIVO**:
```json
{
  "@context": "https://darkdata.platform/context/v1",
  "@id": "ddp:{dominio}:{documento_tipo}:{fecha}",
  "@type": "ProcessedDocument",

  "document_metadata": {
    "document_id": "√∫nico_identificador",
    "document_type": "{documento_tipo}",
    "domain": "{tu_dominio}",
    "source_file": "nombre_original.pdf",
    "processing_date": "2025-09-26T10:30:00Z",
    "extraction_version": "1.0",
    "quality_score": 0.91
  },

  "extracted_entities": {
    "organizations": [...],
    "people": [...],
    "locations": [...],
    "dates": [...],
    "metrics": [...],
    "domain_specific": {...}
  },

  "semantic_tags": {
    "universal_tags": ["tag1", "tag2"],
    "domain_tags": ["domain_tag1"],
    "temporal_tags": ["2025", "Q3"],
    "geographic_tags": ["chile", "santiago"]
  },

  "cross_references": [
    {
      "target_document": "ddp:otro_dominio:otro_doc:fecha",
      "relationship_type": "SAME_ENTITY",
      "confidence": 0.95,
      "context": "Descripci√≥n de la relaci√≥n"
    }
  ]
}
```

**TAREA ESPEC√çFICA**:
1. **Mapea las entidades extra√≠das** de tu documento a las categor√≠as universales
2. **Adapta los datos espec√≠ficos** de tu dominio al campo "domain_specific"
3. **Normaliza los metadatos** seg√∫n el esquema universal
4. **Conserva la informaci√≥n original** pero en formato est√°ndar

Crea el archivo universal_schema.json con la transformaci√≥n completa.
```

üí° **Ventajas de Claude Code para Transformaci√≥n Universal**:
- **Entiende esquemas complejos**: Puede mapear datos espec√≠ficos a formato universal
- **Adaptaci√≥n autom√°tica**: Se ajusta a la estructura espec√≠fica de tu documento
- **Preserva informaci√≥n**: No pierde datos importantes en la transformaci√≥n
- **Validaci√≥n**: Verifica que la transformaci√≥n sea correcta
- **Iterativo**: Puedes refinar la transformaci√≥n hasta que sea perfecta

‚ö†Ô∏è **Por qu√© es cr√≠tico**: Cada tipo de documento (financiero, legal, t√©cnico) tiene estructura diferente, pero necesita transformarse al mismo esquema universal para que la plataforma AI pueda consultarlo consistentemente.

---

## üóÑÔ∏è **FASE 6: INGESTA Y ACCESO AI** (15-30 minutos)

### Paso 6.1: Ingesta a Base de Datos üìä

```bash
make setup-db  # Si es primera vez
python shared_platform/database_tools/ingest_data.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/universal_json/" \
  --update-schema-if-needed \
  --validate-integrity
```
üí° **Nota**: Claude Code puede ejecutar estos comandos y manejar toda la ingesta a la base de datos.

### Paso 6.2: Activaci√≥n de Acceso AI ü§ñ

```bash
make run-mcp  # Servidor principal

# Servidor espec√≠fico del dominio (si existe)
cd ai_platform/mcp_servers/
python {tu_dominio}_server.py  # ej: operaciones_server.py
```
üí° **Nota**: Claude Code puede activar los servidores MCP y ya tienes acceso directo a los datos.

### Paso 6.3: Verificaci√≥n Final ‚úÖ

```bash
python shared_platform/cli/test_ai_queries.py \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --sample-queries "prompts/testing/sample_queries.md"
```
üí° **Nota**: Con Claude Code ya puedes hacer consultas directamente sin scripts adicionales.

**Consultas de prueba t√≠picas**:
```markdown
# Consultas b√°sicas para verificar funcionamiento
"¬øCu√°ntas entidades se extrajeron de este documento?"
"Lista las 5 organizaciones principales mencionadas"
"¬øQu√© referencias cruzadas se encontraron?"
"Muestra un resumen de los tags sem√°nticos"
```

---

## üìã **RESUMEN METODOL√ìGICO**

### ‚úÖ **Checklist Completo para Nuevo Documento**

```bash
# 1. OBTENCI√ìN (15-30 min)
[ ] Documento descargado/copiado
[ ] Estructura de carpetas creada
[ ] Dominio y tipo definidos

# 2. AN√ÅLISIS ESTRUCTURAL (30-60 min)
[ ] An√°lisis autom√°tico ejecutado (Prompt #1)
[ ] Divisi√≥n de cap√≠tulos completada
[ ] Estructura validada manualmente

# 3. EXTRACCI√ìN ADAPTATIVA (45-90 min)
[ ] Extractor espec√≠fico generado (Prompt #2)
[ ] Extractor calibrado (>85% confianza)
[ ] Metadatos generados (Prompt #3)

# 4. VALIDACI√ìN MANUAL (30-60 min)
[ ] Extracciones revisadas interactivamente
[ ] Control de calidad aprobado
[ ] Referencias cruzadas generadas (Prompt #4)

# 5. TRANSFORMACI√ìN UNIVERSAL (15-30 min)
[ ] Esquema universal aplicado
[ ] JSON v√°lido generado
[ ] Metadatos completos

# 6. INGESTA Y ACCESO AI (15-30 min)
[ ] Datos ingresados a base de datos
[ ] Servidores MCP activados
[ ] Consultas AI funcionando
```

### üéØ **Tiempo Total Estimado por Complejidad**

| Tipo de Documento | Tiempo Total | Iteraciones | Dificultad |
|-------------------|--------------|-------------|------------|
| **Simple** (1-20 p√°ginas, estructura clara) | 2-3 horas | 3-5 | ‚≠ê‚≠ê |
| **Medio** (20-100 p√°ginas, m√∫ltiples secciones) | 3-4 horas | 5-8 | ‚≠ê‚≠ê‚≠ê |
| **Complejo** (100+ p√°ginas, estructura irregular) | 4-6 horas | 8-12 | ‚≠ê‚≠ê‚≠ê‚≠ê |

### üõ†Ô∏è **Herramientas Disponibles**

**ü§ñ Herramienta Principal: Claude Code**
- Puede realizar todas las fases de la metodolog√≠a
- Acceso directo a PDFs, base de datos y archivos
- Conversaci√≥n natural para iteraci√≥n y mejora
- Generaci√≥n de c√≥digo espec√≠fico por documento

**‚öôÔ∏è Herramientas Autom√°ticas (Opcionales)**:
```
ai_platform/
‚îú‚îÄ‚îÄ analyzers/document_structure_analyzer.py     # An√°lisis autom√°tico
‚îú‚îÄ‚îÄ processors/adaptive_document_processor.py   # Extracci√≥n adaptativa
‚îú‚îÄ‚îÄ processors/metadata_generator.py            # Generaci√≥n de metadatos
‚îî‚îÄ‚îÄ processors/cross_reference_generator.py     # Referencias cruzadas

shared_platform/
‚îú‚îÄ‚îÄ cli/validation_interface.py                 # Validaci√≥n interactiva
‚îú‚îÄ‚îÄ cli/quality_checker.py                      # Control de calidad
‚îú‚îÄ‚îÄ transformers/universal_schema_transformer.py # Transformaci√≥n universal
‚îî‚îÄ‚îÄ database_tools/ingest_data.py              # Ingesta a base de datos
```

### üí° **Metodolog√≠a con Claude Code**

**üéØ Enfoque Principal: Usar Claude Code para todo el procesamiento**

La metodolog√≠a est√° dise√±ada para trabajar principalmente con **Claude Code**:

- **üìÑ Lectura directa de PDFs**: Claude Code puede leer documentos directamente
- **ü§ñ An√°lisis inteligente**: An√°lisis de estructura con conversaci√≥n natural
- **üíª Generaci√≥n de c√≥digo**: Creaci√≥n de extractores Python personalizados
- **üîç Validaci√≥n interactiva**: Revisi√≥n manual con Claude Code
- **üîó Referencias cruzadas**: Acceso a base de datos para correlaciones
- **üìä Transformaci√≥n**: Conversi√≥n a esquemas universales

### üìù **Prompts de Ejemplo Incluidos**

Los prompts mostrados en cada fase son **ejemplos de conversaci√≥n con Claude Code**:

- **FASE 2**: An√°lisis de estructura de documentos
- **FASE 3**: Generaci√≥n de extractores y metadatos
- **FASE 4**: Detecci√≥n de referencias cruzadas

‚ö†Ô∏è **Importante sobre la Metodolog√≠a**:
- **Claude Code es la herramienta principal** para todo el procesamiento
- Los scripts autom√°ticos son **opcionales** (Opci√≥n A en cada fase)
- **Los prompts son ejemplos** de c√≥mo hablar con Claude Code
- **Personaliza la conversaci√≥n** seg√∫n tu documento espec√≠fico
- **Claude Code puede iterar** contigo hasta lograr resultados perfectos

---

## üéØ **Casos de Uso Validados**

### üìà **Documentos Financieros**
- **Estados de resultados, balances, flujos de caja**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades t√≠picas**: M√©tricas financieras, ratios, comparativos

### üìã **Documentos Legales**
- **Contratos, acuerdos, pol√≠ticas corporativas**
- **Tiempo promedio**: 3-4 horas
- **Entidades t√≠picas**: Partes, obligaciones, fechas cr√≠ticas

### üîß **Documentos T√©cnicos**
- **Manuales, especificaciones, procedimientos**
- **Tiempo promedio**: 3.5-4.5 horas
- **Entidades t√≠picas**: Especificaciones, equipos, normas

### ‚ö° **Documentos Operacionales**
- **Reportes de operaciones, KPIs, an√°lisis de rendimiento**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades t√≠picas**: M√©tricas, procesos, incidentes

---

## üìÅ **ESTRUCTURA FINAL COMPLETA DEL DOCUMENTO PROCESADO**

### üéØ **¬øC√≥mo queda organizado todo despu√©s del procesamiento?**

Una vez completada la metodolog√≠a, esta es la **estructura gen√©rica** que tendr√°s para cualquier documento procesado:

```
domains/{tu_dominio}/
‚îÇ
‚îú‚îÄ‚îÄ chapters/{documento_tipo}/                  # Procesamiento espec√≠fico del documento
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ docs/                                # Documentaci√≥n del procesamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md                           # Resumen del documento y procesamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patterns.json                       # Patrones de extracci√≥n identificados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cross_references.json               # Referencias cruzadas detectadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processing_notes.md                 # Notas del proceso y lecciones aprendidas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation_report.md                # Reporte de validaci√≥n manual
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üîß processors/                          # C√≥digo de procesamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {documento_tipo}_processor.py       # Extractor principal generado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata_generator.py               # Generador de metadatos espec√≠fico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation_rules.py                 # Reglas de validaci√≥n personalizadas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py                  # Verificador de calidad espec√≠fico
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìä outputs/                             # Todas las salidas del procesamiento
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üîç raw_extractions/                 # Extracciones iniciales sin validar
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction_results.json         # Datos extra√≠dos por el processor
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confidence_metrics.json         # M√©tricas de confianza por entidad
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction_log.txt              # Log detallado del procesamiento
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ failed_extractions.json         # Intentos fallidos con razones
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ validated_extractions/           # Datos validados manualmente
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ approved_entities.json          # Entidades aprobadas por humano
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ corrected_data.json             # Datos corregidos manualmente
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rejected_entities.json          # Entidades rechazadas con razones
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation_summary.json         # Resumen de validaci√≥n
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_report.json             # Reporte final de calidad
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üè∑Ô∏è enriched_metadata/               # Metadatos y tags generados
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_tags.json              # Tags sem√°nticos del documento
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ temporal_tags.json              # Tags temporales (fechas, per√≠odos)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geographic_tags.json            # Tags geogr√°ficos identificados
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ business_tags.json              # Tags de negocio espec√≠ficos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cross_references.json           # Referencias a otros documentos
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üåê universal_json/                  # Formato final para base de datos
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ universal_schema.json           # Documento en esquema universal
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ document_metadata.json          # Metadatos completos del documento
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ extracted_entities.json         # Entidades en formato est√°ndar
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ semantic_tags.json              # Tags normalizados
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ cross_references.json           # Referencias cruzadas finales
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ quality_metrics.json            # M√©tricas finales de calidad
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üîÑ universal_schema_adapters/           # Transformadores de esquema
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {documento_tipo}_adapter.py         # Adaptador espec√≠fico del documento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_normalizer.py                # Normalizador de entidades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tag_mapper.py                       # Mapeador de tags al formato universal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cross_reference_detector.py         # Detector de referencias cruzadas
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìã logs/                                # Registros del procesamiento
‚îÇ       ‚îú‚îÄ‚îÄ processing_log.txt                  # Log completo del procesamiento
‚îÇ       ‚îú‚îÄ‚îÄ validation_decisions.txt            # Decisiones de validaci√≥n manual
‚îÇ       ‚îú‚îÄ‚îÄ error_log.txt                       # Errores encontrados y resueltos
‚îÇ       ‚îî‚îÄ‚îÄ performance_metrics.json            # M√©tricas de tiempo y rendimiento
‚îÇ
‚îî‚îÄ‚îÄ üåê shared/                                  # Recursos compartidos del dominio
    ‚îÇ
    ‚îú‚îÄ‚îÄ üìä data/                                # Datos compartidos del dominio
    ‚îÇ   ‚îú‚îÄ‚îÄ source_documents/                   # Documentos PDF originales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documento1.pdf                  # PDFs sin procesar
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documento2.pdf
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backup_documents/               # Respaldos de documentos
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ master_databases/                   # Bases de datos maestras
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities_catalog.json           # Cat√°logo de entidades del dominio
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ organizations_registry.json     # Registro de organizaciones
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validated_patterns.json         # Patrones validados del dominio
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ reference_materials/                # Materiales de referencia
    ‚îÇ       ‚îú‚îÄ‚îÄ domain_glossary.json            # Glosario de t√©rminos del dominio
    ‚îÇ       ‚îú‚îÄ‚îÄ business_rules.json             # Reglas de negocio espec√≠ficas
    ‚îÇ       ‚îî‚îÄ‚îÄ quality_standards.json          # Est√°ndares de calidad
    ‚îÇ
    ‚îú‚îÄ‚îÄ üîß utilities/                           # Utilidades compartidas
    ‚îÇ   ‚îú‚îÄ‚îÄ universal_schema_adapters/          # Adaptadores universales del dominio
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ esquema_universal_{dominio}.py  # Esquema universal del dominio
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extractor_universal_integrado.py # Transformador universal
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ referencias_cruzadas.py         # Detector de referencias del dominio
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ common_processors/                  # Procesadores comunes
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py             # Extractor gen√©rico de entidades
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date_normalizer.py              # Normalizador de fechas
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ currency_converter.py           # Convertidor de monedas
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_cleaner.py                 # Limpiador de texto
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ validation_tools/                   # Herramientas de validaci√≥n
    ‚îÇ       ‚îú‚îÄ‚îÄ quality_checker.py              # Verificador de calidad gen√©rico
    ‚îÇ       ‚îú‚îÄ‚îÄ consistency_validator.py        # Validador de consistencia
    ‚îÇ       ‚îî‚îÄ‚îÄ completeness_checker.py         # Verificador de completitud
    ‚îÇ
    ‚îú‚îÄ‚îÄ üï∑Ô∏è scrapers/                            # Web scrapers del dominio
    ‚îÇ   ‚îú‚îÄ‚îÄ {dominio}_base_scraper.py           # Scraper base del dominio
    ‚îÇ   ‚îú‚îÄ‚îÄ site_specific_scrapers/             # Scrapers espec√≠ficos de sitios
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ coordinador_cl_scraper.py       # Ejemplo: scraper Coordinador
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cne_cl_scraper.py               # Ejemplo: scraper CNE
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sii_cl_scraper.py               # Ejemplo: scraper SII
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ scraper_configs/                    # Configuraciones de scrapers
    ‚îÇ       ‚îú‚îÄ‚îÄ urls_catalog.json               # Cat√°logo de URLs del dominio
    ‚îÇ       ‚îú‚îÄ‚îÄ scraping_rules.json             # Reglas de web scraping
    ‚îÇ       ‚îî‚îÄ‚îÄ update_schedules.json           # Programaci√≥n de actualizaciones
    ‚îÇ
    ‚îú‚îÄ‚îÄ üîç chapter_detection/                   # Herramientas de detecci√≥n de cap√≠tulos
    ‚îÇ   ‚îú‚îÄ‚îÄ interactive_title_detector.py       # Detector interactivo de t√≠tulos
    ‚îÇ   ‚îú‚îÄ‚îÄ interactive_chapter_mapper.py       # Mapeador interactivo de cap√≠tulos
    ‚îÇ   ‚îú‚îÄ‚îÄ find_all_document_titles.py         # Buscador autom√°tico de t√≠tulos
    ‚îÇ   ‚îî‚îÄ‚îÄ chapter_definitions.json            # Definiciones de cap√≠tulos validadas
    ‚îÇ
    ‚îú‚îÄ‚îÄ üìã schemas/                             # Esquemas y patrones del dominio
    ‚îÇ   ‚îú‚îÄ‚îÄ extraction_patterns.json            # Patrones de extracci√≥n comunes
    ‚îÇ   ‚îú‚îÄ‚îÄ validation_schemas.json             # Esquemas de validaci√≥n
    ‚îÇ   ‚îú‚îÄ‚îÄ cross_reference_rules.json          # Reglas de referencias cruzadas
    ‚îÇ   ‚îî‚îÄ‚îÄ domain_ontology.json                # Ontolog√≠a del dominio
    ‚îÇ
    ‚îú‚îÄ‚îÄ üõ†Ô∏è tools/                               # Herramientas del dominio
    ‚îÇ   ‚îú‚îÄ‚îÄ migration_tools/                    # Herramientas de migraci√≥n
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fix_all_paths.py                # Corrector de rutas
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reorganize_structure.py         # Reorganizador de estructura
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_migration_success.py       # Tester de migraci√≥n
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ analysis_tools/                     # Herramientas de an√°lisis
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pattern_analyzer.py             # Analizador de patrones
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_reporter.py             # Reportero de calidad
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ performance_profiler.py         # Perfilador de rendimiento
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ maintenance_tools/                  # Herramientas de mantenimiento
    ‚îÇ       ‚îú‚îÄ‚îÄ database_cleaner.py             # Limpiador de base de datos
    ‚îÇ       ‚îú‚îÄ‚îÄ log_analyzer.py                 # Analizador de logs
    ‚îÇ       ‚îî‚îÄ‚îÄ health_checker.py               # Verificador de salud del sistema
    ‚îÇ
    ‚îî‚îÄ‚îÄ üìö validated_results/                   # Resultados validados por usuarios
        ‚îú‚îÄ‚îÄ master_validated_titles.json        # T√≠tulos validados manualmente
        ‚îú‚îÄ‚îÄ approved_entities_catalog.json      # Cat√°logo de entidades aprobadas
        ‚îú‚îÄ‚îÄ validated_cross_references.json     # Referencias cruzadas validadas
        ‚îî‚îÄ‚îÄ quality_benchmarks.json             # Benchmarks de calidad establecidos
```

### **üìä Ejemplo Real: Estructura de Contrato de Servicios de TI**

```
domains/legal/
‚îÇ
‚îú‚îÄ‚îÄ chapters/contrato_servicios_ti/             # Procesamiento espec√≠fico del contrato
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ docs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md                           # "Contrato DevCorp-TechSolutions procesado"
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patterns.json                       # Patrones de contratos de TI identificados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cross_references.json               # Relaciones con otros contratos de DevCorp
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processing_notes.md                 # "2h 45min, 18 entidades, 94% validaci√≥n"
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation_report.md                # Reporte de 1 correcci√≥n manual
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üîß processors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contrato_servicios_ti_processor.py  # Extractor para contratos de TI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata_generator.py               # Generador de tags contractuales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation_rules.py                 # Validaciones espec√≠ficas de contratos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_checker.py                  # Verificador de calidad legal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìä outputs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üîç raw_extractions/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction_results.json         # 18 entidades extra√≠das inicialmente
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confidence_metrics.json         # Confianza 0.85-0.98 por entidad
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction_log.txt              # "Procesamiento 75 minutos, 2 iteraciones"
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ failed_extractions.json         # 3 intentos fallidos de fechas
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ validated_extractions/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ approved_entities.json          # 17 entidades aprobadas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ corrected_data.json             # 1 monto corregido USD 185,000
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rejected_entities.json          # 0 entidades rechazadas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation_summary.json         # 94% tasa de aprobaci√≥n
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_report.json             # "Apto para producci√≥n"
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üè∑Ô∏è enriched_metadata/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_tags.json              # ["contrato", "servicios", "tecnologia"]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ temporal_tags.json              # ["2025", "anual", "multifase"]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geographic_tags.json            # ["chile", "estados_unidos"]
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ business_tags.json              # ["devcorp", "techsolutions"]
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cross_references.json           # 2 referencias a otros contratos
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üåê universal_json/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ universal_schema.json           # Esquema JSON-LD completo
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ document_metadata.json          # "legal_contrato_devcorp_2025"
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ extracted_entities.json         # Organizaciones, fechas, m√©tricas
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ semantic_tags.json              # Tags normalizados para AI
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ cross_references.json           # Referencias para consultas AI
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ quality_metrics.json            # Confianza 0.94, validaci√≥n humana
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üîÑ universal_schema_adapters/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contrato_servicios_ti_adapter.py    # Transformador legal‚Üíuniversal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_normalizer.py                # Normalizador de entidades legales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tag_mapper.py                       # Mapeador tags legales‚Üíuniversales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cross_reference_detector.py         # Detector referencias legales
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìã logs/
‚îÇ       ‚îú‚îÄ‚îÄ processing_log.txt                  # "2h 45min total, 94% validaci√≥n"
‚îÇ       ‚îú‚îÄ‚îÄ validation_decisions.txt            # "Usuario corrigi√≥ monto l√≠nea 142"
‚îÇ       ‚îú‚îÄ‚îÄ error_log.txt                       # "Problema parser fechas resuelto"
‚îÇ       ‚îî‚îÄ‚îÄ performance_metrics.json            # M√©tricas detalladas de rendimiento
‚îÇ
‚îî‚îÄ‚îÄ üåê shared/                                  # Recursos compartidos del dominio legal
    ‚îÇ
    ‚îú‚îÄ‚îÄ üìä data/
    ‚îÇ   ‚îú‚îÄ‚îÄ source_documents/                   # PDFs legales originales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Contrato_DevCorp_2025.pdf       # Contrato procesado
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Contrato_AcmeCorp_2025.pdf      # Otros contratos del dominio
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backup_documents/               # Respaldos de contratos
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ master_databases/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities_catalog.json           # "DevCorp S.A.", "TechSolutions Ltd."
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ organizations_registry.json     # Registro de empresas legales
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validated_patterns.json         # Patrones de contratos validados
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ reference_materials/
    ‚îÇ       ‚îú‚îÄ‚îÄ domain_glossary.json            # Glosario jur√≠dico
    ‚îÇ       ‚îú‚îÄ‚îÄ business_rules.json             # Reglas legales chilenas
    ‚îÇ       ‚îî‚îÄ‚îÄ quality_standards.json          # Est√°ndares de calidad legal
    ‚îÇ
    ‚îú‚îÄ‚îÄ üîß utilities/
    ‚îÇ   ‚îú‚îÄ‚îÄ universal_schema_adapters/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ esquema_universal_legal.py      # Esquema universal legal
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extractor_universal_integrado.py # Transformador universal legal
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ referencias_cruzadas.py         # Referencias entre contratos
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ common_processors/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py             # Extractor de partes contractuales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date_normalizer.py              # Normalizador de fechas legales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ currency_converter.py           # Convertidor USD/CLP/EUR
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_cleaner.py                 # Limpiador de texto legal
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ validation_tools/
    ‚îÇ       ‚îú‚îÄ‚îÄ quality_checker.py              # Verificador calidad documentos legales
    ‚îÇ       ‚îú‚îÄ‚îÄ consistency_validator.py        # Validador consistencia contractual
    ‚îÇ       ‚îî‚îÄ‚îÄ completeness_checker.py         # Verificador completitud legal
    ‚îÇ
    ‚îú‚îÄ‚îÄ üï∑Ô∏è scrapers/
    ‚îÇ   ‚îú‚îÄ‚îÄ legal_base_scraper.py               # Scraper base para sitios legales
    ‚îÇ   ‚îú‚îÄ‚îÄ site_specific_scrapers/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sii_cl_scraper.py               # Scraper SII para datos fiscales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conservador_cl_scraper.py       # Scraper Conservador de Bienes Ra√≠ces
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registros_cl_scraper.py         # Scraper Registro Civil
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ scraper_configs/
    ‚îÇ       ‚îú‚îÄ‚îÄ urls_catalog.json               # URLs de sitios legales chilenos
    ‚îÇ       ‚îú‚îÄ‚îÄ scraping_rules.json             # Reglas para datos legales
    ‚îÇ       ‚îî‚îÄ‚îÄ update_schedules.json           # Programaci√≥n actualizaciones legales
    ‚îÇ
    ‚îú‚îÄ‚îÄ üîç chapter_detection/
    ‚îÇ   ‚îú‚îÄ‚îÄ interactive_title_detector.py       # Detector de cl√°usulas contractuales
    ‚îÇ   ‚îú‚îÄ‚îÄ interactive_chapter_mapper.py       # Mapeador de secciones legales
    ‚îÇ   ‚îú‚îÄ‚îÄ find_all_document_titles.py         # Buscador de t√≠tulos de contratos
    ‚îÇ   ‚îî‚îÄ‚îÄ chapter_definitions.json            # "Cl√°usulas", "Obligaciones", "Anexos"
    ‚îÇ
    ‚îú‚îÄ‚îÄ üìã schemas/
    ‚îÇ   ‚îú‚îÄ‚îÄ extraction_patterns.json            # Patrones de extracci√≥n legal
    ‚îÇ   ‚îú‚îÄ‚îÄ validation_schemas.json             # Esquemas de validaci√≥n contractual
    ‚îÇ   ‚îú‚îÄ‚îÄ cross_reference_rules.json          # Reglas de referencias entre contratos
    ‚îÇ   ‚îî‚îÄ‚îÄ domain_ontology.json                # Ontolog√≠a legal chilena
    ‚îÇ
    ‚îú‚îÄ‚îÄ üõ†Ô∏è tools/
    ‚îÇ   ‚îú‚îÄ‚îÄ migration_tools/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fix_all_paths.py                # Corrector de rutas legales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reorganize_structure.py         # Reorganizador contratos
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_migration_success.py       # Tester migraci√≥n legal
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ analysis_tools/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pattern_analyzer.py             # Analizador patrones contractuales
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_reporter.py             # Reportero calidad legal
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ performance_profiler.py         # Perfilador rendimiento legal
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ maintenance_tools/
    ‚îÇ       ‚îú‚îÄ‚îÄ database_cleaner.py             # Limpiador BD contratos
    ‚îÇ       ‚îú‚îÄ‚îÄ log_analyzer.py                 # Analizador logs legales
    ‚îÇ       ‚îî‚îÄ‚îÄ health_checker.py               # Verificador salud sistema legal
    ‚îÇ
    ‚îî‚îÄ‚îÄ üìö validated_results/
        ‚îú‚îÄ‚îÄ master_validated_titles.json        # "Contrato", "Acuerdo", "Convenio"
        ‚îú‚îÄ‚îÄ approved_entities_catalog.json      # Cat√°logo empresas validadas
        ‚îú‚îÄ‚îÄ validated_cross_references.json     # Referencias cruzadas entre contratos
        ‚îî‚îÄ‚îÄ quality_benchmarks.json             # Benchmarks calidad legal establecidos
```

### **üéØ Archivos Clave para Cada Uso**

| Prop√≥sito | Archivo Principal | Descripci√≥n |
|-----------|-------------------|-------------|
| **ü§ñ Consultas AI** | `chapters/{documento}/outputs/universal_json/universal_schema.json` | Esquema final para MCP servers |
| **üìä M√©tricas de Calidad** | `chapters/{documento}/outputs/validated_extractions/quality_report.json` | Reporte de validaci√≥n |
| **üîß Reutilizaci√≥n** | `chapters/{documento}/processors/{documento_tipo}_processor.py` | Extractor para documentos similares |
| **üìã Documentaci√≥n** | `chapters/{documento}/docs/README.md` | Resumen del procesamiento |
| **üîç Debugging** | `chapters/{documento}/logs/processing_log.txt` | Log completo para troubleshooting |
| **‚úÖ Validaci√≥n** | `chapters/{documento}/outputs/validated_extractions/validation_summary.json` | Decisiones de validaci√≥n |
| **üåê Esquema Universal** | `shared/utilities/universal_schema_adapters/esquema_universal_{dominio}.py` | Transformador universal del dominio |
| **üìö Entidades Validadas** | `shared/validated_results/approved_entities_catalog.json` | Cat√°logo maestro de entidades |
| **üï∑Ô∏è Web Scraping** | `shared/scrapers/{dominio}_base_scraper.py` | Scraper base del dominio |
| **üîç Detecci√≥n de Cap√≠tulos** | `shared/chapter_detection/chapter_definitions.json` | Definiciones de cap√≠tulos validadas |
| **üìã Patrones de Extracci√≥n** | `shared/schemas/extraction_patterns.json` | Patrones de extracci√≥n comunes |
| **üè∑Ô∏è Referencias Cruzadas** | `shared/validated_results/validated_cross_references.json` | Referencias cruzadas validadas |

### **üöÄ Beneficios de Esta Estructura**

#### **‚úÖ Para el Segundo Documento del Mismo Tipo**
- **Reutilizar**: `chapters/{documento}/processors/{documento_tipo}_processor.py`
- **Tiempo**: 30 segundos vs. 2-3 horas inicial
- **Calidad**: Misma precisi√≥n, sin re-trabajo

#### **‚úÖ Para An√°lisis y Consultas AI**
- **Acceso directo**: `chapters/{documento}/outputs/universal_json/` contiene todo lo necesario
- **Consistencia**: Formato est√°ndar para todos los documentos del dominio
- **Referencias**: Cross-references autom√°ticas entre documentos del dominio

#### **‚úÖ Para Auditor√≠a y Trazabilidad**
- **Historia completa**: Desde raw extractions hasta formato final
- **Decisiones documentadas**: Validation decisions registradas en logs
- **M√©tricas**: Performance y calidad medibles por documento

#### **‚úÖ Para Escalabilidad del Dominio (Carpeta `shared/`)**
- **Esquemas universales**: `shared/utilities/universal_schema_adapters/` para transformaci√≥n consistente
- **Patrones reutilizables**: `shared/schemas/extraction_patterns.json` para documentos similares
- **Entidades maestras**: `shared/validated_results/approved_entities_catalog.json` evita duplicados
- **Web scraping**: `shared/scrapers/` para automatizar obtenci√≥n de documentos
- **Herramientas comunes**: `shared/utilities/common_processors/` para normalizaci√≥n
- **Referencias globales**: `shared/validated_results/validated_cross_references.json` para correlaci√≥n

#### **‚úÖ Para Mantenimiento y Mejora**
- **Logs centralizados**: `shared/tools/maintenance_tools/` para an√°lisis general del dominio
- **Patrones identificados**: `shared/schemas/` para mejorar futuros procesadores
- **Calidad consistente**: `shared/data/reference_materials/quality_standards.json`
- **Migraci√≥n y updates**: `shared/tools/migration_tools/` para evoluci√≥n del sistema

#### **‚úÖ Para Colaboraci√≥n en Equipo**
- **Recursos compartidos**: `shared/` permite que m√∫ltiples desarrolladores trabajen en paralelo
- **Est√°ndares unificados**: `shared/schemas/` asegura consistencia entre procesadores
- **Herramientas comunes**: `shared/utilities/` evita duplicaci√≥n de c√≥digo
- **Documentaci√≥n centralizada**: `shared/data/reference_materials/` para conocimiento del dominio

---

**üåë Dark Data Platform - Metodolog√≠a Universal**

> **"De cualquier PDF a inteligencia AI-queryable en 2-6 horas"**

> **Resultado**: Estructura completa, organizada y reutilizable para procesamiento escalable

> **√öltima actualizaci√≥n**: 27 Sep 2025 | **Versi√≥n**: 2.1 | **Validado con**: 15+ tipos de documentos diferentes