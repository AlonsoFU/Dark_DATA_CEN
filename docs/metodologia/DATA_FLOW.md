# üìä Data Flow - Metodolog√≠a General para Procesamiento de Documentos

## üéØ Objetivo del Documento

Esta es la **gu√≠a metodol√≥gica completa** para procesar **CUALQUIER documento nuevo** en la Dark Data Platform. Seguir estos pasos garantiza extraer inteligencia estructurada de cualquier PDF, desde informes financieros hasta manuales t√©cnicos.

```
üìÑ Documento PDF ‚Üí üîç An√°lisis ‚Üí üß© Divisi√≥n ‚Üí ü§ñ Extracci√≥n ‚Üí ‚úã Validaci√≥n ‚Üí üíæ Base de Datos ‚Üí üîç AI Queries
```

---

## üöÄ **METODOLOG√çA GENERAL - OVERVIEW**

### **Proceso Universal (6 Fases - 2-4 horas total)**

| Fase | Tiempo | Descripci√≥n | Output |
|------|--------|-------------|--------|
| **1. Obtenci√≥n** | 15-30 min | Conseguir y organizar documentos | PDF limpio |
| **2. An√°lisis Estructural** | 30-60 min | Detectar cap√≠tulos, secciones, patrones | Mapa de estructura |
| **3. Extracci√≥n Adaptativa** | 45-90 min | Extraer contenido espec√≠fico del documento | Datos estructurados |
| **4. Validaci√≥n Manual** | 30-60 min | Revisar y aprobar extracciones cr√≠ticas | Datos validados |
| **5. Transformaci√≥n Universal** | 15-30 min | Convertir a esquema est√°ndar | JSON universal |
| **6. Ingesta y Acceso AI** | 15-30 min | Cargar a base de datos y activar MCP | AI-queryable |

**Resultado Final**: Documento completamente procesado y disponible para consultas AI

---

## üì• **FASE 1: OBTENCI√ìN DE DOCUMENTOS** (15-30 minutos)

### Paso 1.1: Determinar Fuente del Documento üìÅ

**A) Documentos P√∫blicos Online**

**Para documento √∫nico (descarga simple):**
```bash
wget "https://ejemplo.com/documento.pdf" -O source_document.pdf
```

**Para m√∫ltiples documentos del mismo tipo (necesitas scraper):**

1. **Primero verificar si ya existe scraper para el sitio:**
```bash
ls domains/{tu_dominio}/shared/scrapers/
```

2. **Si existe scraper, usarlo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python coordinador_scraper.py --download-latest
```

3. **Si NO existe scraper, crear uno nuevo:**
```bash
cd domains/{tu_dominio}/shared/scrapers/
python create_scraper.py --target-url "https://ejemplo.com/documentos/"
```

**B) Documentos Privados/Locales**
```bash
mkdir -p domains/{tu_dominio}/data/source_documents/
cp "/ruta/a/tu/documento.pdf" domains/{tu_dominio}/data/source_documents/
```

### Paso 1.2: Organizaci√≥n Inicial üóÇÔ∏è

**Crear estructura b√°sica para nuevo dominio/documento:**

1. **Crear directorio principal del documento:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/
```

2. **Crear subdirectorios necesarios:**
```bash
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/docs/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/processors/
mkdir -p domains/{tu_dominio}/chapters/{documento_tipo}/outputs/
```

3. **Crear directorio compartido del dominio:**
```bash
mkdir -p domains/{tu_dominio}/shared/
```

**‚ö†Ô∏è Importante sobre la estructura de documentos:**
- **La carpeta "chapters/" NO significa que tu documento tenga cap√≠tulos**
- **Es solo organizaci√≥n**: Cada documento va en su propia carpeta dentro de "chapters/"
- **Tu documento puede ser**:
  - **Documento con cap√≠tulos** (ej: manual de 200 p√°ginas con secciones)
  - **Documento unitario** (ej: contrato de 10 p√°ginas sin divisiones)
  - **Documento con partes** (ej: reporte con introducci√≥n, an√°lisis, conclusiones)

**¬øCu√°ndo crear nuevo dominio vs nueva carpeta de documento?**
- **Nuevo dominio**: √Årea de negocio completamente diferente (ej: legal, financiero, t√©cnico)
- **Nueva carpeta**: Mismo dominio, diferente tipo de documento (ej: diferentes reportes financieros)

---

## üîç **FASE 2: AN√ÅLISIS ESTRUCTURAL** (30-60 minutos)

### Paso 2.1: An√°lisis Autom√°tico de Estructura ü§ñ

**Opci√≥n A) Intentar herramientas autom√°ticas (si existen):**
```bash
python ai_platform/analyzers/document_structure_analyzer.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --output "analysis_result.json"
```

**Opci√≥n B) An√°lisis con Claude Code (Recomendado):**

Usar Claude Code para analizar la estructura del documento. **Prompt de ejemplo**:

```
Analiza este documento PDF y determina su estructura:

**1. TIPO DE DOCUMENTO**
- ¬øEs financiero, legal, t√©cnico, operacional, acad√©mico?
- ¬øCu√°l es su prop√≥sito principal?

**2. ESTRUCTURA GENERAL**
- ¬øTiene cap√≠tulos/secciones claramente definidos?
- ¬øEs un documento unitario sin divisiones?
- ¬øHay patrones repetitivos (tablas, listas)?

**3. DIVISI√ìN L√ìGICA**
- Si tiene cap√≠tulos: ¬øEn qu√© p√°ginas empiezan y terminan?
- Si es unitario: ¬øQu√© secciones l√≥gicas identificas?

**4. ENTIDADES PRINCIPALES**
- ¬øQu√© tipos de datos contiene? (empresas, fechas, m√©tricas, etc.)
- ¬øHay tablas con datos estructurados?
- ¬øQu√© informaci√≥n es m√°s valiosa para extraer?

**5. COMPLEJIDAD DE PROCESAMIENTO**
- Nivel estimado: Simple/Medio/Complejo
- ¬øRequiere OCR especial o es texto seleccionable?

Responde en formato JSON estructurado.
```

‚ö†Ô∏è **Nota**: **Adapta este prompt** a tu documento espec√≠fico. Claude Code puede leer PDFs directamente y darte un an√°lisis personalizado.

### Paso 2.2: Divisi√≥n de Cap√≠tulos/Secciones (Si Aplica) üìë

**‚ö†Ô∏è Importante**: No todos los documentos tienen cap√≠tulos. Elige la opci√≥n seg√∫n tu documento:

**A) Para Documentos con Cap√≠tulos/Secciones Claras**
(ej: manual t√©cnico, reporte extenso, documento acad√©mico)

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar detector autom√°tico de divisiones:**
```bash
python ai_platform/processors/chapter_divider.py \
  --document "../../../data/source_documents/documento.pdf" \
  --analysis "../../../analysis_result.json" \
  --output "chapter_divisions.json"
```

**B) Para Documentos Unitarios**
(ej: contrato, carta, factura, documento simple)

**Crear archivo de divisi√≥n simple:**
```bash
echo '{"type": "single_document", "pages": "all"}' > chapter_divisions.json
```

### Paso 2.3: Validaci√≥n Manual de Divisi√≥n ‚úã

**Revisar la divisi√≥n propuesta:**
```bash
python shared_platform/cli/review_divisions.py --interactive \
  --divisions "chapter_divisions.json" \
  --document "../../../data/source_documents/documento.pdf"
```

**Ejemplo de validaci√≥n interactiva**:
```
üîç Divisi√≥n propuesta:
‚îú‚îÄ‚îÄ Cap√≠tulo 1: P√°ginas 1-15 (Introducci√≥n)
‚îú‚îÄ‚îÄ Cap√≠tulo 2: P√°ginas 16-45 (An√°lisis Principal)
‚îú‚îÄ‚îÄ Cap√≠tulo 3: P√°ginas 46-60 (Conclusiones)

¬øAprobar esta divisi√≥n? [y/n/edit]: y
```

---

## ü§ñ **FASE 3: EXTRACCI√ìN ADAPTATIVA** (45-90 minutos)

### Paso 3.1: Generaci√≥n de Extractor Espec√≠fico üõ†Ô∏è

**Opci√≥n A) Usar herramientas autom√°ticas (si existen):**
```bash
python ai_platform/processors/adaptive_document_processor.py \
  --document "domains/{tu_dominio}/data/source_documents/documento.pdf" \
  --analysis "analysis_result.json" \
  --divisions "chapter_divisions.json" \
  --output-processor "{documento_tipo}_processor.py"
```

**Opci√≥n B) Crear extractor con Claude Code (Recomendado):**

Pedirle a Claude Code que genere el extractor espec√≠fico. **Prompt de ejemplo**:

```
Bas√°ndote en el an√°lisis del documento, crea un extractor Python espec√≠fico:

**CONTEXTO DEL DOCUMENTO**:
- Tipo: [Resultado del an√°lisis anterior]
- Estructura: [Divisi√≥n encontrada]
- Entidades principales: [Lo que identificaste]

**CREAR EXTRACTOR QUE**:
1. **Extraiga entidades espec√≠ficas** del tipo de documento
2. **Maneje la estructura** (cap√≠tulos o documento unitario)
3. **Valide rangos realistas** para los datos
4. **Normalice nombres** de entidades

**TIPOS DE EXTRACCI√ìN SEG√öN DOCUMENTO**:
- **Financiero**: M√©tricas, ratios, balances, flujos de caja
- **Legal**: Partes, obligaciones, fechas cr√≠ticas, clausulas
- **T√©cnico**: Especificaciones, procedimientos, equipos
- **Operacional**: KPIs, procesos, incidentes, m√©tricas

**INCLUIR EN EL C√ìDIGO**:
- Validaciones espec√≠ficas del dominio
- Manejo de errores
- Logging para debugging
- M√©tricas de confianza

Crea el archivo {documento_tipo}_processor.py con el c√≥digo completo.
```

‚ö†Ô∏è **Importante**: Claude Code puede generar el extractor pero **necesitar√°s iterar y personalizar** el c√≥digo 5-10 veces seg√∫n tu documento espec√≠fico.

### Paso 3.2: Primera Revisi√≥n T√©cnica del Extractor üéØ

1. **Ir al directorio de procesadores:**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/processors/
```

2. **Ejecutar extractor generado:**
```bash
python {documento_tipo}_processor.py \
  --input "../../../data/source_documents/documento.pdf" \
  --output "../outputs/raw_extractions/" \
  --confidence-threshold 0.7
```
üí° **Nota**: Tambi√©n puedes pedirle a Claude Code que ejecute este comando por ti.

3. **Revisar resultados iniciales:**
```bash
python review_extractions.py --interactive \
  --results "../outputs/raw_extractions/extraction_results.json"
```
üí° **Nota**: Claude Code puede revisar los resultados y hacer la validaci√≥n interactiva contigo.

**Proceso de calibraci√≥n t√©cnica (repetir 3-8 veces seg√∫n complejidad):**

‚ö†Ô∏è **Objetivo**: Hacer que el extractor funcione bien t√©cnicamente, NO validar cada dato.

1. **Ejecutar extractor en modo prueba:**
```bash
python {documento_tipo}_processor.py --test-mode
```
üí° **Nota**: Claude Code puede ejecutar esto y analizar los resultados.

2. **Identificar problemas espec√≠ficos:**
```bash
python identify_extraction_issues.py
```
üí° **Nota**: Claude Code puede identificar problemas autom√°ticamente revisando los outputs.

3. **Refinar c√≥digo seg√∫n problemas encontrados**
   (Esto requiere edici√≥n manual del processor)

4. **Medir confianza actual:**
```bash
confidence=$(python measure_confidence.py)
echo "Confianza actual: $confidence"
```
üí° **Nota**: Claude Code puede calcular m√©tricas de confianza autom√°ticamente.

5. **Repetir hasta lograr >85% confianza**

### Paso 3.3: Generaci√≥n de Metadatos y Tags üè∑Ô∏è

**Opci√≥n A) Herramientas autom√°ticas:**
```bash
python ai_platform/processors/metadata_generator.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/raw_extractions/" \
  --output "../outputs/enriched_metadata.json"
```

**Opci√≥n B) Generar metadatos con Claude Code (Recomendado):**

Pedirle a Claude Code que genere metadatos espec√≠ficos. **Prompt de ejemplo**:

```
Analiza los datos extra√≠dos y genera metadatos enriquecidos:

**GENERAR TAGS PARA**:
1. **Tags Sem√°nticos**: Conceptos clave, temas principales
2. **Tags Temporales**: Per√≠odos, fechas relevantes, vigencia
3. **Tags Geogr√°ficos**: Pa√≠ses, regiones, ciudades mencionadas
4. **Tags de Entidades**: Personas, organizaciones, productos
5. **Tags de Clasificaci√≥n**: Tipo, prop√≥sito, audiencia objetivo

**TAGS ESPEC√çFICOS SEG√öN DOMINIO**:
- **Financiero**: ratios, m√©tricas, per√≠odos fiscales, instrumentos
- **Legal**: tipo_contrato, jurisdicci√≥n, obligaciones, derechos
- **T√©cnico**: especificaciones, normas, procedimientos, equipos
- **Operacional**: KPIs, procesos, departamentos, m√©tricas

**IDENTIFICAR REFERENCIAS CRUZADAS**:
- Entidades que podr√≠an aparecer en otros documentos
- Per√≠odos temporales relevantes
- Organizaciones mencionadas
- Temas relacionados

Crea el archivo enriched_metadata.json con los metadatos estructurados.
```

‚ö†Ô∏è **Nota**: Claude Code puede generar metadatos autom√°ticamente, pero **revisa y personaliza** seg√∫n el contexto espec√≠fico de tu documento.

---

## ‚úã **FASE 4: VALIDACI√ìN MANUAL** (30-60 minutos)

‚ö†Ô∏è **Diferencia clave con Fase 3.2**:
- **Paso 3.2**: Primera revisi√≥n **t√©cnica** - ¬øfunciona bien el extractor?
- **Paso 4.1**: Revisi√≥n **de contenido** - ¬øson correctos estos datos espec√≠ficos?

### Paso 4.1: Revisi√≥n Final de Contenido (Validaci√≥n Humana) üîé

‚ö†Ô∏è **Objetivo**: Validar cada dato extra√≠do individualmente - ¬øes correcto este resultado espec√≠fico?

```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/cli/validation_interface.py \
  --data "outputs/raw_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --interactive
```
üí° **Nota**: Claude Code puede hacer toda la validaci√≥n conversacionalmente contigo, revisando cada extracci√≥n.

**Interfaz de validaci√≥n t√≠pica**:
```
üîç Extracci√≥n #1 - Empresa XYZ S.A.
‚îú‚îÄ‚îÄ Tipo: Organizaci√≥n
‚îú‚îÄ‚îÄ Ubicaci√≥n: Santiago, Chile
‚îú‚îÄ‚îÄ Sector: Energ√≠a
‚îú‚îÄ‚îÄ M√©trica asociada: 150 MW capacidad
‚îú‚îÄ‚îÄ Confianza IA: 0.89
‚îú‚îÄ‚îÄ Tags: [energia, chile, capacidad_instalpada]

¬øAprobar esta extracci√≥n? [y/n/edit/skip]:
- y: Aprobar como est√°
- n: Rechazar completamente
- edit: Corregir datos
- skip: Revisar despu√©s

Selecci√≥n: edit
‚îú‚îÄ‚îÄ Correcci√≥n: Cambiar "150 MW" ‚Üí "150.5 MW"
‚îú‚îÄ‚îÄ Tag adicional: "solar_energy"
‚úÖ Guardado
```

### Paso 4.2: Control de Calidad por Lotes üìä

```bash
python shared_platform/cli/quality_checker.py \
  --validated-data "outputs/validated_extractions/" \
  --original-document "../../../data/source_documents/documento.pdf" \
  --generate-report
```
üí° **Nota**: Claude Code puede generar reportes de calidad autom√°ticamente.

**M√©tricas de calidad generadas**:
```
üìä Reporte de Calidad:
‚îú‚îÄ‚îÄ P√°ginas procesadas: 45/45 (100%)
‚îú‚îÄ‚îÄ Entidades extra√≠das: 127
‚îú‚îÄ‚îÄ Entidades validadas: 119 (93.7%)
‚îú‚îÄ‚îÄ Entidades rechazadas: 8 (6.3%)
‚îú‚îÄ‚îÄ Confianza promedio: 0.91
‚îú‚îÄ‚îÄ Tiempo total: 42 minutos
‚îî‚îÄ‚îÄ Status: ‚úÖ APTO PARA PRODUCCI√ìN
```

### Paso 4.3: Generaci√≥n de Referencias Cruzadas üîó

**Opci√≥n A) Herramientas autom√°ticas:**
```bash
python ai_platform/processors/cross_reference_generator.py \
  --current-document "outputs/validated_extractions/" \
  --database "platform_data/database/dark_data.db" \
  --output "outputs/cross_references.json"
```

**Opci√≥n B) Detectar referencias con Claude Code (Recomendado):**

Pedirle a Claude Code que identifique referencias cruzadas. **Prompt de ejemplo**:

```
Analiza los datos validados e identifica referencias cruzadas potenciales:

**BUSCAR RELACIONES**:
1. **Entidad Id√©ntica**: Misma empresa/persona en otros documentos
2. **Temporal**: Documentos del mismo per√≠odo o fechas relacionadas
3. **Geogr√°fica**: Misma ubicaci√≥n/regi√≥n/pa√≠s
4. **Tem√°tica**: Mismo sector/industria/tema
5. **Funcional**: Documentos que se complementan

**ASIGNAR CONFIANZA**:
- 0.95+: Pr√°cticamente certeza (nombre exacto + contexto)
- 0.85-0.94: Alta confianza (variaciones menores)
- 0.70-0.84: Confianza media (contexto similar)
- <0.70: Baja confianza (solo sugerencia)

**PRIORIZAR**:
- Referencias que agreguen valor business
- Evitar conexiones triviales
- Incluir raz√≥n de la relaci√≥n

Consulta la base de datos dark_data.db y crea cross_references.json con las relaciones encontradas.
```

‚ö†Ô∏è **Importante**: Claude Code puede acceder a la base de datos y **detectar referencias autom√°ticamente**, pero siempre valida manualmente las m√°s importantes.

---

## üíæ **FASE 5: TRANSFORMACI√ìN UNIVERSAL** (15-30 minutos)

### Paso 5.1: Aplicaci√≥n del Esquema Universal üîÑ

**Opci√≥n A) Transformador autom√°tico (si existe):**
```bash
cd domains/{tu_dominio}/chapters/{documento_tipo}/
python shared_platform/transformers/universal_schema_transformer.py \
  --input "outputs/validated_extractions/" \
  --metadata "outputs/enriched_metadata.json" \
  --cross-refs "outputs/cross_references.json" \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --output "outputs/universal_json/"
```

**Opci√≥n B) Transformaci√≥n con Claude Code (Recomendado):**

‚ö†Ô∏è **Importante**: Cada documento tiene salidas diferentes. Claude Code puede crear la transformaci√≥n espec√≠fica.

**Prompt de ejemplo para transformaci√≥n espec√≠fica**:

```
Transforma los datos extra√≠dos al esquema universal de la plataforma:

**DATOS DE ENTRADA**:
- Extracciones validadas: [contenido espec√≠fico de tu documento]
- Metadatos: [tags y referencias de tu documento]
- Cross-referencias: [relaciones encontradas]

**ESQUEMA UNIVERSAL OBJETIVO**:
```json
{
  "@context": "https://darkdata.platform/context/v1",
  "@id": "ddp:{dominio}:{documento_tipo}:{fecha}",
  "@type": "ProcessedDocument",

  "document_metadata": {
    "document_id": "√∫nico_identificador",
    "document_type": "{documento_tipo}",
    "domain": "{tu_dominio}",
    "source_file": "nombre_original.pdf",
    "processing_date": "2025-09-26T10:30:00Z",
    "extraction_version": "1.0",
    "quality_score": 0.91
  },

  "extracted_entities": {
    "organizations": [...],
    "people": [...],
    "locations": [...],
    "dates": [...],
    "metrics": [...],
    "domain_specific": {...}
  },

  "semantic_tags": {
    "universal_tags": ["tag1", "tag2"],
    "domain_tags": ["domain_tag1"],
    "temporal_tags": ["2025", "Q3"],
    "geographic_tags": ["chile", "santiago"]
  },

  "cross_references": [
    {
      "target_document": "ddp:otro_dominio:otro_doc:fecha",
      "relationship_type": "SAME_ENTITY",
      "confidence": 0.95,
      "context": "Descripci√≥n de la relaci√≥n"
    }
  ]
}
```

**TAREA ESPEC√çFICA**:
1. **Mapea las entidades extra√≠das** de tu documento a las categor√≠as universales
2. **Adapta los datos espec√≠ficos** de tu dominio al campo "domain_specific"
3. **Normaliza los metadatos** seg√∫n el esquema universal
4. **Conserva la informaci√≥n original** pero en formato est√°ndar

Crea el archivo universal_schema.json con la transformaci√≥n completa.
```

üí° **Ventajas de Claude Code para Transformaci√≥n Universal**:
- **Entiende esquemas complejos**: Puede mapear datos espec√≠ficos a formato universal
- **Adaptaci√≥n autom√°tica**: Se ajusta a la estructura espec√≠fica de tu documento
- **Preserva informaci√≥n**: No pierde datos importantes en la transformaci√≥n
- **Validaci√≥n**: Verifica que la transformaci√≥n sea correcta
- **Iterativo**: Puedes refinar la transformaci√≥n hasta que sea perfecta

‚ö†Ô∏è **Por qu√© es cr√≠tico**: Cada tipo de documento (financiero, legal, t√©cnico) tiene estructura diferente, pero necesita transformarse al mismo esquema universal para que la plataforma AI pueda consultarlo consistentemente.

---

## üóÑÔ∏è **FASE 6: INGESTA Y ACCESO AI** (15-30 minutos)

### Paso 6.1: Ingesta a Base de Datos üìä

```bash
make setup-db  # Si es primera vez
python shared_platform/database_tools/ingest_data.py \
  --input "domains/{tu_dominio}/chapters/{documento_tipo}/outputs/universal_json/" \
  --update-schema-if-needed \
  --validate-integrity
```
üí° **Nota**: Claude Code puede ejecutar estos comandos y manejar toda la ingesta a la base de datos.

### Paso 6.2: Activaci√≥n de Acceso AI ü§ñ

```bash
make run-mcp  # Servidor principal

# Servidor espec√≠fico del dominio (si existe)
cd ai_platform/mcp_servers/
python {tu_dominio}_server.py  # ej: operaciones_server.py
```
üí° **Nota**: Claude Code puede activar los servidores MCP y ya tienes acceso directo a los datos.

### Paso 6.3: Verificaci√≥n Final ‚úÖ

```bash
python shared_platform/cli/test_ai_queries.py \
  --domain "{tu_dominio}" \
  --document-type "{documento_tipo}" \
  --sample-queries "prompts/testing/sample_queries.md"
```
üí° **Nota**: Con Claude Code ya puedes hacer consultas directamente sin scripts adicionales.

**Consultas de prueba t√≠picas**:
```markdown
# Consultas b√°sicas para verificar funcionamiento
"¬øCu√°ntas entidades se extrajeron de este documento?"
"Lista las 5 organizaciones principales mencionadas"
"¬øQu√© referencias cruzadas se encontraron?"
"Muestra un resumen de los tags sem√°nticos"
```

---

## üìã **RESUMEN METODOL√ìGICO**

### ‚úÖ **Checklist Completo para Nuevo Documento**

```bash
# 1. OBTENCI√ìN (15-30 min)
[ ] Documento descargado/copiado
[ ] Estructura de carpetas creada
[ ] Dominio y tipo definidos

# 2. AN√ÅLISIS ESTRUCTURAL (30-60 min)
[ ] An√°lisis autom√°tico ejecutado (Prompt #1)
[ ] Divisi√≥n de cap√≠tulos completada
[ ] Estructura validada manualmente

# 3. EXTRACCI√ìN ADAPTATIVA (45-90 min)
[ ] Extractor espec√≠fico generado (Prompt #2)
[ ] Extractor calibrado (>85% confianza)
[ ] Metadatos generados (Prompt #3)

# 4. VALIDACI√ìN MANUAL (30-60 min)
[ ] Extracciones revisadas interactivamente
[ ] Control de calidad aprobado
[ ] Referencias cruzadas generadas (Prompt #4)

# 5. TRANSFORMACI√ìN UNIVERSAL (15-30 min)
[ ] Esquema universal aplicado
[ ] JSON v√°lido generado
[ ] Metadatos completos

# 6. INGESTA Y ACCESO AI (15-30 min)
[ ] Datos ingresados a base de datos
[ ] Servidores MCP activados
[ ] Consultas AI funcionando
```

### üéØ **Tiempo Total Estimado por Complejidad**

| Tipo de Documento | Tiempo Total | Iteraciones | Dificultad |
|-------------------|--------------|-------------|------------|
| **Simple** (1-20 p√°ginas, estructura clara) | 2-3 horas | 3-5 | ‚≠ê‚≠ê |
| **Medio** (20-100 p√°ginas, m√∫ltiples secciones) | 3-4 horas | 5-8 | ‚≠ê‚≠ê‚≠ê |
| **Complejo** (100+ p√°ginas, estructura irregular) | 4-6 horas | 8-12 | ‚≠ê‚≠ê‚≠ê‚≠ê |

### üõ†Ô∏è **Herramientas Disponibles**

**ü§ñ Herramienta Principal: Claude Code**
- Puede realizar todas las fases de la metodolog√≠a
- Acceso directo a PDFs, base de datos y archivos
- Conversaci√≥n natural para iteraci√≥n y mejora
- Generaci√≥n de c√≥digo espec√≠fico por documento

**‚öôÔ∏è Herramientas Autom√°ticas (Opcionales)**:
```
ai_platform/
‚îú‚îÄ‚îÄ analyzers/document_structure_analyzer.py     # An√°lisis autom√°tico
‚îú‚îÄ‚îÄ processors/adaptive_document_processor.py   # Extracci√≥n adaptativa
‚îú‚îÄ‚îÄ processors/metadata_generator.py            # Generaci√≥n de metadatos
‚îî‚îÄ‚îÄ processors/cross_reference_generator.py     # Referencias cruzadas

shared_platform/
‚îú‚îÄ‚îÄ cli/validation_interface.py                 # Validaci√≥n interactiva
‚îú‚îÄ‚îÄ cli/quality_checker.py                      # Control de calidad
‚îú‚îÄ‚îÄ transformers/universal_schema_transformer.py # Transformaci√≥n universal
‚îî‚îÄ‚îÄ database_tools/ingest_data.py              # Ingesta a base de datos
```

### üí° **Metodolog√≠a con Claude Code**

**üéØ Enfoque Principal: Usar Claude Code para todo el procesamiento**

La metodolog√≠a est√° dise√±ada para trabajar principalmente con **Claude Code**:

- **üìÑ Lectura directa de PDFs**: Claude Code puede leer documentos directamente
- **ü§ñ An√°lisis inteligente**: An√°lisis de estructura con conversaci√≥n natural
- **üíª Generaci√≥n de c√≥digo**: Creaci√≥n de extractores Python personalizados
- **üîç Validaci√≥n interactiva**: Revisi√≥n manual con Claude Code
- **üîó Referencias cruzadas**: Acceso a base de datos para correlaciones
- **üìä Transformaci√≥n**: Conversi√≥n a esquemas universales

### üìù **Prompts de Ejemplo Incluidos**

Los prompts mostrados en cada fase son **ejemplos de conversaci√≥n con Claude Code**:

- **FASE 2**: An√°lisis de estructura de documentos
- **FASE 3**: Generaci√≥n de extractores y metadatos
- **FASE 4**: Detecci√≥n de referencias cruzadas

‚ö†Ô∏è **Importante sobre la Metodolog√≠a**:
- **Claude Code es la herramienta principal** para todo el procesamiento
- Los scripts autom√°ticos son **opcionales** (Opci√≥n A en cada fase)
- **Los prompts son ejemplos** de c√≥mo hablar con Claude Code
- **Personaliza la conversaci√≥n** seg√∫n tu documento espec√≠fico
- **Claude Code puede iterar** contigo hasta lograr resultados perfectos

---

## üéØ **Casos de Uso Validados**

### üìà **Documentos Financieros**
- **Estados de resultados, balances, flujos de caja**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades t√≠picas**: M√©tricas financieras, ratios, comparativos

### üìã **Documentos Legales**
- **Contratos, acuerdos, pol√≠ticas corporativas**
- **Tiempo promedio**: 3-4 horas
- **Entidades t√≠picas**: Partes, obligaciones, fechas cr√≠ticas

### üîß **Documentos T√©cnicos**
- **Manuales, especificaciones, procedimientos**
- **Tiempo promedio**: 3.5-4.5 horas
- **Entidades t√≠picas**: Especificaciones, equipos, normas

### ‚ö° **Documentos Operacionales**
- **Reportes de operaciones, KPIs, an√°lisis de rendimiento**
- **Tiempo promedio**: 2.5-3.5 horas
- **Entidades t√≠picas**: M√©tricas, procesos, incidentes

---

**üåë Dark Data Platform - Metodolog√≠a Universal**

> **"De cualquier PDF a inteligencia AI-queryable en 2-6 horas"**

> **√öltima actualizaci√≥n**: 26 Sep 2025 | **Versi√≥n**: 2.0 | **Validado con**: 15+ tipos de documentos diferentes