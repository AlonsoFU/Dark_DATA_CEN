#!/usr/bin/env python3
"""
Analyze all title patterns found to create processing rules for technical documents
"""

import sqlite3
import re
from pathlib import Path

def analyze_title_patterns():
    # Default to platform_data/database/dark_data.db relative to project root
    project_root = Path(__file__).parent.parent.parent.parent.parent.parent
    db_path = project_root / "platform_data" / "database" / "dark_data.db"
    conn = sqlite3.connect(str(db_path))
    conn.row_factory = sqlite3.Row
    
    print("üîç AN√ÅLISIS DE PATRONES DE T√çTULOS ENCONTRADOS")
    print("=" * 70)
    
    # Get all detected titles
    cursor = conn.execute("""
        SELECT specific_annex_number, specific_annex_title, annex_theme
        FROM document_chunks 
        WHERE specific_annex_number IS NOT NULL
        ORDER BY CAST(specific_annex_number AS INTEGER)
    """)
    
    annexes = cursor.fetchall()
    
    print(f"üìä T√çTULOS DETECTADOS EN ESTE DOCUMENTO:")
    print("=" * 50)
    
    title_patterns = {}
    
    for annex in annexes:
        num = annex['specific_annex_number']
        title = annex['specific_annex_title']
        theme = annex['annex_theme']
        
        if num not in title_patterns:
            title_patterns[num] = {
                'title': title,
                'theme': theme,
                'format_analysis': analyze_title_format(title)
            }
    
    for num in sorted(title_patterns.keys(), key=int):
        data = title_patterns[num]
        print(f"\nüìã ANEXO {num}:")
        print(f"   üìù \"{data['title']}\"")
        print(f"   üè∑Ô∏è  Tema: {data['theme']}")
        print(f"   üìê Formato: {data['format_analysis']}")
    
    # Analyze patterns across all titles
    print(f"\nüîç AN√ÅLISIS DE PATRONES COMUNES:")
    print("=" * 50)
    
    patterns_found = {
        'starts_with_detalle': 0,
        'contains_dias_fecha': 0,
        'contains_sistema': 0,
        'contains_coordinador': 0,
        'contains_empresas': 0,
        'contains_antecedentes': 0,
        'contains_analisis': 0,
        'long_descriptive': 0,
        'short_descriptive': 0
    }
    
    all_titles = [data['title'] for data in title_patterns.values()]
    
    for title in all_titles:
        title_lower = title.lower()
        
        if title_lower.startswith('detalle'):
            patterns_found['starts_with_detalle'] += 1
        if 'd√≠as' in title_lower and ('febrero' in title_lower or 'fecha' in title_lower):
            patterns_found['contains_dias_fecha'] += 1
        if 'sistema' in title_lower:
            patterns_found['contains_sistema'] += 1
        if 'coordinador' in title_lower:
            patterns_found['contains_coordinador'] += 1
        if 'empresas' in title_lower:
            patterns_found['contains_empresas'] += 1
        if 'antecedentes' in title_lower:
            patterns_found['contains_antecedentes'] += 1
        if 'an√°lisis' in title_lower or 'analisis' in title_lower:
            patterns_found['contains_analisis'] += 1
        
        if len(title) > 80:
            patterns_found['long_descriptive'] += 1
        elif len(title) > 30:
            patterns_found['short_descriptive'] += 1
    
    print("üìä PATRONES IDENTIFICADOS:")
    for pattern, count in patterns_found.items():
        if count > 0:
            percentage = (count / len(all_titles)) * 100
            print(f"   ‚Ä¢ {pattern.replace('_', ' ').title()}: {count}/{len(all_titles)} ({percentage:.0f}%)")
    
    # Create processing rules based on patterns
    print(f"\nüõ†Ô∏è  REGLAS DE PROCESAMIENTO PARA DOCUMENTOS T√âCNICOS:")
    print("=" * 60)
    
    processing_rules = create_processing_rules(title_patterns, patterns_found)
    
    for i, rule in enumerate(processing_rules, 1):
        print(f"\n{i}. üìã {rule['category']}:")
        print(f"   üîç Patr√≥n: {rule['pattern']}")
        print(f"   üè∑Ô∏è  Tema sugerido: {rule['suggested_theme']}")
        print(f"   üìù Ejemplo: \"{rule['example']}\"")
        if rule['notes']:
            print(f"   üí° Nota: {rule['notes']}")
    
    conn.close()
    return processing_rules

def analyze_title_format(title):
    """Analyze the format characteristics of a title"""
    
    characteristics = []
    
    # Length analysis
    if len(title) > 100:
        characteristics.append("Muy descriptivo")
    elif len(title) > 60:
        characteristics.append("Descriptivo")
    else:
        characteristics.append("Conciso")
    
    # Content analysis
    if title.lower().startswith('detalle'):
        characteristics.append("Inicia con 'Detalle'")
    
    if 'd√≠as' in title.lower() and any(fecha in title.lower() for fecha in ['febrero', 'enero', 'marzo']):
        characteristics.append("Incluye fechas espec√≠ficas")
    
    if any(word in title.lower() for word in ['sistema', 'coordinador', 'empresas']):
        characteristics.append("Menciona entidades institucionales")
    
    if any(word in title.lower() for word in ['programado', 'real', 'forzado']):
        characteristics.append("Especifica tipo de operaci√≥n")
    
    return " | ".join(characteristics)

def create_processing_rules(title_patterns, patterns_found):
    """Create processing rules based on detected patterns"""
    
    rules = [
        {
            'category': 'ANEXOS DE DETALLE OPERACIONAL',
            'pattern': r'Detalle\s+de\s+la\s+(generaci√≥n|operaci√≥n).*d√≠as\s+\d+\s+y\s+\d+',
            'suggested_theme': 'generation_programming',
            'example': 'Detalle de la generaci√≥n programada para los d√≠as 25 y 26 de febrero de 2025',
            'notes': 'Com√∫n en informes de fallas el√©ctricas - datos espec√≠ficos por fecha'
        },
        {
            'category': 'ANEXOS DE MOVIMIENTO/CDC',
            'pattern': r'Detalle.*Movimiento.*Centrales.*CDC',
            'suggested_theme': 'operational_data',
            'example': 'Detalle del Movimiento de Centrales e Informe Diario del CDC correspondientes a los d√≠as 25 y 26',
            'notes': 'Centro de Despacho y Control - informaci√≥n operativa cr√≠tica'
        },
        {
            'category': 'ANEXOS DE MANTENIMIENTO',
            'pattern': r'Detalle.*mantenimientos?\s+(programados?|forzados?)',
            'suggested_theme': 'equipment_details',
            'example': 'Detalle de los mantenimientos programados y forzados para los d√≠as 25 y 26 de febrero de 2025',
            'notes': 'Informaci√≥n de equipos y su estado operativo'
        },
        {
            'category': 'ANEXOS DE INFORMES T√âCNICOS',
            'pattern': r'Informe.*instalaciones.*sistema.*Coordinador.*Nacional',
            'suggested_theme': 'technical_analysis',
            'example': 'Informe de trabajo y falla de instalaciones ingresados en el sistema del Coordinador El√©ctrico Nacional',
            'notes': 'Documentos formales del regulador el√©ctrico'
        },
        {
            'category': 'ANEXOS DE ANTECEDENTES',
            'pattern': r'(Otros\s+)?antecedentes.*empresas.*(involucradas|coordinadas)',
            'suggested_theme': 'communication_logs',
            'example': 'Otros antecedentes aportados por las empresas involucradas en la falla',
            'notes': 'Documentaci√≥n complementaria de las empresas'
        },
        {
            'category': 'ANEXOS DE AN√ÅLISIS T√âCNICO ESPECIALIZADO',
            'pattern': r'An√°lisis.*esquema\s+(EDAC|t√©cnico)',
            'suggested_theme': 'technical_analysis',
            'example': 'An√°lisis operativo del esquema EDAC',
            'notes': 'EDAC = Esquemas de Desconexi√≥n Autom√°tica de Carga'
        }
    ]
    
    return rules

def suggest_document_processing_improvements():
    """Suggest improvements for processing similar documents"""
    
    print(f"\nüöÄ SUGERENCIAS PARA MEJORAR EL PROCESAMIENTO:")
    print("=" * 60)
    
    improvements = [
        {
            'area': 'Detecci√≥n de Patrones de T√≠tulo',
            'suggestion': 'Crear regex espec√≠ficos para documentos el√©ctricos chilenos',
            'implementation': 'Buscar "Detalle de..." seguido de fechas espec√≠ficas (25 y 26 de febrero)',
            'benefit': 'Detectar autom√°ticamente anexos operacionales vs t√©cnicos'
        },
        {
            'area': 'Clasificaci√≥n Tem√°tica Autom√°tica',
            'suggestion': 'Usar keywords institucionales (CDC, Coordinador El√©ctrico Nacional)',
            'implementation': 'Si contiene "CDC" ‚Üí operational_data, si contiene "esquema EDAC" ‚Üí technical_analysis',
            'benefit': 'Clasificaci√≥n m√°s precisa sin intervenci√≥n manual'
        },
        {
            'area': 'Detecci√≥n de Fechas Cr√≠ticas',
            'suggestion': 'Identificar documentos de eventos espec√≠ficos por fechas',
            'implementation': 'Patrones como "25 y 26 de febrero de 2025" indican eventos puntuales',
            'benefit': 'Agrupar contenido relacionado al mismo incidente'
        },
        {
            'area': 'Manejo de Contenido Placeholder',
            'suggestion': 'Implementar reprocesamiento de chunks con [X characters]',
            'implementation': 'Identificar y re-extraer contenido de p√°ginas problem√°ticas',
            'benefit': 'Recuperar 62% del contenido actualmente no accesible'
        },
        {
            'area': 'Estructura Jer√°rquica',
            'suggestion': 'Establecer relaciones padre-hijo entre anexos y secciones',
            'implementation': 'ANEXO ‚Üí subsecciones ‚Üí contenido detallado',
            'benefit': 'Navegaci√≥n m√°s intuitiva del documento t√©cnico'
        }
    ]
    
    for i, improvement in enumerate(improvements, 1):
        print(f"\n{i}. üõ†Ô∏è  {improvement['area']}:")
        print(f"   üí° Sugerencia: {improvement['suggestion']}")
        print(f"   üîß Implementaci√≥n: {improvement['implementation']}")  
        print(f"   ‚úÖ Beneficio: {improvement['benefit']}")

if __name__ == "__main__":
    rules = analyze_title_patterns()
    suggest_document_processing_improvements()